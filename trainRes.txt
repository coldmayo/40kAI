Model units:
Name: Apothecary, Army Type: Space_Marine
Name: Eliminator Squad, Army Type: Space_Marine
Enemy units:
Name: Apothecary, Army Type: Space_Marine
Name: Eliminator Squad, Army Type: Space_Marine
Number of Lifetimes ran: 400

Iteration 0 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 1 ended with reward tensor([0.4000]), enemy health [4, 0.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 2 ended with reward tensor([-1.]), enemy health [4, 0.0], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 3 ended with reward tensor([-0.5000]), enemy health [4, 0.0], model health [0, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 4 ended with reward tensor([-1.8000]), enemy health [0, 0.0], model health [0, 8], model VP 0, enemy VP 5, victory condition 2
Major Victory
enemy won!
Iteration 5 ended with reward tensor([0]), enemy health [4, 8], model health [3.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 6 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [3.0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 7 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0.0, 2.0], model VP 0, enemy VP 5, victory condition 1
Iteration 8 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0.0, 2.0], model VP 0, enemy VP 7, victory condition 1
Iteration 9 ended with reward tensor([-1.3000]), enemy health [3.0, 8], model health [0.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 10 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 11 ended with reward tensor([2.7000]), enemy health [4, 8], model health [0, 8.0], model VP 0, enemy VP 5, victory condition 1
Iteration 12 ended with reward tensor([1.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 8, victory condition 1
Iteration 13 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 11, victory condition 1
Iteration 14 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 15, victory condition 1
Major Victory
model won!
Iteration 15 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 16 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 8, victory condition 2
Iteration 17 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 12, victory condition 2
Major Victory
model won!
Iteration 18 ended with reward tensor([1.9000]), enemy health [4, 0.0], model health [4, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 19 ended with reward tensor([-1.]), enemy health [0.0, 0.0], model health [4, 5.0], model VP 0, enemy VP 7, victory condition 2
Major Victory
enemy won!
Iteration 20 ended with reward tensor([0.9000]), enemy health [4, 8.0], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 21 ended with reward tensor([2.2000]), enemy health [0.0, 8.0], model health [0, 5.0], model VP 0, enemy VP 6, victory condition 1
Iteration 22 ended with reward tensor([0.]), enemy health [0.0, 8.0], model health [0, 2.0], model VP 0, enemy VP 9, victory condition 1
Iteration 23 ended with reward tensor([2]), enemy health [0.0, 8.0], model health [0, 0.0], model VP 0, enemy VP 12, victory condition 1
Major Victory
model won!
Iteration 24 ended with reward tensor([3.7000]), enemy health [4.0, 8], model health [4, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 25 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [4, 0], model VP 0, enemy VP 6, victory condition 1
Iteration 26 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [4.0, 0], model VP 0, enemy VP 9, victory condition 1
Iteration 27 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 12, victory condition 1
Major Victory
model won!
Iteration 28 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 29 ended with reward tensor([1.4000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 6, victory condition 2
Iteration 30 ended with reward tensor([0]), enemy health [0, 8], model health [0.0, 8], model VP 0, enemy VP 8, victory condition 2
Iteration 31 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 8], model VP 0, enemy VP 10, victory condition 2
Iteration 32 ended with reward tensor([-1.3000]), enemy health [0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 12, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 33 ended with reward tensor([3.7000]), enemy health [4, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 34 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 35 ended with reward tensor([1.5000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 6, victory condition 2
Iteration 36 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 8, victory condition 2
Major Victory
model won!
Iteration 37 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 38 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 39 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 6, victory condition 2
Major Victory
model won!
Iteration 40 ended with reward tensor([1.4000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 41 ended with reward tensor([5.4000]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 42 ended with reward tensor([0.]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 6, victory condition 2
Iteration 43 ended with reward tensor([2]), enemy health [0, 0], model health [0, 0], model VP 0, enemy VP 8, victory condition 2
Major Victory
model won!
Iteration 44 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 45 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 46 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 47 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 48 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0, 4.0], model VP 0, enemy VP 6, victory condition 1
Iteration 49 ended with reward tensor([1.]), enemy health [0.0, 8], model health [0, 3.0], model VP 0, enemy VP 8, victory condition 1
Iteration 50 ended with reward tensor([2]), enemy health [0.0, 8], model health [0, 0.0], model VP 0, enemy VP 10, victory condition 1
Major Victory
model won!
Iteration 51 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 52 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 53 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0.0, 2.0], model VP 0, enemy VP 6, victory condition 1
Iteration 54 ended with reward tensor([1.2000]), enemy health [1.0, 0], model health [0.0, 2.0], model VP 0, enemy VP 8, victory condition 1
Iteration 55 ended with reward tensor([-2.5000]), enemy health [1.0, 0], model health [0.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 56 ended with reward tensor([4.4000]), enemy health [4, 2.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 57 ended with reward tensor([0.9000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 58 ended with reward tensor([0.2000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 59 ended with reward tensor([0.7000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 60 ended with reward tensor([0.2000]), enemy health [0, 0], model health [0, 8], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 61 ended with reward tensor([1.9000]), enemy health [4, 8.0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 62 ended with reward tensor([5.4000]), enemy health [4, 0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 63 ended with reward tensor([4.]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 64 ended with reward tensor([1.]), enemy health [4, 0], model health [1.0, 0], model VP 0, enemy VP 4, victory condition 1
Iteration 65 ended with reward tensor([2]), enemy health [4, 0], model health [0.0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 66 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [4, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 67 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [1.0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 68 ended with reward tensor([1.5000]), enemy health [4, 5.0], model health [0, 8.0], model VP 0, enemy VP 3, victory condition 1
Iteration 69 ended with reward tensor([0.7000]), enemy health [4, 0.0], model health [0, 8.0], model VP 0, enemy VP 4, victory condition 1
Iteration 70 ended with reward tensor([-2.5000]), enemy health [1.0, 0.0], model health [0, 8.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 71 ended with reward tensor([2.7000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 72 ended with reward tensor([0.5000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 73 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 74 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 75 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 76 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 77 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 78 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 79 ended with reward tensor([2.7000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 80 ended with reward tensor([1.5000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 81 ended with reward tensor([2]), enemy health [1.0, 0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 82 ended with reward tensor([0]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 83 ended with reward tensor([0.]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 84 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 85 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 86 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 87 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 88 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 89 ended with reward tensor([0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 90 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 91 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 92 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 93 ended with reward tensor([0.4000]), enemy health [4, 8.0], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 94 ended with reward tensor([1.5000]), enemy health [4, 8.0], model health [4, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 95 ended with reward tensor([2.2000]), enemy health [4, 8.0], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 96 ended with reward tensor([2]), enemy health [4, 8.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 97 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 98 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0.0, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 99 ended with reward tensor([2]), enemy health [4, 2.0], model health [0.0, 0.0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 100 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4.0, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 101 ended with reward tensor([-1.6000]), enemy health [0, 0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Major Victory
enemy won!
Iteration 102 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 103 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [4, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 104 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 8.0], model VP 0, enemy VP 3, victory condition 1
Iteration 105 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 106 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [0, 1.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 107 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 108 ended with reward tensor([2.2000]), enemy health [1.0, 5.0], model health [0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 109 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 110 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 111 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 112 ended with reward tensor([2.2000]), enemy health [4, 2.0], model health [2.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 113 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 114 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 115 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 116 ended with reward tensor([2.2000]), enemy health [0, 8.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 117 ended with reward tensor([3.7000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 118 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 119 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 120 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 121 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 122 ended with reward tensor([2.7000]), enemy health [4, 5.0], model health [1.0, 0.0], model VP 0, enemy VP 1, victory condition 2
Iteration 123 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 124 ended with reward tensor([0.7000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 125 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 126 ended with reward tensor([0]), enemy health [1.0, 8], model health [0.0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 127 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0.0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 128 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 129 ended with reward tensor([2]), enemy health [4, 8.0], model health [0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 130 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [1.0, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 131 ended with reward tensor([2.2000]), enemy health [4, 2.0], model health [0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 132 ended with reward tensor([0.2000]), enemy health [0.0, 2.0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 133 ended with reward tensor([-1.8000]), enemy health [0.0, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 134 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 135 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 136 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 137 ended with reward tensor([1.]), enemy health [0.0, 8], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 138 ended with reward tensor([2]), enemy health [0.0, 8], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 139 ended with reward tensor([2.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 140 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 141 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 4.0], model VP 0, enemy VP 3, victory condition 1
Iteration 142 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [0, 4.0], model VP 0, enemy VP 4, victory condition 1
Iteration 143 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 144 ended with reward tensor([0.9000]), enemy health [4, 0], model health [1.0, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 145 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 146 ended with reward tensor([-0.5000]), enemy health [2.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 147 ended with reward tensor([-1.]), enemy health [0.0, 0], model health [1.0, 4.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 148 ended with reward tensor([4.4000]), enemy health [4, 5.0], model health [0.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 149 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [0.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 150 ended with reward tensor([2]), enemy health [4.0, 2.0], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 151 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 152 ended with reward tensor([-0.5000]), enemy health [4, 6.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 153 ended with reward tensor([2]), enemy health [4, 6.0], model health [0, 0.0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 154 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [1.0, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 155 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 156 ended with reward tensor([1.]), enemy health [4, 0.0], model health [0, 1.0], model VP 0, enemy VP 3, victory condition 1
Iteration 157 ended with reward tensor([2]), enemy health [4, 0.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 158 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 159 ended with reward tensor([4.4000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 160 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 161 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 162 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 5.0], model VP 0, enemy VP 5, victory condition 1
Major Victory
enemy won!
Iteration 163 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 164 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 165 ended with reward tensor([2]), enemy health [4, 8], model health [0.0, 0.0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 166 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 167 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 168 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 169 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 170 ended with reward tensor([-2.5000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 171 ended with reward tensor([0.2000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 172 ended with reward tensor([-1.1000]), enemy health [0, 0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 2
Major Victory
enemy won!
Iteration 173 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 174 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 175 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 176 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 4, victory condition 2
Iteration 177 ended with reward tensor([-2.5000]), enemy health [1.0, 7.0], model health [0, 6.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 178 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 179 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [4.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 180 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [4.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 181 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [3.0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 182 ended with reward tensor([-2.5000]), enemy health [0, 1.0], model health [2.0, 5.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 183 ended with reward tensor([1.4000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 184 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 185 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0.0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 186 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 187 ended with reward tensor([0.]), enemy health [4, 5.0], model health [4.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 188 ended with reward tensor([0.9000]), enemy health [0, 5.0], model health [4.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 189 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 190 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 191 ended with reward tensor([0.9000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 192 ended with reward tensor([0.2000]), enemy health [0, 8.0], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 193 ended with reward tensor([2]), enemy health [0, 8.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 194 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [1.0, 0], model VP 0, enemy VP 1, victory condition 1
Iteration 195 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 196 ended with reward tensor([1.2000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 197 ended with reward tensor([0.]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 198 ended with reward tensor([-1.]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 199 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 200 ended with reward tensor([-2]), enemy health [4, 0], model health [1.0, 0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 201 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 202 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 203 ended with reward tensor([0]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 204 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 4, victory condition 1
Iteration 205 ended with reward tensor([-1.8000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 206 ended with reward tensor([4.9000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 207 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 208 ended with reward tensor([0]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 209 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 210 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 8], model VP 0, enemy VP 5, victory condition 2
Major Victory
enemy won!
Iteration 211 ended with reward tensor([0.2000]), enemy health [4, 8], model health [1.0, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 212 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 213 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 214 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 215 ended with reward tensor([1.2000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 216 ended with reward tensor([0]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 217 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 218 ended with reward tensor([0.]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 219 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 220 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [4.0, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 221 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [4.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 222 ended with reward tensor([0]), enemy health [0, 2.0], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 223 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [1.0, 0], model VP 0, enemy VP 4, victory condition 1
Iteration 224 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 225 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 226 ended with reward tensor([4.9000]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 227 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 228 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 1.0], model VP 0, enemy VP 4, victory condition 1
Iteration 229 ended with reward tensor([-0.8000]), enemy health [0, 2.0], model health [0, 1.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 230 ended with reward tensor([0.2000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 231 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 232 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 233 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 234 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 235 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 236 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 237 ended with reward tensor([4.7000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 238 ended with reward tensor([2.7000]), enemy health [0.0, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 239 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 240 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 241 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 242 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 243 ended with reward tensor([0]), enemy health [0, 8], model health [4, 0.0], model VP 0, enemy VP 2, victory condition 2
Iteration 244 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 0.0], model VP 0, enemy VP 3, victory condition 2
Iteration 245 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 246 ended with reward tensor([0.7000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 247 ended with reward tensor([0.2000]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 248 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 249 ended with reward tensor([0]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 250 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0.0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 251 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 252 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 253 ended with reward tensor([3.5000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 254 ended with reward tensor([-1.]), enemy health [1.0, 0], model health [1.0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 255 ended with reward tensor([-3.]), enemy health [1.0, 0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 256 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 257 ended with reward tensor([0.4000]), enemy health [1.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 258 ended with reward tensor([-1.]), enemy health [1.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 259 ended with reward tensor([-1.1000]), enemy health [0, 0], model health [1.0, 5.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 260 ended with reward tensor([0.7000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 261 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 262 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 263 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 264 ended with reward tensor([-2.5000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 265 ended with reward tensor([4.4000]), enemy health [4, 8.0], model health [4.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 266 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 267 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [0.0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 268 ended with reward tensor([1.]), enemy health [4, 0.0], model health [0.0, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 269 ended with reward tensor([-2.5000]), enemy health [4, 0.0], model health [0.0, 7.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 270 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 271 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 272 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 273 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 274 ended with reward tensor([-2]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 275 ended with reward tensor([0.9000]), enemy health [4.0, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 276 ended with reward tensor([-0.5000]), enemy health [4.0, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 277 ended with reward tensor([-0.5000]), enemy health [4.0, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 278 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 279 ended with reward tensor([-2.5000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 280 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 281 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 282 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 283 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 284 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 285 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 286 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 4.0], model VP 0, enemy VP 3, victory condition 2
Iteration 287 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 4.0], model VP 0, enemy VP 4, victory condition 2
Iteration 288 ended with reward tensor([-2]), enemy health [4, 8], model health [0, 1.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 289 ended with reward tensor([0.4000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 290 ended with reward tensor([4.5000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 291 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 292 ended with reward tensor([-1.]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 293 ended with reward tensor([-2.5000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 294 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0.0, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 295 ended with reward tensor([2]), enemy health [1.0, 8], model health [0.0, 0.0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 296 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 297 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 298 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [1.0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 299 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 300 ended with reward tensor([0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 301 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 302 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 303 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 304 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 305 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 306 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 307 ended with reward tensor([2.]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 308 ended with reward tensor([-2.]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 309 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 310 ended with reward tensor([0]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 311 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 312 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 313 ended with reward tensor([-1.8000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 314 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 315 ended with reward tensor([0.9000]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 316 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 317 ended with reward tensor([0]), enemy health [4, 0], model health [1.0, 1.0], model VP 0, enemy VP 4, victory condition 2
Iteration 318 ended with reward tensor([-2]), enemy health [4, 0], model health [1.0, 1.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 319 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 320 ended with reward tensor([4.9000]), enemy health [4, 2.0], model health [1.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 321 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 322 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, -1.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 323 ended with reward tensor([0]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 324 ended with reward tensor([-0.3000]), enemy health [4, 2.0], model health [1.0, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 325 ended with reward tensor([4.2000]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 326 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 327 ended with reward tensor([2]), enemy health [4, 8], model health [0.0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 328 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 329 ended with reward tensor([0.4000]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 330 ended with reward tensor([-1.]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 331 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [1.0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 332 ended with reward tensor([-2.5000]), enemy health [2.0, 0], model health [1.0, 0.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 333 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 334 ended with reward tensor([0]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 335 ended with reward tensor([0.5000]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 336 ended with reward tensor([0]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 337 ended with reward tensor([-2]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 338 ended with reward tensor([0.4000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 339 ended with reward tensor([0]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 340 ended with reward tensor([0.5000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 341 ended with reward tensor([0.5000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 342 ended with reward tensor([-2.]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 343 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 344 ended with reward tensor([2.2000]), enemy health [4, 2.0], model health [4, 0.0], model VP 0, enemy VP 2, victory condition 2
Iteration 345 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0.0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 346 ended with reward tensor([0.2000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 347 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 348 ended with reward tensor([0.2000]), enemy health [1.0, 2.0], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 349 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 350 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 5, victory condition 1
Major Victory
enemy won!
Iteration 351 ended with reward tensor([0]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 1
Iteration 352 ended with reward tensor([0]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 353 ended with reward tensor([0]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 354 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 355 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 356 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 357 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 358 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 359 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 360 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 361 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 362 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 363 ended with reward tensor([2.7000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 364 ended with reward tensor([0.]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 365 ended with reward tensor([2.]), enemy health [1.0, 0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 366 ended with reward tensor([0.4000]), enemy health [1.0, 5.0], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 1
Iteration 367 ended with reward tensor([0.4000]), enemy health [1.0, 2.0], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 368 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [4, 0.0], model VP 0, enemy VP 3, victory condition 1
Iteration 369 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [4, 0.0], model VP 0, enemy VP 4, victory condition 1
Iteration 370 ended with reward tensor([-2.5000]), enemy health [1.0, 0], model health [4, 0.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 371 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 372 ended with reward tensor([0.7000]), enemy health [4, 0], model health [0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 373 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 374 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 375 ended with reward tensor([-2.5000]), enemy health [4, 0], model health [0.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 376 ended with reward tensor([1.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 377 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 378 ended with reward tensor([2.2000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 379 ended with reward tensor([-0.5000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 380 ended with reward tensor([2]), enemy health [1.0, 0], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 381 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 382 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 383 ended with reward tensor([0.9000]), enemy health [4, 8.0], model health [0, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 384 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 385 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 386 ended with reward tensor([0.7000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 387 ended with reward tensor([2]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 388 ended with reward tensor([4.9000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 389 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 390 ended with reward tensor([1.5000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 391 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 392 ended with reward tensor([-1.3000]), enemy health [0, 5.0], model health [0.0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 393 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 394 ended with reward tensor([-1.]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 395 ended with reward tensor([0.]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 396 ended with reward tensor([2.]), enemy health [0, 5.0], model health [4.0, 0.0], model VP 0, enemy VP 4, victory condition 2
Iteration 397 ended with reward tensor([-2.5000]), enemy health [0, 5.0], model health [4.0, 0.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 398 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 399 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 400 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 401 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 4, victory condition 2
Iteration 402 ended with reward tensor([-1.8000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 403 ended with reward tensor([0.2000]), enemy health [4, 8.0], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 404 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 405 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 406 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 407 ended with reward tensor([4.4000]), enemy health [1.0, 8], model health [4.0, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 408 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [4.0, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 409 ended with reward tensor([0.]), enemy health [1.0, 8], model health [4.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 410 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 411 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 412 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [4.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 413 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 414 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [4.0, 0], model VP 0, enemy VP 4, victory condition 1
Iteration 415 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 416 ended with reward tensor([4.9000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 417 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 418 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 419 ended with reward tensor([4.7000]), enemy health [4, 2.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 420 ended with reward tensor([4.9000]), enemy health [0, 2.0], model health [0.0, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 421 ended with reward tensor([2]), enemy health [0, 0], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 422 ended with reward tensor([4.2000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 423 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 424 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 425 ended with reward tensor([0.4000]), enemy health [4, 8], model health [4, 8.0], model VP 0, enemy VP 1, victory condition 2
Iteration 426 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 427 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 428 ended with reward tensor([0]), enemy health [0, 8], model health [2.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 429 ended with reward tensor([0.]), enemy health [0, 8], model health [2.0, 0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 430 ended with reward tensor([0.4000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 431 ended with reward tensor([0]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 432 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 433 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 434 ended with reward tensor([2]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 435 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 436 ended with reward tensor([0.4000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 437 ended with reward tensor([0.9000]), enemy health [0, 5.0], model health [1.0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 438 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 8], model VP 0, enemy VP 4, victory condition 1
Iteration 439 ended with reward tensor([-2.5000]), enemy health [0, 5.0], model health [0, 4.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 440 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 441 ended with reward tensor([0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 442 ended with reward tensor([0.4000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 443 ended with reward tensor([0.4000]), enemy health [4.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 444 ended with reward tensor([-2.5000]), enemy health [4.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 445 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 446 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 447 ended with reward tensor([2.7000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 448 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 449 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 450 ended with reward tensor([4.4000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 451 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 452 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 453 ended with reward tensor([0.7000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 1
Iteration 454 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 455 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 456 ended with reward tensor([4.4000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 457 ended with reward tensor([0]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 1
Iteration 458 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 459 ended with reward tensor([0.2000]), enemy health [0, 6.0], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 460 ended with reward tensor([4.4000]), enemy health [4.0, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 461 ended with reward tensor([2]), enemy health [4.0, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 462 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4.0, 7.0], model VP 0, enemy VP 1, victory condition 1
Iteration 463 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 7.0], model VP 0, enemy VP 2, victory condition 1
Iteration 464 ended with reward tensor([0.7000]), enemy health [2.0, 8], model health [0, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 465 ended with reward tensor([-0.5000]), enemy health [2.0, 8], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 466 ended with reward tensor([2]), enemy health [2.0, 8], model health [0, 0.0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 467 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 1, victory condition 1
Iteration 468 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 469 ended with reward tensor([2.7000]), enemy health [4, 5.0], model health [0, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 470 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 471 ended with reward tensor([5.2000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 472 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 473 ended with reward tensor([2.4000]), enemy health [0, 0], model health [4, 5.0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 474 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [4, 8.0], model VP 0, enemy VP 1, victory condition 1
Iteration 475 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [1.0, 8.0], model VP 0, enemy VP 2, victory condition 1
Iteration 476 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0, 6.0], model VP 0, enemy VP 3, victory condition 1
Iteration 477 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 478 ended with reward tensor([2.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 479 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 480 ended with reward tensor([0.4000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 481 ended with reward tensor([0.7000]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 482 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 483 ended with reward tensor([0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 484 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 485 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 486 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 487 ended with reward tensor([-2.5000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 488 ended with reward tensor([0.2000]), enemy health [4, 8.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 489 ended with reward tensor([0.]), enemy health [4, 8.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 490 ended with reward tensor([2.]), enemy health [4, 8.0], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 491 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 3.0], model VP 0, enemy VP 4, victory condition 1
Iteration 492 ended with reward tensor([-2]), enemy health [4, 7.0], model health [0, 1.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 493 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 494 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 495 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 496 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 497 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 498 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 499 ended with reward tensor([0.4000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 500 ended with reward tensor([-1.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 501 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 502 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 503 ended with reward tensor([-1.]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 2
Iteration 504 ended with reward tensor([-1.]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 3, victory condition 2
Iteration 505 ended with reward tensor([0]), enemy health [0, 8], model health [0.0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 506 ended with reward tensor([2]), enemy health [0, 8], model health [0.0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 507 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 1, victory condition 2
Iteration 508 ended with reward tensor([0.]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 2, victory condition 2
Iteration 509 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 510 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [4, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 511 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 2, victory condition 2
Iteration 512 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 3, victory condition 2
Iteration 513 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 514 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 515 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 516 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 3, victory condition 2
Major Victory
enemy won!
Iteration 517 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4.0, 8.0], model VP 0, enemy VP 1, victory condition 2
Iteration 518 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 8.0], model VP 0, enemy VP 2, victory condition 2
Iteration 519 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 520 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 521 ended with reward tensor([-1.]), enemy health [4, 0.0], model health [0, 2.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 522 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 523 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 524 ended with reward tensor([0.2000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 525 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 526 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 527 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 528 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 529 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 530 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 4.0], model VP 0, enemy VP 2, victory condition 2
Iteration 531 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 4.0], model VP 0, enemy VP 3, victory condition 2
Iteration 532 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0, 3.0], model VP 0, enemy VP 4, victory condition 2
Iteration 533 ended with reward tensor([-2.5000]), enemy health [1.0, 5.0], model health [0, 2.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 534 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 535 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 536 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 537 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 538 ended with reward tensor([-2.3000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 539 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 540 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 541 ended with reward tensor([0.2000]), enemy health [0, 8.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 542 ended with reward tensor([0]), enemy health [0, 8.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 2
Iteration 543 ended with reward tensor([-2]), enemy health [0, 8.0], model health [0, 2.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 544 ended with reward tensor([0]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 1, victory condition 1
Iteration 545 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 546 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 1, victory condition 2
Iteration 547 ended with reward tensor([2.7000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 548 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 549 ended with reward tensor([4.]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 2, victory condition 1
Iteration 550 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 3, victory condition 1
Iteration 551 ended with reward tensor([0]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 4, victory condition 1
Iteration 552 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 553 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 1, victory condition 1
Iteration 554 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [4, 8], model VP 0, enemy VP 2, victory condition 1
Iteration 555 ended with reward tensor([1.4000]), enemy health [4.0, 0], model health [4, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 556 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [4, 8], model VP 0, enemy VP 3, victory condition 1
Iteration 557 ended with reward tensor([-1.6000]), enemy health [0, 0.0], model health [4, 8], model VP 0, enemy VP 3, victory condition 1
Major Victory
enemy won!
Iteration 558 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 559 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 560 ended with reward tensor([2.]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 561 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 562 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 563 ended with reward tensor([0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 564 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 565 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 566 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 567 ended with reward tensor([0.2000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 568 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 569 ended with reward tensor([0.5000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 570 ended with reward tensor([-2.5000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 571 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 572 ended with reward tensor([-0.3000]), enemy health [1.0, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 573 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 574 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 575 ended with reward tensor([4.9000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 576 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 577 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 578 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 579 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 580 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 581 ended with reward tensor([2]), enemy health [1.0, 8], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 582 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 583 ended with reward tensor([0.9000]), enemy health [4, 2.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 584 ended with reward tensor([-1.]), enemy health [4, 2.0], model health [1.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 585 ended with reward tensor([0.2000]), enemy health [1.0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 586 ended with reward tensor([2]), enemy health [1.0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 587 ended with reward tensor([0.4000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 588 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 589 ended with reward tensor([0.7000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 590 ended with reward tensor([0]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 591 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 592 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 593 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 594 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 595 ended with reward tensor([4.9000]), enemy health [4.0, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 596 ended with reward tensor([-1.8000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 597 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 598 ended with reward tensor([0.4000]), enemy health [4, 0], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 599 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 600 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 601 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 602 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 603 ended with reward tensor([-1.]), enemy health [4, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 604 ended with reward tensor([1.5000]), enemy health [4, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 605 ended with reward tensor([0.4000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 606 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 607 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 608 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 609 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 610 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 611 ended with reward tensor([0.9000]), enemy health [0, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 612 ended with reward tensor([4.9000]), enemy health [0, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 613 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 614 ended with reward tensor([-1.3000]), enemy health [0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 615 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 616 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 617 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 618 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 619 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 620 ended with reward tensor([0]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 621 ended with reward tensor([4.5000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 622 ended with reward tensor([-3.]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 623 ended with reward tensor([4.7000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 624 ended with reward tensor([0]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 625 ended with reward tensor([0]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 626 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 627 ended with reward tensor([-2.5000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 628 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 629 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 630 ended with reward tensor([0]), enemy health [1.0, 8], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 631 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 632 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 633 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 634 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 635 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 636 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 637 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 638 ended with reward tensor([-0.5000]), enemy health [0.0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 639 ended with reward tensor([1.5000]), enemy health [0.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 640 ended with reward tensor([2]), enemy health [0.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 641 ended with reward tensor([4.4000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 642 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 643 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 644 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 645 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 646 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 647 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 648 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 649 ended with reward tensor([4.4000]), enemy health [4, 5.0], model health [1.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 650 ended with reward tensor([2.2000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 651 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 652 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 653 ended with reward tensor([2.]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 654 ended with reward tensor([0.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 655 ended with reward tensor([2]), enemy health [0, 0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 656 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 657 ended with reward tensor([0]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 658 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 659 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 660 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 661 ended with reward tensor([0.9000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 662 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [1.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 663 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [1.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 664 ended with reward tensor([-1.6000]), enemy health [1.0, 0], model health [1.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 665 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 666 ended with reward tensor([2.2000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 667 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 668 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 669 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 670 ended with reward tensor([0.4000]), enemy health [0, 5.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 671 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 672 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 673 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 674 ended with reward tensor([-1.]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 675 ended with reward tensor([-1.1000]), enemy health [0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 676 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 677 ended with reward tensor([0.4000]), enemy health [1.0, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 678 ended with reward tensor([0.4000]), enemy health [0, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 679 ended with reward tensor([1.5000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 680 ended with reward tensor([-2.]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 681 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 682 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 683 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 684 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 685 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 686 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 687 ended with reward tensor([0]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 688 ended with reward tensor([0]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 689 ended with reward tensor([-2.5000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 690 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 691 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 692 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 693 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 694 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 695 ended with reward tensor([0.9000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 696 ended with reward tensor([2.]), enemy health [0, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 697 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 698 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 699 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 700 ended with reward tensor([-1.]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 701 ended with reward tensor([-1.]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 702 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 703 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 704 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 705 ended with reward tensor([4.4000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 706 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 707 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 708 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 709 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 710 ended with reward tensor([0]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 711 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 712 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 713 ended with reward tensor([0.2000]), enemy health [0.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 714 ended with reward tensor([-0.5000]), enemy health [0.0, 8], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 715 ended with reward tensor([2]), enemy health [0.0, 8], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 716 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 717 ended with reward tensor([3.7000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 718 ended with reward tensor([3.5000]), enemy health [4, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 719 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 720 ended with reward tensor([-2.5000]), enemy health [4, 0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 721 ended with reward tensor([0.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 722 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 723 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 724 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 725 ended with reward tensor([1.5000]), enemy health [0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 726 ended with reward tensor([3.7000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 727 ended with reward tensor([0.4000]), enemy health [1.0, 5.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 728 ended with reward tensor([0.2000]), enemy health [1.0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 729 ended with reward tensor([2]), enemy health [1.0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 730 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 731 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 732 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 733 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 734 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 735 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 736 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 737 ended with reward tensor([1.2000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 738 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 739 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 740 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 741 ended with reward tensor([2]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 742 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 743 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 744 ended with reward tensor([2.2000]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 745 ended with reward tensor([0.2000]), enemy health [4, 8.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 746 ended with reward tensor([2.2000]), enemy health [1.0, 8.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 747 ended with reward tensor([1.]), enemy health [0, 8.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 748 ended with reward tensor([2]), enemy health [0, 8.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 749 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 750 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 751 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 752 ended with reward tensor([1.]), enemy health [0, 5.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 753 ended with reward tensor([2]), enemy health [0, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 754 ended with reward tensor([4.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 755 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 756 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 757 ended with reward tensor([0.4000]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 758 ended with reward tensor([-1.]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 759 ended with reward tensor([0.4000]), enemy health [1.0, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 760 ended with reward tensor([3.5000]), enemy health [1.0, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 761 ended with reward tensor([-1.1000]), enemy health [0, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 762 ended with reward tensor([4.9000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 763 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [1.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 764 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 765 ended with reward tensor([2]), enemy health [0, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 766 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 767 ended with reward tensor([-1.1000]), enemy health [0, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 768 ended with reward tensor([0.7000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 769 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 770 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 771 ended with reward tensor([1.]), enemy health [0, 8], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 772 ended with reward tensor([-1.3000]), enemy health [0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 773 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 774 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 775 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 776 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 777 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 778 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 779 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 780 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 781 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 782 ended with reward tensor([0]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 783 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 784 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 785 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 786 ended with reward tensor([-1.]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 787 ended with reward tensor([0]), enemy health [0, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 788 ended with reward tensor([-2.5000]), enemy health [0, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 789 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 790 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 791 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 792 ended with reward tensor([1.]), enemy health [0, 6.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 793 ended with reward tensor([-1.3000]), enemy health [0, 4.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 794 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 795 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 796 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 797 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 798 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 799 ended with reward tensor([0.7000]), enemy health [2.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 800 ended with reward tensor([-0.5000]), enemy health [2.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 801 ended with reward tensor([-1.3000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 802 ended with reward tensor([0]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 803 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 804 ended with reward tensor([0.2000]), enemy health [1.0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 805 ended with reward tensor([0.2000]), enemy health [1.0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 806 ended with reward tensor([2]), enemy health [1.0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 807 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 808 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 809 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 810 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 811 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 812 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 813 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 814 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 815 ended with reward tensor([4.4000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 816 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 817 ended with reward tensor([-0.5000]), enemy health [1.0, 0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 818 ended with reward tensor([-1.]), enemy health [0, 0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 819 ended with reward tensor([1.2000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 820 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 821 ended with reward tensor([0.7000]), enemy health [4, 8], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 822 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 823 ended with reward tensor([-1.3000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 824 ended with reward tensor([4.2000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 825 ended with reward tensor([4.4000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 826 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 827 ended with reward tensor([2]), enemy health [4, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 828 ended with reward tensor([0.9000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 829 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 830 ended with reward tensor([0.4000]), enemy health [4.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 831 ended with reward tensor([-1.]), enemy health [4.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 832 ended with reward tensor([-1.6000]), enemy health [0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 833 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 834 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 835 ended with reward tensor([4.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 836 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 837 ended with reward tensor([-1.6000]), enemy health [1.0, 8], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 838 ended with reward tensor([0.7000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 839 ended with reward tensor([0.7000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 840 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 841 ended with reward tensor([0]), enemy health [0, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 842 ended with reward tensor([-1.3000]), enemy health [0, 6.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 843 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 844 ended with reward tensor([0.2000]), enemy health [1.0, 2.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 845 ended with reward tensor([0.2000]), enemy health [0.0, 2.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 846 ended with reward tensor([2]), enemy health [0.0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 847 ended with reward tensor([0.7000]), enemy health [4.0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 848 ended with reward tensor([2]), enemy health [4.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 849 ended with reward tensor([4.4000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 850 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 851 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 852 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 853 ended with reward tensor([2.7000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 854 ended with reward tensor([0.7000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 855 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 856 ended with reward tensor([0.]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 857 ended with reward tensor([-2]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 858 ended with reward tensor([-0.3000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 859 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 860 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 861 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 862 ended with reward tensor([2]), enemy health [4, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 863 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 864 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 865 ended with reward tensor([2]), enemy health [4, 2.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 866 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 867 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 868 ended with reward tensor([-1.]), enemy health [4, 8], model health [4.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 869 ended with reward tensor([-0.1000]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 870 ended with reward tensor([-1.3000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 871 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 872 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 873 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 874 ended with reward tensor([4.7000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 875 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 876 ended with reward tensor([-0.3000]), enemy health [1.0, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 877 ended with reward tensor([1.7000]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 878 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 879 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 880 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 881 ended with reward tensor([0.4000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 882 ended with reward tensor([-1.]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 883 ended with reward tensor([4.4000]), enemy health [4.0, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 884 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 885 ended with reward tensor([-1.3000]), enemy health [1.0, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 886 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 887 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [1.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 888 ended with reward tensor([0]), enemy health [4, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 889 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 890 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 891 ended with reward tensor([2.2000]), enemy health [1.0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 892 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 893 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 894 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 895 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 896 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 897 ended with reward tensor([-1.3000]), enemy health [0, 4.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 898 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 899 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 900 ended with reward tensor([0.2000]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 901 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 902 ended with reward tensor([0.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 903 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 904 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 905 ended with reward tensor([-1.3000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 906 ended with reward tensor([3.5000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 907 ended with reward tensor([3.]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 908 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 909 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 910 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 911 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 912 ended with reward tensor([-1.6000]), enemy health [0, 0], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 913 ended with reward tensor([-1.]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 914 ended with reward tensor([2.7000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 915 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 916 ended with reward tensor([-0.3000]), enemy health [4.0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 917 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 918 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 919 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 920 ended with reward tensor([-2.5000]), enemy health [0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 921 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 922 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 923 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 924 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 925 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 926 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 927 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 928 ended with reward tensor([-2.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 929 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 930 ended with reward tensor([0.7000]), enemy health [2.0, 8], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 931 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 932 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 933 ended with reward tensor([0.4000]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 934 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 935 ended with reward tensor([2.7000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 936 ended with reward tensor([1.5000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 937 ended with reward tensor([-2.]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 938 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 939 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 940 ended with reward tensor([2.2000]), enemy health [0.0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 941 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 942 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 943 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 944 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 945 ended with reward tensor([2.2000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 946 ended with reward tensor([-2.5000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 947 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 948 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [3.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 949 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 950 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 951 ended with reward tensor([-1.3000]), enemy health [4.0, 7.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 952 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 953 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 954 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 955 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 956 ended with reward tensor([0.]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 957 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 958 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 959 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 960 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 961 ended with reward tensor([0]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 962 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 963 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 964 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 965 ended with reward tensor([-1.]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 966 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 967 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 968 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 969 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 970 ended with reward tensor([3.5000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 971 ended with reward tensor([4.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 972 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 973 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 974 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 975 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 976 ended with reward tensor([0.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 977 ended with reward tensor([0.7000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 978 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 979 ended with reward tensor([-1.3000]), enemy health [0, 3.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 980 ended with reward tensor([0.4000]), enemy health [4.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 981 ended with reward tensor([2.2000]), enemy health [4.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 982 ended with reward tensor([4.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 983 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 984 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 985 ended with reward tensor([-1.]), enemy health [0, 0.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 986 ended with reward tensor([4.2000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 987 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 988 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 989 ended with reward tensor([1.]), enemy health [0.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 990 ended with reward tensor([2]), enemy health [0.0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 991 ended with reward tensor([3.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 992 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 993 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 994 ended with reward tensor([4.7000]), enemy health [1.0, 2.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 995 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 996 ended with reward tensor([1.5000]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 997 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 998 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 999 ended with reward tensor([5.2000]), enemy health [4.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1000 ended with reward tensor([4.9000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1001 ended with reward tensor([2.7000]), enemy health [0, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1002 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1003 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1004 ended with reward tensor([1.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1005 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1006 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1007 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1008 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1009 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1010 ended with reward tensor([2.]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1011 ended with reward tensor([2]), enemy health [0, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1012 ended with reward tensor([4.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1013 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1014 ended with reward tensor([4.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1015 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1016 ended with reward tensor([-2]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1017 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1018 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1019 ended with reward tensor([2]), enemy health [4.0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1020 ended with reward tensor([4.7000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1021 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1022 ended with reward tensor([4.4000]), enemy health [4, 2.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1023 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1024 ended with reward tensor([-0.5000]), enemy health [4.0, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1025 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1026 ended with reward tensor([-1.3000]), enemy health [3.0, 2.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1027 ended with reward tensor([2.7000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1028 ended with reward tensor([1.5000]), enemy health [0, 8.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1029 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1030 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1031 ended with reward tensor([3.7000]), enemy health [4, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1032 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1033 ended with reward tensor([4.2000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1034 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1035 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1036 ended with reward tensor([4.4000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1037 ended with reward tensor([4.4000]), enemy health [0, 5.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1038 ended with reward tensor([1.5000]), enemy health [0, 5.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1039 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1040 ended with reward tensor([4.4000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1041 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1042 ended with reward tensor([1.5000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1043 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1044 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1045 ended with reward tensor([4.2000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1046 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1047 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1048 ended with reward tensor([-0.3000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1049 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1050 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1051 ended with reward tensor([4.2000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1052 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1053 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1054 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1055 ended with reward tensor([4.2000]), enemy health [1.0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1056 ended with reward tensor([4.4000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1057 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1058 ended with reward tensor([0.9000]), enemy health [0, 8.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1059 ended with reward tensor([1.5000]), enemy health [0, 8.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1060 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1061 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1062 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1063 ended with reward tensor([4.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1064 ended with reward tensor([1.5000]), enemy health [4, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1065 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1066 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1067 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1068 ended with reward tensor([0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1069 ended with reward tensor([1.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1070 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1071 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1072 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1073 ended with reward tensor([2.7000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1074 ended with reward tensor([0.7000]), enemy health [4, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1075 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1076 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1077 ended with reward tensor([4.4000]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1078 ended with reward tensor([4.]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1079 ended with reward tensor([-1.]), enemy health [4, 0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1080 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1081 ended with reward tensor([0.7000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1082 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1083 ended with reward tensor([-0.5000]), enemy health [1.0, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1084 ended with reward tensor([1.]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1085 ended with reward tensor([-2.]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1086 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1087 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1088 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1089 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1090 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1091 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1092 ended with reward tensor([2.]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1093 ended with reward tensor([2]), enemy health [0, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1094 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1095 ended with reward tensor([0.7000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1096 ended with reward tensor([2.7000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1097 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1098 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1099 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1100 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1101 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1102 ended with reward tensor([0.]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1103 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1104 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1105 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1106 ended with reward tensor([0.4000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1107 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1108 ended with reward tensor([1.9000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1109 ended with reward tensor([2.5000]), enemy health [0, 8], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1110 ended with reward tensor([2]), enemy health [0, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1111 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1112 ended with reward tensor([0]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1113 ended with reward tensor([0.]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1114 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1115 ended with reward tensor([2]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1116 ended with reward tensor([0.2000]), enemy health [4, 8.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1117 ended with reward tensor([0.4000]), enemy health [4, 8.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1118 ended with reward tensor([2]), enemy health [4, 8.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1119 ended with reward tensor([3.7000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1120 ended with reward tensor([2.7000]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1121 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1122 ended with reward tensor([0.2000]), enemy health [4.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1123 ended with reward tensor([2]), enemy health [4.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1124 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1125 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1126 ended with reward tensor([0.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1127 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1128 ended with reward tensor([-0.1000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1129 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1130 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1131 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1132 ended with reward tensor([-1.3000]), enemy health [1.0, 8.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1133 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1134 ended with reward tensor([-0.3000]), enemy health [0, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1135 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1136 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1137 ended with reward tensor([0.9000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1138 ended with reward tensor([0.2000]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1139 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1140 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1141 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1142 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1143 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1144 ended with reward tensor([-0.5000]), enemy health [1.0, 5.0], model health [3.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1145 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1146 ended with reward tensor([1.2000]), enemy health [1.0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1147 ended with reward tensor([0.2000]), enemy health [0, 8], model health [1.0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1148 ended with reward tensor([0]), enemy health [0, 8], model health [1.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1149 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [1.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1150 ended with reward tensor([-2]), enemy health [0, 6.0], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1151 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1152 ended with reward tensor([0.9000]), enemy health [1.0, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1153 ended with reward tensor([1.2000]), enemy health [1.0, 5.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1154 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1155 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1156 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1157 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1158 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1159 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1160 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1161 ended with reward tensor([0]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1162 ended with reward tensor([0.5000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1163 ended with reward tensor([0]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1164 ended with reward tensor([0]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1165 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1166 ended with reward tensor([-0.3000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1167 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1168 ended with reward tensor([-1.]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1169 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1170 ended with reward tensor([-1.]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1171 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [1.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1172 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1173 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1174 ended with reward tensor([-1.3000]), enemy health [2.0, 5.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1175 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1176 ended with reward tensor([0.2000]), enemy health [4.0, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1177 ended with reward tensor([0.2000]), enemy health [1.0, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1178 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1179 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1180 ended with reward tensor([0.]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1181 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1182 ended with reward tensor([0]), enemy health [0, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1183 ended with reward tensor([-2.5000]), enemy health [0, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1184 ended with reward tensor([0.9000]), enemy health [4, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1185 ended with reward tensor([3.]), enemy health [4, 0], model health [4.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1186 ended with reward tensor([3.]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1187 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1188 ended with reward tensor([0.5000]), enemy health [4, 0], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1189 ended with reward tensor([0.7000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1190 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1191 ended with reward tensor([1.]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1192 ended with reward tensor([4.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1193 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1194 ended with reward tensor([3.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1195 ended with reward tensor([0.9000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1196 ended with reward tensor([-1.3000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1197 ended with reward tensor([0]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1198 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1199 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1200 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1201 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1202 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1203 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1204 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1205 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1206 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1207 ended with reward tensor([2.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1208 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1209 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1210 ended with reward tensor([0.9000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1211 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1212 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1213 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1214 ended with reward tensor([2.]), enemy health [4, 8], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1215 ended with reward tensor([2.]), enemy health [4, 8], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1216 ended with reward tensor([2]), enemy health [4, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1217 ended with reward tensor([4.9000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1218 ended with reward tensor([4.4000]), enemy health [0, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1219 ended with reward tensor([2.]), enemy health [0, 2.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1220 ended with reward tensor([2.2000]), enemy health [0, 2.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1221 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1222 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1223 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1224 ended with reward tensor([0.2000]), enemy health [0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1225 ended with reward tensor([5.2000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1226 ended with reward tensor([3.5000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1227 ended with reward tensor([2.]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1228 ended with reward tensor([2.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1229 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1230 ended with reward tensor([4.9000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1231 ended with reward tensor([-0.3000]), enemy health [4, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1232 ended with reward tensor([1.9000]), enemy health [0, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1233 ended with reward tensor([0.]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1234 ended with reward tensor([0.2000]), enemy health [0.0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1235 ended with reward tensor([2.5000]), enemy health [0.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1236 ended with reward tensor([4.4000]), enemy health [4, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1237 ended with reward tensor([-1.6000]), enemy health [0, 0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1238 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1239 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1240 ended with reward tensor([0.7000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1241 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1242 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1243 ended with reward tensor([3.7000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1244 ended with reward tensor([-0.1000]), enemy health [0, 8.0], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1245 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1246 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1247 ended with reward tensor([-1.3000]), enemy health [0, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1248 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1249 ended with reward tensor([4.9000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1250 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1251 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1252 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1253 ended with reward tensor([4.4000]), enemy health [1.0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1254 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1255 ended with reward tensor([1.]), enemy health [0.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1256 ended with reward tensor([2]), enemy health [0.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1257 ended with reward tensor([4.]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1258 ended with reward tensor([4.2000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1259 ended with reward tensor([2.7000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1260 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1261 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1262 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1263 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1264 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1265 ended with reward tensor([-2.5000]), enemy health [0, 8.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1266 ended with reward tensor([4.7000]), enemy health [1.0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1267 ended with reward tensor([2.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1268 ended with reward tensor([4.]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1269 ended with reward tensor([4.4000]), enemy health [4, 2.0], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1270 ended with reward tensor([-1.]), enemy health [4, 2.0], model health [1.0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1271 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1272 ended with reward tensor([-0.5000]), enemy health [4, 1.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1273 ended with reward tensor([2]), enemy health [4, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1274 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1275 ended with reward tensor([2.7000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1276 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1277 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1278 ended with reward tensor([4.4000]), enemy health [4, 0], model health [4.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1279 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1280 ended with reward tensor([-1.]), enemy health [0.0, 0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1281 ended with reward tensor([-0.3000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1282 ended with reward tensor([2.2000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1283 ended with reward tensor([2.2000]), enemy health [1.0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1284 ended with reward tensor([0.7000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1285 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1286 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1287 ended with reward tensor([0.9000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1288 ended with reward tensor([3.]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1289 ended with reward tensor([0.4000]), enemy health [0, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1290 ended with reward tensor([2.2000]), enemy health [0, 2.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1291 ended with reward tensor([2]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1292 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1293 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1294 ended with reward tensor([2]), enemy health [1.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1295 ended with reward tensor([0.4000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1296 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1297 ended with reward tensor([4.4000]), enemy health [0.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1298 ended with reward tensor([2]), enemy health [0.0, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1299 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1300 ended with reward tensor([3.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1301 ended with reward tensor([4.9000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1302 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1303 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1304 ended with reward tensor([4.7000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1305 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1306 ended with reward tensor([3.5000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1307 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1308 ended with reward tensor([-1.3000]), enemy health [0, 8.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1309 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1310 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1311 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1312 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1313 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1314 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1315 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1316 ended with reward tensor([-2.5000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1317 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1318 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1319 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1320 ended with reward tensor([2]), enemy health [1.0, 0.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1321 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1322 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1323 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1324 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1325 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1326 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1327 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1328 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1329 ended with reward tensor([0.4000]), enemy health [0.0, 8], model health [4, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1330 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1331 ended with reward tensor([-1.6000]), enemy health [0.0, 0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1332 ended with reward tensor([4.4000]), enemy health [4, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1333 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1334 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1335 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1336 ended with reward tensor([-1.3000]), enemy health [2.0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1337 ended with reward tensor([0]), enemy health [4, 8], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1338 ended with reward tensor([2.2000]), enemy health [4, 8], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1339 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1340 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1341 ended with reward tensor([-1.3000]), enemy health [4, 4.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1342 ended with reward tensor([0.4000]), enemy health [0.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1343 ended with reward tensor([2]), enemy health [0.0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1344 ended with reward tensor([0.2000]), enemy health [0, 8], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1345 ended with reward tensor([0]), enemy health [0, 8], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1346 ended with reward tensor([0.5000]), enemy health [0, 8], model health [4.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1347 ended with reward tensor([0.9000]), enemy health [0, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1348 ended with reward tensor([1.5000]), enemy health [0, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1349 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1350 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1351 ended with reward tensor([0.2000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1352 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1353 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1354 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1355 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1356 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1357 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [4, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1358 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1359 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1360 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1361 ended with reward tensor([0.]), enemy health [4, 8], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1362 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1363 ended with reward tensor([0.]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1364 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1365 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1366 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1367 ended with reward tensor([0.5000]), enemy health [0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1368 ended with reward tensor([2.5000]), enemy health [0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1369 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1370 ended with reward tensor([4.2000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1371 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1372 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1373 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1374 ended with reward tensor([0.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1375 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1376 ended with reward tensor([2.]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1377 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1378 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1379 ended with reward tensor([5.]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1380 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1381 ended with reward tensor([-0.5000]), enemy health [0.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1382 ended with reward tensor([0.5000]), enemy health [0.0, 5.0], model health [3.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1383 ended with reward tensor([0.5000]), enemy health [0.0, 5.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1384 ended with reward tensor([0.9000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1385 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1386 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1387 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1388 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1389 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1390 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1391 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1392 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1393 ended with reward tensor([-2.5000]), enemy health [4, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1394 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1395 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1396 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1397 ended with reward tensor([2]), enemy health [4, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1398 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1399 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1400 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1401 ended with reward tensor([0.9000]), enemy health [4.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1402 ended with reward tensor([0.7000]), enemy health [0.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1403 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1404 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1405 ended with reward tensor([-2.5000]), enemy health [0.0, 6.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1406 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1407 ended with reward tensor([0.2000]), enemy health [1.0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1408 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1409 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1410 ended with reward tensor([3.5000]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1411 ended with reward tensor([-1.6000]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1412 ended with reward tensor([0]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1413 ended with reward tensor([4.7000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1414 ended with reward tensor([2.2000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1415 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1416 ended with reward tensor([-2]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1417 ended with reward tensor([1.2000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1418 ended with reward tensor([2.5000]), enemy health [1.0, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1419 ended with reward tensor([2.7000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1420 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1421 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1422 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1423 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1424 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1425 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1426 ended with reward tensor([1.2000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1427 ended with reward tensor([0.]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1428 ended with reward tensor([0.]), enemy health [0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1429 ended with reward tensor([2.5000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1430 ended with reward tensor([0.5000]), enemy health [0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1431 ended with reward tensor([1.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1432 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1433 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1434 ended with reward tensor([-0.5000]), enemy health [4, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1435 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1436 ended with reward tensor([0.4000]), enemy health [4, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1437 ended with reward tensor([4.9000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1438 ended with reward tensor([3.5000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1439 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1440 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1441 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1442 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1443 ended with reward tensor([2.7000]), enemy health [1.0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1444 ended with reward tensor([1.]), enemy health [1.0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1445 ended with reward tensor([-1.]), enemy health [0.0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1446 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1447 ended with reward tensor([4.9000]), enemy health [0, 5.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1448 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1449 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1450 ended with reward tensor([0.7000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1451 ended with reward tensor([4.5000]), enemy health [0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1452 ended with reward tensor([4.]), enemy health [0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1453 ended with reward tensor([0.9000]), enemy health [0, 5.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1454 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1455 ended with reward tensor([5.2000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1456 ended with reward tensor([5.4000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1457 ended with reward tensor([0.7000]), enemy health [1.0, 8], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1458 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1459 ended with reward tensor([-1.3000]), enemy health [1.0, 7.0], model health [0.0, 8], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1460 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1461 ended with reward tensor([4.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1462 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1463 ended with reward tensor([3.5000]), enemy health [4, 5.0], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1464 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1465 ended with reward tensor([0.5000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1466 ended with reward tensor([4.]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1467 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1468 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1469 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1470 ended with reward tensor([0.2000]), enemy health [4, 8.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1471 ended with reward tensor([2]), enemy health [4, 8.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1472 ended with reward tensor([4.7000]), enemy health [4, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1473 ended with reward tensor([2.5000]), enemy health [4, 8], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1474 ended with reward tensor([2.]), enemy health [4, 8], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1475 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1476 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1477 ended with reward tensor([-0.5000]), enemy health [1.0, 8], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1478 ended with reward tensor([2]), enemy health [1.0, 8], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1479 ended with reward tensor([1.4000]), enemy health [1.0, 5.0], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1480 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1481 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1482 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1483 ended with reward tensor([-1.3000]), enemy health [1.0, 2.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1484 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1485 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1486 ended with reward tensor([4.7000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1487 ended with reward tensor([4.9000]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1488 ended with reward tensor([4.]), enemy health [0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1489 ended with reward tensor([2.]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1490 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1491 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [1.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1492 ended with reward tensor([0.4000]), enemy health [4, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1493 ended with reward tensor([-1.6000]), enemy health [0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1494 ended with reward tensor([0.4000]), enemy health [4, 5.0], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1495 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1496 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1497 ended with reward tensor([0.2000]), enemy health [1.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1498 ended with reward tensor([2]), enemy health [1.0, 0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1499 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1500 ended with reward tensor([1.2000]), enemy health [1.0, 8], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1501 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1502 ended with reward tensor([0.2000]), enemy health [4, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1503 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1504 ended with reward tensor([0.9000]), enemy health [4.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1505 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1506 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1507 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1508 ended with reward tensor([0.7000]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1509 ended with reward tensor([2.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1510 ended with reward tensor([0]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1511 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1512 ended with reward tensor([-1.3000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1513 ended with reward tensor([0.4000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1514 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1515 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1516 ended with reward tensor([2]), enemy health [4, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1517 ended with reward tensor([0.9000]), enemy health [1.0, 8], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1518 ended with reward tensor([4.2000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1519 ended with reward tensor([-0.5000]), enemy health [0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1520 ended with reward tensor([2.]), enemy health [0, 2.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1521 ended with reward tensor([2]), enemy health [0, 2.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1522 ended with reward tensor([0.2000]), enemy health [4, 8.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1523 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1524 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1525 ended with reward tensor([0.9000]), enemy health [4, 8.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1526 ended with reward tensor([2.2000]), enemy health [4, 8.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1527 ended with reward tensor([2]), enemy health [4, 8.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1528 ended with reward tensor([0.2000]), enemy health [4, 8], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1529 ended with reward tensor([2]), enemy health [4, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1530 ended with reward tensor([0.7000]), enemy health [4.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1531 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1532 ended with reward tensor([0.7000]), enemy health [3.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1533 ended with reward tensor([0.7000]), enemy health [2.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1534 ended with reward tensor([-1.]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1535 ended with reward tensor([0.]), enemy health [4, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1536 ended with reward tensor([0.2000]), enemy health [0, 8], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1537 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1538 ended with reward tensor([0.4000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1539 ended with reward tensor([3.5000]), enemy health [1.0, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1540 ended with reward tensor([4.9000]), enemy health [0.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1541 ended with reward tensor([3.]), enemy health [0.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1542 ended with reward tensor([1.]), enemy health [0.0, 8], model health [1.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1543 ended with reward tensor([0.9000]), enemy health [4, 5.0], model health [4.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1544 ended with reward tensor([2.7000]), enemy health [0, 5.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1545 ended with reward tensor([2.]), enemy health [0, 5.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1546 ended with reward tensor([0]), enemy health [0, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1547 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1548 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1549 ended with reward tensor([2.5000]), enemy health [4, 2.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1550 ended with reward tensor([0]), enemy health [4, 2.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1551 ended with reward tensor([2.5000]), enemy health [4, 2.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1552 ended with reward tensor([2]), enemy health [4, 2.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1553 ended with reward tensor([4.4000]), enemy health [1.0, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1554 ended with reward tensor([4.7000]), enemy health [1.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1555 ended with reward tensor([4.9000]), enemy health [0.0, 8], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1556 ended with reward tensor([4.]), enemy health [0.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1557 ended with reward tensor([2.5000]), enemy health [0.0, 8], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1558 ended with reward tensor([4.7000]), enemy health [4, 8], model health [1.0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1559 ended with reward tensor([2.2000]), enemy health [0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1560 ended with reward tensor([1.5000]), enemy health [0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1561 ended with reward tensor([2]), enemy health [0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1562 ended with reward tensor([0.4000]), enemy health [4, 8], model health [4, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1563 ended with reward tensor([4.9000]), enemy health [0, 8], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1564 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1565 ended with reward tensor([2]), enemy health [0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1566 ended with reward tensor([4.7000]), enemy health [1.0, 8], model health [0, 8], model VP 0, enemy VP 0, victory condition 1
Iteration 1567 ended with reward tensor([1.5000]), enemy health [1.0, 8], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1568 ended with reward tensor([2]), enemy health [1.0, 8], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1569 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 8], model VP 0, enemy VP 0, victory condition 2
Iteration 1570 ended with reward tensor([0.2000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1571 ended with reward tensor([-0.5000]), enemy health [4, 2.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1572 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1573 ended with reward tensor([-1.]), enemy health [4, 0.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
