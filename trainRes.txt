Model units:
Name: Commander Farsight, Army Type: Tau
Name: Breacher Team, Army Type: Tau
Enemy units:
Name: Commander Farsight, Army Type: Tau
Name: Breacher Team, Army Type: Tau
Number of Lifetimes ran: 400

Iteration 0 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 1 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 2 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8, 9.0]
Iteration 3 ended with reward tensor([0.2000]), enemy health [0, 9], model health [8, 9.0]
Iteration 4 ended with reward tensor([0.5000]), enemy health [0, 9], model health [8, 9.0]
Iteration 5 ended with reward tensor([0.2000]), enemy health [0, 8.0], model health [5.0, 9.0]
Iteration 6 ended with reward tensor([0.]), enemy health [0, 8.0], model health [5.0, 9.0]
Iteration 7 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [1.0, 9.0]
Iteration 8 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [0.0, 9.0]
Iteration 9 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [0.0, 8.0]
Iteration 10 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 8.0]
Iteration 11 ended with reward tensor([-0.5000]), enemy health [0, 4.0], model health [0.0, 8.0]
Iteration 12 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 5.0]
Iteration 13 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0.0, 3.0]
Iteration 14 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [0.0, 0]
enemy won!
Iteration 15 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 16 ended with reward tensor([0.]), enemy health [8, 9], model health [6.0, 7.0]
Iteration 17 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 7.0]
Iteration 18 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [0, 7.0]
Iteration 19 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0, 7.0]
Iteration 20 ended with reward tensor([0]), enemy health [8, 9.0], model health [0, 4.0]
Iteration 21 ended with reward tensor([0]), enemy health [8, 9.0], model health [0, 3.0]
Iteration 22 ended with reward tensor([0]), enemy health [8, 9.0], model health [0, 2.0]
Iteration 23 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0, 2.0]
Iteration 24 ended with reward tensor([0]), enemy health [7.0, 9.0], model health [0, 2.0]
Iteration 25 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0, 2.0]
Iteration 26 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0, 2.0]
Iteration 27 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 28 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 29 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 30 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 31 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 32 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [1.0, 9]
Iteration 33 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 34 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 6.0]
Iteration 35 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 6.0]
Iteration 36 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 6.0]
Iteration 37 ended with reward tensor([0]), enemy health [7.0, 9], model health [0, 3.0]
Iteration 38 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 3.0]
Iteration 39 ended with reward tensor([0]), enemy health [7.0, 9], model health [0, 3.0]
Iteration 40 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 0.0]
enemy won!
Iteration 41 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 42 ended with reward tensor([0.]), enemy health [7.0, 9], model health [8, 9]
Iteration 43 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 7.0]
Iteration 44 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [5.0, 5.0]
Iteration 45 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 46 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 47 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 48 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 49 ended with reward tensor([0.2000]), enemy health [8, 9], model health [5.0, 9]
Iteration 50 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 51 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 9]
Iteration 52 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 9]
Iteration 53 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 9]
Iteration 54 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0.0, 9]
Iteration 55 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0.0, 6.0]
Iteration 56 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 5.0]
Iteration 57 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 5.0]
Iteration 58 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 5.0]
Iteration 59 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 5.0]
Iteration 60 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 5.0]
Iteration 61 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 4.0]
Iteration 62 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 3.0]
Iteration 63 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 3.0]
Iteration 64 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0.0, 3.0]
Iteration 65 ended with reward tensor([0]), enemy health [0.0, 9.0], model health [0.0, 1.0]
Iteration 66 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 67 ended with reward tensor([0.4000]), enemy health [8, 8.0], model health [3.0, 9]
Iteration 68 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [0, 9]
Iteration 69 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [0, 9.0]
Iteration 70 ended with reward tensor([0.2000]), enemy health [6.0, 8.0], model health [0, 9.0]
Iteration 71 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0, 9.0]
Iteration 72 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0, 9.0]
Iteration 73 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 9.0]
Iteration 74 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 9.0]
Iteration 75 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 8.0]
Iteration 76 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0, 8.0]
Iteration 77 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 8.0]
Iteration 78 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0, 8.0]
Iteration 79 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0, 7.0]
Iteration 80 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 6.0]
Iteration 81 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 4.0]
Iteration 82 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 3.0]
Iteration 83 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 1.0]
model won!
Iteration 84 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 9]
Iteration 85 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [6.0, 9]
Iteration 86 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [2.0, 9]
Iteration 87 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 88 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 89 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 90 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 91 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 6.0]
Iteration 92 ended with reward tensor([-0.5000]), enemy health [5.0, 7.0], model health [0.0, 4.0]
Iteration 93 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 3.0]
Iteration 94 ended with reward tensor([0]), enemy health [5.0, 5.0], model health [0.0, 1.0]
Iteration 95 ended with reward tensor([-0.5000]), enemy health [5.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 96 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 97 ended with reward tensor([0.2000]), enemy health [8, 9], model health [8, 9]
Iteration 98 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 9.0]
Iteration 99 ended with reward tensor([1.4000]), enemy health [3.0, 9], model health [5.0, 9.0]
Iteration 100 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [5.0, 9.0]
Iteration 101 ended with reward tensor([0.4000]), enemy health [0.0, 6.0], model health [5.0, 9.0]
Iteration 102 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [3.0, 7.0]
Iteration 103 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [3.0, 6.0]
Iteration 104 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [2.0, 6.0]
Iteration 105 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [2.0, 3.0]
Iteration 106 ended with reward tensor([1.2000]), enemy health [0.0, 5.0], model health [2.0, 2.0]
Iteration 107 ended with reward tensor([0.2000]), enemy health [0.0, 4.0], model health [1.0, 2.0]
Iteration 108 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 109 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [0.0, 1.0]
Iteration 110 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 111 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9]
Iteration 112 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 9]
Iteration 113 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 6.0]
Iteration 114 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 6.0]
Iteration 115 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0.0, 6.0]
Iteration 116 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 117 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 118 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 119 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 120 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 121 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 122 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 123 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 124 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 125 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 126 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 127 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 128 ended with reward tensor([1.]), enemy health [0, 9], model health [0.0, 6.0]
Iteration 129 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 6.0]
Iteration 130 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 5.0]
Iteration 131 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 132 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0]
enemy won!
Iteration 133 ended with reward tensor([0.5000]), enemy health [8, 9], model health [7.0, 9]
Iteration 134 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [7.0, 9]
Iteration 135 ended with reward tensor([0.4000]), enemy health [6.0, 8.0], model health [7.0, 8.0]
Iteration 136 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [5.0, 8.0]
Iteration 137 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [5.0, 8.0]
Iteration 138 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [4.0, 8.0]
Iteration 139 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [3.0, 8.0]
Iteration 140 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [3.0, 8.0]
Iteration 141 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [3.0, 8.0]
Iteration 142 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [1.0, 8.0]
Iteration 143 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [0.0, 8.0]
Iteration 144 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [0.0, 8.0]
Iteration 145 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 5.0]
Iteration 146 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 147 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 148 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 2.0]
Iteration 149 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 150 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 151 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [6.0, 6.0]
Iteration 152 ended with reward tensor([1.]), enemy health [0, 9], model health [5.0, 3.0]
Iteration 153 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [2.0, 3.0]
Iteration 154 ended with reward tensor([0]), enemy health [0, 7.0], model health [2.0, 2.0]
Iteration 155 ended with reward tensor([0]), enemy health [0, 7.0], model health [2.0, 0]
Iteration 156 ended with reward tensor([0.2000]), enemy health [0, 7.0], model health [2.0, 0]
Iteration 157 ended with reward tensor([-1.]), enemy health [0, 7.0], model health [0.0, 0]
enemy won!
Iteration 158 ended with reward tensor([0.2000]), enemy health [8, 9], model health [5.0, 9]
Iteration 159 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [1.0, 9]
Iteration 160 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0.0, 9]
Iteration 161 ended with reward tensor([-0.5000]), enemy health [7.0, 9.0], model health [0.0, 9]
Iteration 162 ended with reward tensor([0.7000]), enemy health [6.0, 9.0], model health [0.0, 9]
Iteration 163 ended with reward tensor([-0.5000]), enemy health [6.0, 9.0], model health [0.0, 9.0]
Iteration 164 ended with reward tensor([-0.5000]), enemy health [6.0, 9.0], model health [0.0, 6.0]
Iteration 165 ended with reward tensor([-0.5000]), enemy health [6.0, 9.0], model health [0.0, 6.0]
Iteration 166 ended with reward tensor([-0.5000]), enemy health [6.0, 9.0], model health [0.0, 6.0]
Iteration 167 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 6.0]
Iteration 168 ended with reward tensor([-0.5000]), enemy health [5.0, 9.0], model health [0.0, 6.0]
Iteration 169 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 6.0]
Iteration 170 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0.0, 6.0]
Iteration 171 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 172 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 173 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 174 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 175 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 176 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 177 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 178 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 5.0]
Iteration 179 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 2.0]
Iteration 180 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 2.0]
Iteration 181 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 1.0]
Iteration 182 ended with reward tensor([1.]), enemy health [0, 9.0], model health [0.0, 1.0]
Iteration 183 ended with reward tensor([-0.5000]), enemy health [0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 184 ended with reward tensor([0.2000]), enemy health [8, 9], model health [4.0, 9]
Iteration 185 ended with reward tensor([0.7000]), enemy health [8, 9], model health [4.0, 7.0]
Iteration 186 ended with reward tensor([0.2000]), enemy health [5.0, 9.0], model health [4.0, 5.0]
Iteration 187 ended with reward tensor([-0.5000]), enemy health [5.0, 9.0], model health [1.0, 5.0]
Iteration 188 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0, 5.0]
Iteration 189 ended with reward tensor([-0.5000]), enemy health [5.0, 6.0], model health [0, 5.0]
Iteration 190 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 191 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0, 1.0]
Iteration 192 ended with reward tensor([-1.]), enemy health [4.0, 5.0], model health [0, 0.0]
enemy won!
Iteration 193 ended with reward tensor([0.5000]), enemy health [8, 9], model health [7.0, 9]
Iteration 194 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [5.0, 9]
Iteration 195 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [5.0, 9.0]
Iteration 196 ended with reward tensor([-1.]), enemy health [8, 8.0], model health [3.0, 9.0]
Iteration 197 ended with reward tensor([0.7000]), enemy health [8.0, 7.0], model health [3.0, 8.0]
Iteration 198 ended with reward tensor([-0.5000]), enemy health [8.0, 7.0], model health [2.0, 8.0]
Iteration 199 ended with reward tensor([-0.5000]), enemy health [8.0, 7.0], model health [1.0, 8.0]
Iteration 200 ended with reward tensor([-0.5000]), enemy health [8.0, 7.0], model health [0.0, 8.0]
Iteration 201 ended with reward tensor([0.2000]), enemy health [3.0, 7.0], model health [0.0, 8.0]
Iteration 202 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [0.0, 8.0]
Iteration 203 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 8.0]
Iteration 204 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 8.0]
Iteration 205 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 7.0]
Iteration 206 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 4.0]
Iteration 207 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 208 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 209 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [8, 8.0]
Iteration 210 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [3.0, 8.0]
Iteration 211 ended with reward tensor([0.4000]), enemy health [5.0, 8.0], model health [1.0, 8.0]
Iteration 212 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 8.0]
Iteration 213 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 214 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 215 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 216 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0, 2.0]
Iteration 217 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0, 2.0]
Iteration 218 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0, 2.0]
Iteration 219 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0, 2.0]
Iteration 220 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0, 2.0]
Iteration 221 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0, 2.0]
Iteration 222 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0, 2.0]
Iteration 223 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0, 2.0]
Iteration 224 ended with reward tensor([-1.]), enemy health [1.0, 8.0], model health [0, 0]
enemy won!
Iteration 225 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 9.0]
Iteration 226 ended with reward tensor([0.4000]), enemy health [8, 9.0], model health [8, 8.0]
Iteration 227 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [3.0, 8.0]
Iteration 228 ended with reward tensor([-0.5000]), enemy health [8, 5.0], model health [3.0, 8.0]
Iteration 229 ended with reward tensor([-0.5000]), enemy health [8, 5.0], model health [3.0, 7.0]
Iteration 230 ended with reward tensor([-0.5000]), enemy health [8, 5.0], model health [3.0, 3.0]
Iteration 231 ended with reward tensor([-0.5000]), enemy health [8, 5.0], model health [0.0, 3.0]
Iteration 232 ended with reward tensor([0]), enemy health [8, 5.0], model health [0.0, 1.0]
Iteration 233 ended with reward tensor([-1.]), enemy health [8, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 234 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 235 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9.0]
Iteration 236 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 9.0]
Iteration 237 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 238 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 239 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 240 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 241 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 242 ended with reward tensor([0]), enemy health [1.0, 9], model health [0.0, 4.0]
Iteration 243 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 2.0]
Iteration 244 ended with reward tensor([-1.]), enemy health [1.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 245 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 246 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 247 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [3.0, 9]
Iteration 248 ended with reward tensor([0.9000]), enemy health [8, 7.0], model health [3.0, 9.0]
Iteration 249 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0, 9.0]
Iteration 250 ended with reward tensor([-0.5000]), enemy health [7.0, 7.0], model health [0.0, 9.0]
Iteration 251 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0.0, 8.0]
Iteration 252 ended with reward tensor([-0.5000]), enemy health [7.0, 7.0], model health [0.0, 5.0]
Iteration 253 ended with reward tensor([0]), enemy health [7.0, 7.0], model health [0.0, 3.0]
Iteration 254 ended with reward tensor([0]), enemy health [7.0, 7.0], model health [0.0, 3.0]
Iteration 255 ended with reward tensor([-1.]), enemy health [7.0, 7.0], model health [0.0, 0]
enemy won!
Iteration 256 ended with reward tensor([0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 257 ended with reward tensor([0.9000]), enemy health [8, 9.0], model health [5.0, 9]
Iteration 258 ended with reward tensor([0.7000]), enemy health [6.0, 9.0], model health [1.0, 9]
Iteration 259 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 9]
Iteration 260 ended with reward tensor([-0.5000]), enemy health [5.0, 9.0], model health [0.0, 9]
Iteration 261 ended with reward tensor([-0.5000]), enemy health [5.0, 9.0], model health [0.0, 9]
Iteration 262 ended with reward tensor([-0.5000]), enemy health [5.0, 9.0], model health [0.0, 6.0]
Iteration 263 ended with reward tensor([-0.5000]), enemy health [5.0, 9.0], model health [0.0, 5.0]
Iteration 264 ended with reward tensor([-1.]), enemy health [5.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 265 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 266 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 267 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 9]
Iteration 268 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8.0, 9]
Iteration 269 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [8.0, 9]
Iteration 270 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [6.0, 9]
Iteration 271 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 272 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 273 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 274 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 275 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 276 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 6.0]
Iteration 277 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 6.0]
Iteration 278 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 6.0]
Iteration 279 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 5.0]
Iteration 280 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 5.0]
Iteration 281 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 5.0]
Iteration 282 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 283 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 4.0]
Iteration 284 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 4.0]
Iteration 285 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 286 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 287 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 288 ended with reward tensor([0]), enemy health [0.0, 6.0], model health [0.0, 1.0]
Iteration 289 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 290 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [1.0, 9]
Iteration 291 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [1.0, 8.0]
Iteration 292 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [1.0, 7.0]
Iteration 293 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 7.0]
Iteration 294 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 4.0]
Iteration 295 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 3.0]
Iteration 296 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 3.0]
Iteration 297 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 2.0]
Iteration 298 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 2.0]
Iteration 299 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 2.0]
Iteration 300 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0.0, 2.0]
Iteration 301 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 1.0]
Iteration 302 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 1.0]
Iteration 303 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 1.0]
Iteration 304 ended with reward tensor([-1.5000]), enemy health [2.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 305 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 306 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 307 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 9.0]
Iteration 308 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 9.0]
Iteration 309 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 9.0]
Iteration 310 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 9.0]
Iteration 311 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 9.0]
Iteration 312 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 9.0]
Iteration 313 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 5.0]
Iteration 314 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 5.0]
Iteration 315 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 5.0]
Iteration 316 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 5.0]
Iteration 317 ended with reward tensor([-0.5000]), enemy health [6.0, 7.0], model health [0.0, 5.0]
Iteration 318 ended with reward tensor([-0.5000]), enemy health [6.0, 7.0], model health [0.0, 5.0]
Iteration 319 ended with reward tensor([0]), enemy health [6.0, 7.0], model health [0.0, 2.0]
Iteration 320 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 2.0]
Iteration 321 ended with reward tensor([0]), enemy health [5.0, 7.0], model health [0.0, 2.0]
Iteration 322 ended with reward tensor([-1.]), enemy health [5.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 323 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 324 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 8.0]
Iteration 325 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [2.0, 8.0]
Iteration 326 ended with reward tensor([0.7000]), enemy health [8.0, 8.0], model health [0.0, 8.0]
Iteration 327 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0.0, 8.0]
Iteration 328 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0.0, 8.0]
Iteration 329 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0.0, 6.0]
Iteration 330 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0.0, 6.0]
Iteration 331 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 5.0]
Iteration 332 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 5.0]
Iteration 333 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0.0, 5.0]
Iteration 334 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0.0, 5.0]
Iteration 335 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 5.0]
Iteration 336 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 5.0]
Iteration 337 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 5.0]
Iteration 338 ended with reward tensor([0]), enemy health [2.0, 8.0], model health [0.0, 3.0]
Iteration 339 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 3.0]
Iteration 340 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 3.0]
Iteration 341 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 3.0]
Iteration 342 ended with reward tensor([-1.]), enemy health [2.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 343 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 344 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 345 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [5.0, 9]
Iteration 346 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [5.0, 3.0]
Iteration 347 ended with reward tensor([0]), enemy health [8, 9.0], model health [3.0, 3.0]
Iteration 348 ended with reward tensor([0]), enemy health [8, 9.0], model health [0, 3.0]
Iteration 349 ended with reward tensor([0]), enemy health [8, 9.0], model health [0, 3.0]
Iteration 350 ended with reward tensor([0]), enemy health [8, 9.0], model health [0, 3.0]
Iteration 351 ended with reward tensor([-1.]), enemy health [8, 9.0], model health [0, 0.0]
enemy won!
Iteration 352 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 353 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 9]
Iteration 354 ended with reward tensor([0.7000]), enemy health [0, 9], model health [5.0, 6.0]
Iteration 355 ended with reward tensor([0.5000]), enemy health [0, 9], model health [5.0, 6.0]
Iteration 356 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0.0, 6.0]
Iteration 357 ended with reward tensor([0.2000]), enemy health [0, 8.0], model health [0.0, 6.0]
Iteration 358 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 2.0]
Iteration 359 ended with reward tensor([-1.]), enemy health [0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 360 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 361 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 9.0]
Iteration 362 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [8, 9.0]
Iteration 363 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [8, 9.0]
Iteration 364 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [5.0, 6.0]
Iteration 365 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 6.0]
Iteration 366 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 6.0]
Iteration 367 ended with reward tensor([-0.5000]), enemy health [5.0, 7.0], model health [0.0, 6.0]
Iteration 368 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 6.0]
Iteration 369 ended with reward tensor([-0.5000]), enemy health [5.0, 7.0], model health [0.0, 5.0]
Iteration 370 ended with reward tensor([-0.5000]), enemy health [5.0, 7.0], model health [0.0, 5.0]
Iteration 371 ended with reward tensor([-0.5000]), enemy health [5.0, 7.0], model health [0.0, 5.0]
Iteration 372 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 5.0]
Iteration 373 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 374 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 375 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 376 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 377 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 378 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 379 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 380 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 381 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 382 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 383 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 384 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 5.0]
Iteration 385 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 5.0]
Iteration 386 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0.0, 4.0]
Iteration 387 ended with reward tensor([-0.5000]), enemy health [2.0, 7.0], model health [0.0, 3.0]
Iteration 388 ended with reward tensor([-0.5000]), enemy health [2.0, 7.0], model health [0.0, 3.0]
Iteration 389 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 3.0]
Iteration 390 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 3.0]
Iteration 391 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 3.0]
Iteration 392 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 3.0]
Iteration 393 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 2.0]
Iteration 394 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 2.0]
Iteration 395 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 396 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 397 ended with reward tensor([0.9000]), enemy health [8, 6.0], model health [4.0, 9]
Iteration 398 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 9]
Iteration 399 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 8.0]
Iteration 400 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 8.0]
Iteration 401 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 7.0]
Iteration 402 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 7.0]
Iteration 403 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 4.0]
Iteration 404 ended with reward tensor([0]), enemy health [1.0, 6.0], model health [0.0, 2.0]
Iteration 405 ended with reward tensor([-1.]), enemy health [1.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 406 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 407 ended with reward tensor([0.]), enemy health [8, 9], model health [0, 9]
Iteration 408 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0, 9.0]
Iteration 409 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0, 9.0]
Iteration 410 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0, 7.0]
Iteration 411 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0.0, 4.0]
Iteration 412 ended with reward tensor([-1.]), enemy health [8, 7.0], model health [0.0, 0]
enemy won!
Iteration 413 ended with reward tensor([0.4000]), enemy health [8, 8.0], model health [8, 9]
Iteration 414 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [5.0, 7.0]
Iteration 415 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 7.0]
Iteration 416 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 7.0]
Iteration 417 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0.0, 6.0]
Iteration 418 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 4.0]
Iteration 419 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0.0, 2.0]
Iteration 420 ended with reward tensor([-1.]), enemy health [3.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 421 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 422 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 423 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 9]
Iteration 424 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [8, 9]
Iteration 425 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [3.0, 9]
Iteration 426 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [1.0, 9]
Iteration 427 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 9]
Iteration 428 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 7.0]
Iteration 429 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 7.0]
Iteration 430 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 4.0]
Iteration 431 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 4.0]
Iteration 432 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 4.0]
Iteration 433 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0.0, 4.0]
Iteration 434 ended with reward tensor([-0.5000]), enemy health [7.0, 6.0], model health [0.0, 4.0]
Iteration 435 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0.0, 4.0]
Iteration 436 ended with reward tensor([-0.5000]), enemy health [7.0, 6.0], model health [0.0, 4.0]
Iteration 437 ended with reward tensor([0]), enemy health [7.0, 6.0], model health [0.0, 1.0]
Iteration 438 ended with reward tensor([0]), enemy health [7.0, 6.0], model health [0.0, 1.0]
Iteration 439 ended with reward tensor([-1.]), enemy health [7.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 440 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 441 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 9]
Iteration 442 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [8, 9]
Iteration 443 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [8, 8.0]
Iteration 444 ended with reward tensor([0.2000]), enemy health [2.0, 7.0], model health [2.0, 8.0]
Iteration 445 ended with reward tensor([-0.5000]), enemy health [2.0, 7.0], model health [0, 8.0]
Iteration 446 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0, 8.0]
Iteration 447 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 8.0]
Iteration 448 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 8.0]
Iteration 449 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 8.0]
Iteration 450 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 8.0]
Iteration 451 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0.0, 8.0]
Iteration 452 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0.0, 8.0]
Iteration 453 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0.0, 5.0]
Iteration 454 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 455 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 2.0]
model won!
Iteration 456 ended with reward tensor([0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 457 ended with reward tensor([0.9000]), enemy health [8, 9.0], model health [2.0, 9.0]
Iteration 458 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [1.0, 9.0]
Iteration 459 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [1.0, 9.0]
Iteration 460 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 9.0]
Iteration 461 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 9.0]
Iteration 462 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 9.0]
Iteration 463 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 9.0]
Iteration 464 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 8.0]
Iteration 465 ended with reward tensor([0]), enemy health [8, 7.0], model health [0.0, 3.0]
Iteration 466 ended with reward tensor([-1.]), enemy health [8, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 467 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 468 ended with reward tensor([0.2000]), enemy health [4.0, 8.0], model health [8, 9]
Iteration 469 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [6.0, 8.0]
Iteration 470 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [6.0, 8.0]
Iteration 471 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [2.0, 8.0]
Iteration 472 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 8.0]
Iteration 473 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 8.0]
Iteration 474 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 8.0]
Iteration 475 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 8.0]
Iteration 476 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 5.0]
Iteration 477 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 5.0]
Iteration 478 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 2.0]
Iteration 479 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 1.0]
Iteration 480 ended with reward tensor([-1.]), enemy health [1.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 481 ended with reward tensor([0.5000]), enemy health [8, 9], model health [6.0, 9]
Iteration 482 ended with reward tensor([0.]), enemy health [8, 9], model health [6.0, 4.0]
Iteration 483 ended with reward tensor([0.]), enemy health [8, 9], model health [6.0, 4.0]
Iteration 484 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [6.0, 4.0]
Iteration 485 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [6.0, 4.0]
Iteration 486 ended with reward tensor([-1.]), enemy health [1.0, 9], model health [6.0, 4.0]
Iteration 487 ended with reward tensor([0.4000]), enemy health [1.0, 9.0], model health [6.0, 4.0]
Iteration 488 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 489 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 490 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 491 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 492 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 493 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 494 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 4.0]
Iteration 495 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 1.0]
Iteration 496 ended with reward tensor([-1.5000]), enemy health [1.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 497 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 498 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 499 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 500 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 501 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 502 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 503 ended with reward tensor([0]), enemy health [2.0, 9], model health [0.0, 3.0]
Iteration 504 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 1.0]
Iteration 505 ended with reward tensor([0]), enemy health [2.0, 8.0], model health [0.0, 1.0]
Iteration 506 ended with reward tensor([-1.]), enemy health [2.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 507 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [2.0, 9]
Iteration 508 ended with reward tensor([0.2000]), enemy health [8, 6.0], model health [0, 9]
Iteration 509 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0, 8.0]
Iteration 510 ended with reward tensor([-0.5000]), enemy health [7.0, 6.0], model health [0, 6.0]
Iteration 511 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [0, 6.0]
Iteration 512 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [0, 6.0]
Iteration 513 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0, 6.0]
Iteration 514 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0, 6.0]
Iteration 515 ended with reward tensor([-0.5000]), enemy health [5.0, 6.0], model health [0, 6.0]
Iteration 516 ended with reward tensor([-0.5000]), enemy health [5.0, 6.0], model health [0, 6.0]
Iteration 517 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 518 ended with reward tensor([-0.5000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 519 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 520 ended with reward tensor([-0.5000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 521 ended with reward tensor([-0.5000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 522 ended with reward tensor([-0.5000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 523 ended with reward tensor([-0.5000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 524 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 525 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 526 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 527 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 528 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 529 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 530 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 5.0]
Iteration 531 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 2.0]
Iteration 532 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 2.0]
Iteration 533 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 2.0]
Iteration 534 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0, 2.0]
Iteration 535 ended with reward tensor([-0.5000]), enemy health [2.0, 6.0], model health [0, 2.0]
Iteration 536 ended with reward tensor([-1.]), enemy health [2.0, 6.0], model health [0, 0]
enemy won!
Iteration 537 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 9]
Iteration 538 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [1.0, 6.0]
Iteration 539 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [0, 6.0]
Iteration 540 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0, 6.0]
Iteration 541 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 6.0]
Iteration 542 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 6.0]
Iteration 543 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 3.0]
Iteration 544 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 545 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 546 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 547 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 548 ended with reward tensor([-1.]), enemy health [4.0, 9], model health [0, 0]
enemy won!
Iteration 549 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [8, 8.0]
Iteration 550 ended with reward tensor([0.]), enemy health [8, 9.0], model health [8, 8.0]
Iteration 551 ended with reward tensor([-1.]), enemy health [8, 9.0], model health [8, 8.0]
Iteration 552 ended with reward tensor([0.4000]), enemy health [8, 9.0], model health [8, 6.0]
Iteration 553 ended with reward tensor([-0.6000]), enemy health [6.0, 9.0], model health [8, 6.0]
Iteration 554 ended with reward tensor([-0.5000]), enemy health [6.0, 9.0], model health [4.0, 6.0]
Iteration 555 ended with reward tensor([-0.5000]), enemy health [6.0, 9.0], model health [3.0, 5.0]
Iteration 556 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 557 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 558 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 559 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 4.0]
Iteration 560 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0.0, 3.0]
Iteration 561 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0.0, 2.0]
Iteration 562 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0.0, 1.0]
Iteration 563 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0.0, 1.0]
Iteration 564 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0.0, 1.0]
Iteration 565 ended with reward tensor([-1.]), enemy health [5.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 566 ended with reward tensor([0]), enemy health [8, 9], model health [8.0, 9]
Iteration 567 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [8.0, 8.0]
Iteration 568 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [4.0, 8.0]
Iteration 569 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [3.0, 8.0]
Iteration 570 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 8.0]
Iteration 571 ended with reward tensor([0]), enemy health [2.0, 9], model health [0, 4.0]
Iteration 572 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 3.0]
Iteration 573 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 3.0]
Iteration 574 ended with reward tensor([-1.]), enemy health [2.0, 9], model health [0, 0.0]
enemy won!
Iteration 575 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 576 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 8.0]
Iteration 577 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 8.0]
Iteration 578 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 8.0]
Iteration 579 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 7.0]
Iteration 580 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 6.0]
Iteration 581 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 6.0]
Iteration 582 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [0.0, 3.0]
Iteration 583 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0.0, 2.0]
Iteration 584 ended with reward tensor([-1.]), enemy health [8, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 585 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 586 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [2.0, 9]
Iteration 587 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 588 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 589 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 590 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 9]
Iteration 591 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 9]
Iteration 592 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 9]
Iteration 593 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 594 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 595 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 596 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 597 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 598 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 599 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 600 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 9]
Iteration 601 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 8.0]
Iteration 602 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 8.0]
Iteration 603 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 7.0]
Iteration 604 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 7.0]
Iteration 605 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 7.0]
Iteration 606 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 5.0]
Iteration 607 ended with reward tensor([0]), enemy health [0.0, 8.0], model health [0.0, 2.0]
Iteration 608 ended with reward tensor([0]), enemy health [0.0, 8.0], model health [0.0, 2.0]
Iteration 609 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 610 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 611 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [6.0, 9]
Iteration 612 ended with reward tensor([0.4000]), enemy health [8, 7.0], model health [6.0, 8.0]
Iteration 613 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [1.0, 8.0]
Iteration 614 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0, 6.0]
Iteration 615 ended with reward tensor([-0.5000]), enemy health [8, 7.0], model health [0, 4.0]
Iteration 616 ended with reward tensor([0]), enemy health [8, 7.0], model health [0, 2.0]
Iteration 617 ended with reward tensor([0]), enemy health [8, 7.0], model health [0, 1.0]
Iteration 618 ended with reward tensor([-1.]), enemy health [8, 7.0], model health [0, 0]
enemy won!
Iteration 619 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [7.0, 9]
Iteration 620 ended with reward tensor([0.9000]), enemy health [8, 6.0], model health [7.0, 9]
Iteration 621 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [5.0, 9.0]
Iteration 622 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [4.0, 9.0]
Iteration 623 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [2.0, 8.0]
Iteration 624 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 8.0]
Iteration 625 ended with reward tensor([-0.5000]), enemy health [3.0, 5.0], model health [0.0, 8.0]
Iteration 626 ended with reward tensor([-0.5000]), enemy health [3.0, 5.0], model health [0.0, 8.0]
Iteration 627 ended with reward tensor([-0.5000]), enemy health [3.0, 5.0], model health [0.0, 5.0]
Iteration 628 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 5.0]
Iteration 629 ended with reward tensor([1.]), enemy health [0.0, 5.0], model health [0.0, 5.0]
Iteration 630 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [0.0, 2.0]
Iteration 631 ended with reward tensor([-1.]), enemy health [0.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 632 ended with reward tensor([-0.3000]), enemy health [8, 9.0], model health [8, 9]
Iteration 633 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [5.0, 9]
Iteration 634 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [3.0, 9]
Iteration 635 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 636 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 637 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 638 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 639 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [0.0, 9]
Iteration 640 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0.0, 9]
Iteration 641 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0.0, 9.0]
Iteration 642 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 9.0]
Iteration 643 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 644 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 645 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 6.0]
Iteration 646 ended with reward tensor([1.]), enemy health [0, 8.0], model health [0.0, 6.0]
Iteration 647 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 3.0]
Iteration 648 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 2.0]
Iteration 649 ended with reward tensor([-1.]), enemy health [0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 650 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 651 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 652 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [0, 9]
Iteration 653 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0, 9]
Iteration 654 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0, 9.0]
Iteration 655 ended with reward tensor([0.7000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 656 ended with reward tensor([0.7000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 657 ended with reward tensor([-0.5000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 658 ended with reward tensor([-0.5000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 659 ended with reward tensor([-0.5000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 660 ended with reward tensor([0.7000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 661 ended with reward tensor([-0.5000]), enemy health [8.0, 9.0], model health [0, 9.0]
Iteration 662 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0, 9.0]
Iteration 663 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0, 8.0]
Iteration 664 ended with reward tensor([-0.5000]), enemy health [7.0, 9.0], model health [0, 7.0]
Iteration 665 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0, 7.0]
Iteration 666 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0, 7.0]
Iteration 667 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 7.0]
Iteration 668 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 7.0]
Iteration 669 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0, 7.0]
Iteration 670 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0, 7.0]
Iteration 671 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0, 7.0]
Iteration 672 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 5.0]
Iteration 673 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0, 5.0]
Iteration 674 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 3.0]
Iteration 675 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 2.0]
Iteration 676 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 1.0]
Iteration 677 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0, 0.0]
enemy won!
Iteration 678 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 679 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8.0, 9]
Iteration 680 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8.0, 6.0]
Iteration 681 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8.0, 6.0]
Iteration 682 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 6.0]
Iteration 683 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [5.0, 6.0]
Iteration 684 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 685 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 686 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 687 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 688 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 689 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 690 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 6.0]
Iteration 691 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 692 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 693 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 3.0]
Iteration 694 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 3.0]
Iteration 695 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 2.0]
Iteration 696 ended with reward tensor([-0.5000]), enemy health [0.0, 2.0], model health [0, 2.0]
Iteration 697 ended with reward tensor([-0.5000]), enemy health [0.0, 2.0], model health [0, 1.0]
Iteration 698 ended with reward tensor([-1.]), enemy health [0.0, 2.0], model health [0, 0.0]
enemy won!
Iteration 699 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 700 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [8, 9.0]
Iteration 701 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [8, 6.0]
Iteration 702 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [8, 6.0]
Iteration 703 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [3.0, 6.0]
Iteration 704 ended with reward tensor([-0.3000]), enemy health [3.0, 8.0], model health [3.0, 3.0]
Iteration 705 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 3.0]
Iteration 706 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 2.0]
Iteration 707 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 2.0]
Iteration 708 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 2.0]
Iteration 709 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 2.0]
Iteration 710 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 2.0]
Iteration 711 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 712 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 713 ended with reward tensor([0.7000]), enemy health [8, 9], model health [6.0, 9]
Iteration 714 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 715 ended with reward tensor([-0.3000]), enemy health [4.0, 9], model health [5.0, 6.0]
Iteration 716 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [5.0, 6.0]
Iteration 717 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [5.0, 6.0]
Iteration 718 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [5.0, 5.0]
Iteration 719 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [5.0, 5.0]
Iteration 720 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [5.0, 5.0]
Iteration 721 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [5.0, 5.0]
Iteration 722 ended with reward tensor([0.2000]), enemy health [0, 9], model health [5.0, 4.0]
Iteration 723 ended with reward tensor([0]), enemy health [0, 9], model health [5.0, 3.0]
Iteration 724 ended with reward tensor([0.]), enemy health [0, 9], model health [5.0, 1.0]
Iteration 725 ended with reward tensor([0.2000]), enemy health [0, 9.0], model health [0, 1.0]
Iteration 726 ended with reward tensor([-1.]), enemy health [0, 9.0], model health [0, 0.0]
enemy won!
Iteration 727 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [7.0, 9]
Iteration 728 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9]
Iteration 729 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [4.0, 9.0]
Iteration 730 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9.0]
Iteration 731 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 732 ended with reward tensor([0]), enemy health [5.0, 9], model health [0.0, 3.0]
Iteration 733 ended with reward tensor([-1.]), enemy health [5.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 734 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8, 9]
Iteration 735 ended with reward tensor([0.5000]), enemy health [2.0, 9], model health [8, 9]
Iteration 736 ended with reward tensor([0]), enemy health [0, 9], model health [8.0, 9]
Iteration 737 ended with reward tensor([0.5000]), enemy health [0, 9], model health [8.0, 9]
Iteration 738 ended with reward tensor([0]), enemy health [0, 9], model health [8.0, 9]
Iteration 739 ended with reward tensor([0]), enemy health [0, 9], model health [8.0, 9]
Iteration 740 ended with reward tensor([0]), enemy health [0, 9], model health [8.0, 9]
Iteration 741 ended with reward tensor([0]), enemy health [0, 9], model health [8.0, 9]
Iteration 742 ended with reward tensor([0.2000]), enemy health [0, 9.0], model health [5.0, 9]
Iteration 743 ended with reward tensor([-0.5000]), enemy health [0, 9.0], model health [5.0, 8.0]
Iteration 744 ended with reward tensor([-1.]), enemy health [0, 9.0], model health [5.0, 8.0]
Iteration 745 ended with reward tensor([-0.5000]), enemy health [0, 9.0], model health [0, 5.0]
Iteration 746 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0, 4.0]
Iteration 747 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 3.0]
Iteration 748 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 2.0]
Iteration 749 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [0, 0.0]
enemy won!
Iteration 750 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 751 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 752 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 753 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 8.0]
Iteration 754 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [6.0, 7.0]
Iteration 755 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [2.0, 7.0]
Iteration 756 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [1.0, 7.0]
Iteration 757 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 758 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 759 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 760 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 761 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 762 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 763 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 764 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 765 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 766 ended with reward tensor([1.]), enemy health [0, 9], model health [0, 7.0]
Iteration 767 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 3.0]
Iteration 768 ended with reward tensor([0]), enemy health [0, 7.0], model health [0, 2.0]
Iteration 769 ended with reward tensor([-1.]), enemy health [0, 7.0], model health [0, 0.0]
enemy won!
Iteration 770 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 771 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 772 ended with reward tensor([0.4000]), enemy health [3.0, 5.0], model health [5.0, 7.0]
Iteration 773 ended with reward tensor([-0.5000]), enemy health [3.0, 5.0], model health [5.0, 6.0]
Iteration 774 ended with reward tensor([0.4000]), enemy health [1.0, 5.0], model health [5.0, 4.0]
Iteration 775 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0, 4.0]
Iteration 776 ended with reward tensor([-0.5000]), enemy health [1.0, 5.0], model health [0.0, 4.0]
Iteration 777 ended with reward tensor([0]), enemy health [1.0, 5.0], model health [0.0, 2.0]
Iteration 778 ended with reward tensor([-1.]), enemy health [1.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 779 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 780 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 781 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 7.0]
Iteration 782 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 6.0]
Iteration 783 ended with reward tensor([0.2000]), enemy health [8.0, 9], model health [6.0, 4.0]
Iteration 784 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [6.0, 4.0]
Iteration 785 ended with reward tensor([0.9000]), enemy health [5.0, 9.0], model health [2.0, 4.0]
Iteration 786 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0, 4.0]
Iteration 787 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0, 4.0]
Iteration 788 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 789 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 790 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9]
Iteration 791 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 9]
Iteration 792 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 9]
Iteration 793 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 9]
Iteration 794 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [3.0, 9]
Iteration 795 ended with reward tensor([0.9000]), enemy health [0.0, 9.0], model health [3.0, 8.0]
Iteration 796 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [3.0, 8.0]
Iteration 797 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [3.0, 8.0]
Iteration 798 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 8.0]
Iteration 799 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 7.0]
Iteration 800 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 801 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 802 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 5.0]
Iteration 803 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 804 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 805 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 806 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0.0, 1.0]
Iteration 807 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 808 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 809 ended with reward tensor([-0.3000]), enemy health [8, 9.0], model health [8, 9]
Iteration 810 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [8, 9.0]
Iteration 811 ended with reward tensor([0.9000]), enemy health [3.0, 9.0], model health [8, 5.0]
Iteration 812 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [8, 5.0]
Iteration 813 ended with reward tensor([0.4000]), enemy health [0.0, 9.0], model health [5.0, 5.0]
Iteration 814 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0.0, 5.0]
Iteration 815 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 2.0]
Iteration 816 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 817 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 818 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 2.0]
Iteration 819 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [4.0, 2.0]
Iteration 820 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [1.0, 2.0]
Iteration 821 ended with reward tensor([0]), enemy health [2.0, 9], model health [0.0, 2.0]
Iteration 822 ended with reward tensor([-1.]), enemy health [2.0, 9], model health [0.0, 0]
enemy won!
Iteration 823 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 824 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [4.0, 9]
Iteration 825 ended with reward tensor([0.9000]), enemy health [6.0, 9.0], model health [4.0, 7.0]
Iteration 826 ended with reward tensor([-0.6000]), enemy health [6.0, 9.0], model health [4.0, 5.0]
Iteration 827 ended with reward tensor([0]), enemy health [6.0, 9.0], model health [2.0, 3.0]
Iteration 828 ended with reward tensor([0]), enemy health [6.0, 9.0], model health [0.0, 2.0]
Iteration 829 ended with reward tensor([-1.]), enemy health [6.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 830 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 831 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 832 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 833 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 834 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 835 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [8, 7.0]
Iteration 836 ended with reward tensor([0.4000]), enemy health [3.0, 8.0], model health [8, 4.0]
Iteration 837 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [5.0, 4.0]
Iteration 838 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 4.0]
Iteration 839 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 4.0]
Iteration 840 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 3.0]
Iteration 841 ended with reward tensor([-1.]), enemy health [2.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 842 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 8.0]
Iteration 843 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0.0, 7.0]
Iteration 844 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 7.0]
Iteration 845 ended with reward tensor([0]), enemy health [5.0, 9], model health [0.0, 4.0]
Iteration 846 ended with reward tensor([-1.]), enemy health [5.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 847 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 848 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [2.0, 9]
Iteration 849 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 9]
Iteration 850 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 851 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 6.0]
Iteration 852 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 4.0]
Iteration 853 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 854 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 855 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 856 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 857 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 858 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 9.0]
Iteration 859 ended with reward tensor([-0.3000]), enemy health [4.0, 9.0], model health [8.0, 9.0]
Iteration 860 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [7.0, 6.0]
Iteration 861 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [2.0, 6.0]
Iteration 862 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [2.0, 6.0]
Iteration 863 ended with reward tensor([0]), enemy health [4.0, 9.0], model health [0, 4.0]
Iteration 864 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 3.0]
Iteration 865 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 3.0]
Iteration 866 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 3.0]
Iteration 867 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 2.0]
Iteration 868 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 2.0]
Iteration 869 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 2.0]
Iteration 870 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0, 2.0]
Iteration 871 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 872 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 873 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 874 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 875 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 876 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 877 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0, 2.0]
Iteration 878 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0, 2.0]
Iteration 879 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0, 2.0]
Iteration 880 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0, 2.0]
Iteration 881 ended with reward tensor([-1.]), enemy health [2.0, 9.0], model health [0, 0]
enemy won!
Iteration 882 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 883 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 884 ended with reward tensor([0.2000]), enemy health [8, 6.0], model health [2.0, 8.0]
Iteration 885 ended with reward tensor([0.7000]), enemy health [8.0, 6.0], model health [1.0, 8.0]
Iteration 886 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [1.0, 8.0]
Iteration 887 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [-7.0, 8.0]
Iteration 888 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [-7.0, 8.0]
Iteration 889 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [-7.0, 8.0]
Iteration 890 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [-7.0, 8.0]
Iteration 891 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [0.0, 8.0]
Iteration 892 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [0.0, 3.0]
Iteration 893 ended with reward tensor([0]), enemy health [6.0, 6.0], model health [0.0, 1.0]
Iteration 894 ended with reward tensor([-1.]), enemy health [6.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 895 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 896 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 9]
Iteration 897 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 9]
Iteration 898 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 899 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [2.0, 9]
Iteration 900 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 901 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 902 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 903 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 904 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [8, 9]
Iteration 905 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [8, 9.0]
Iteration 906 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [2.0, 9.0]
Iteration 907 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0, 9.0]
Iteration 908 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 909 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 910 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 911 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 912 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 6.0]
Iteration 913 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 6.0]
Iteration 914 ended with reward tensor([1.]), enemy health [0, 6.0], model health [0.0, 6.0]
Iteration 915 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 3.0]
Iteration 916 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 2.0]
Iteration 917 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 2.0]
Iteration 918 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 2.0]
Iteration 919 ended with reward tensor([-1.]), enemy health [0, 1.0], model health [0.0, 0.0]
enemy won!
Iteration 920 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 921 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 922 ended with reward tensor([0.2000]), enemy health [6.0, 8.0], model health [0.0, 8.0]
Iteration 923 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 8.0]
Iteration 924 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 8.0]
Iteration 925 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 8.0]
Iteration 926 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 8.0]
Iteration 927 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 5.0]
Iteration 928 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 5.0]
Iteration 929 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 5.0]
Iteration 930 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 5.0]
Iteration 931 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 932 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 933 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 4.0]
Iteration 934 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 3.0]
Iteration 935 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 2.0]
Iteration 936 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 2.0]
Iteration 937 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 2.0]
Iteration 938 ended with reward tensor([-1.]), enemy health [4.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 939 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8, 8.0]
Iteration 940 ended with reward tensor([0.2000]), enemy health [7.0, 7.0], model health [6.0, 8.0]
Iteration 941 ended with reward tensor([0.4000]), enemy health [3.0, 7.0], model health [2.0, 8.0]
Iteration 942 ended with reward tensor([0.4000]), enemy health [1.0, 7.0], model health [2.0, 8.0]
Iteration 943 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [0.0, 8.0]
Iteration 944 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 8.0]
Iteration 945 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 8.0]
Iteration 946 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 7.0]
Iteration 947 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 4.0]
Iteration 948 ended with reward tensor([1.]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 949 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 950 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 951 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 1.0]
Iteration 952 ended with reward tensor([-1.]), enemy health [0.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 953 ended with reward tensor([0]), enemy health [8, 9], model health [8.0, 9]
Iteration 954 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [4.0, 7.0]
Iteration 955 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 7.0]
Iteration 956 ended with reward tensor([-1.]), enemy health [8, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 957 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 958 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 959 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 960 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 961 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 5.0]
Iteration 962 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 5.0]
Iteration 963 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 5.0]
Iteration 964 ended with reward tensor([0]), enemy health [2.0, 8.0], model health [0.0, 2.0]
Iteration 965 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 966 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 967 ended with reward tensor([0.9000]), enemy health [1.0, 9], model health [8, 9]
Iteration 968 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [7.0, 9]
Iteration 969 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [4.0, 9]
Iteration 970 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [3.0, 9]
Iteration 971 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 972 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 973 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 974 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 975 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 976 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 977 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 978 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 979 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 980 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 981 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 982 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 983 ended with reward tensor([1.]), enemy health [0, 9], model health [0.0, 5.0]
Iteration 984 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 985 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [8, 9]
Iteration 986 ended with reward tensor([-0.3000]), enemy health [0.0, 9], model health [8, 9.0]
Iteration 987 ended with reward tensor([0.2000]), enemy health [0.0, 9.0], model health [8, 9.0]
Iteration 988 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [1.0, 9.0]
Iteration 989 ended with reward tensor([1.2000]), enemy health [0.0, 8.0], model health [0, 9.0]
Iteration 990 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 8.0]
Iteration 991 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 7.0]
Iteration 992 ended with reward tensor([0]), enemy health [0.0, 8.0], model health [0, 1.0]
Iteration 993 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 994 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 995 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 7.0]
Iteration 996 ended with reward tensor([-1.]), enemy health [1.0, 9], model health [8, 4.0]
Iteration 997 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [4.0, 4.0]
Iteration 998 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 999 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 1000 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 1001 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 2.0]
Iteration 1002 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 2.0]
Iteration 1003 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0, 0]
enemy won!
Iteration 1004 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [7.0, 9]
Iteration 1005 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9]
Iteration 1006 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 8.0]
Iteration 1007 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 6.0]
Iteration 1008 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 5.0]
Iteration 1009 ended with reward tensor([0]), enemy health [8, 9], model health [0, 1.0]
Iteration 1010 ended with reward tensor([-1.]), enemy health [8, 9], model health [0, 0]
enemy won!
Iteration 1011 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [8, 9]
Iteration 1012 ended with reward tensor([0.2000]), enemy health [6.0, 9.0], model health [8, 4.0]
Iteration 1013 ended with reward tensor([0]), enemy health [6.0, 9.0], model health [8, 2.0]
Iteration 1014 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [5.0, 2.0]
Iteration 1015 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [1.0, 2.0]
Iteration 1016 ended with reward tensor([0.2000]), enemy health [1.0, 9.0], model health [0, 2.0]
Iteration 1017 ended with reward tensor([0.2000]), enemy health [1.0, 9.0], model health [0, 2.0]
Iteration 1018 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0, 1.0]
Iteration 1019 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0, 1.0]
Iteration 1020 ended with reward tensor([-1.]), enemy health [1.0, 9.0], model health [0, 0.0]
enemy won!
Iteration 1021 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1022 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1023 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 1024 ended with reward tensor([-1.]), enemy health [8, 9], model health [5.0, 9]
Iteration 1025 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 1026 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 1027 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [1.0, 9]
Iteration 1028 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [0, 9]
Iteration 1029 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 1030 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 5.0]
Iteration 1031 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0.0, 5.0]
Iteration 1032 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0.0, 0]
enemy won!
Iteration 1033 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1034 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [6.0, 9]
Iteration 1035 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [3.0, 6.0]
Iteration 1036 ended with reward tensor([0.4000]), enemy health [0, 9], model health [3.0, 6.0]
Iteration 1037 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 5.0]
Iteration 1038 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 5.0]
Iteration 1039 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1040 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1041 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [8, 9]
Iteration 1042 ended with reward tensor([-1.]), enemy health [5.0, 9], model health [8.0, 9]
Iteration 1043 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [5.0, 8.0]
Iteration 1044 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [5.0, 6.0]
Iteration 1045 ended with reward tensor([0.]), enemy health [0.0, 9], model health [5.0, 5.0]
Iteration 1046 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [5.0, 3.0]
Iteration 1047 ended with reward tensor([0]), enemy health [0.0, 9], model health [5.0, 2.0]
Iteration 1048 ended with reward tensor([0]), enemy health [0.0, 9], model health [5.0, 2.0]
Iteration 1049 ended with reward tensor([0]), enemy health [0.0, 9], model health [5.0, 0.0]
Iteration 1050 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [5.0, 0.0]
Iteration 1051 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0]
enemy won!
Iteration 1052 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1053 ended with reward tensor([-0.3000]), enemy health [8, 9], model health [8.0, 8.0]
Iteration 1054 ended with reward tensor([-0.3000]), enemy health [6.0, 9], model health [8.0, 5.0]
Iteration 1055 ended with reward tensor([0]), enemy health [6.0, 9], model health [8.0, 1.0]
Iteration 1056 ended with reward tensor([0]), enemy health [6.0, 9], model health [4.0, 0]
Iteration 1057 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [4.0, 0]
Iteration 1058 ended with reward tensor([-1.]), enemy health [6.0, 9], model health [0.0, 0]
enemy won!
Iteration 1059 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1060 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [5.0, 9]
Iteration 1061 ended with reward tensor([0.4000]), enemy health [0, 9], model health [5.0, 8.0]
Iteration 1062 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 8.0]
Iteration 1063 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 8.0]
Iteration 1064 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 6.0]
Iteration 1065 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 5.0]
Iteration 1066 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [0.0, 4.0]
Iteration 1067 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 3.0]
Iteration 1068 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 1.0]
Iteration 1069 ended with reward tensor([-1.]), enemy health [0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1070 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 1071 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 1072 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 1073 ended with reward tensor([-1.]), enemy health [8, 9], model health [2.0, 8.0]
Iteration 1074 ended with reward tensor([0.9000]), enemy health [6.0, 9], model health [2.0, 8.0]
Iteration 1075 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0.0, 7.0]
Iteration 1076 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 7.0]
Iteration 1077 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 6.0]
Iteration 1078 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 4.0]
Iteration 1079 ended with reward tensor([-1.]), enemy health [3.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 1080 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 1081 ended with reward tensor([0.2000]), enemy health [8, 6.0], model health [8, 8.0]
Iteration 1082 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [2.0, 5.0]
Iteration 1083 ended with reward tensor([-0.5000]), enemy health [8, 4.0], model health [2.0, 5.0]
Iteration 1084 ended with reward tensor([-0.5000]), enemy health [8, 4.0], model health [0, 5.0]
Iteration 1085 ended with reward tensor([0]), enemy health [8, 4.0], model health [0, 2.0]
Iteration 1086 ended with reward tensor([0.7000]), enemy health [8.0, 4.0], model health [0, 2.0]
Iteration 1087 ended with reward tensor([0.7000]), enemy health [8.0, 3.0], model health [0, 1.0]
Iteration 1088 ended with reward tensor([0]), enemy health [8.0, 3.0], model health [0, 1.0]
Iteration 1089 ended with reward tensor([0.7000]), enemy health [8.0, 3.0], model health [0, 1.0]
Iteration 1090 ended with reward tensor([0.7000]), enemy health [7.0, 3.0], model health [0, 1.0]
Iteration 1091 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0, 1.0]
Iteration 1092 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0, 1.0]
Iteration 1093 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 1.0]
Iteration 1094 ended with reward tensor([1.]), enemy health [0.0, 3.0], model health [0, 1.0]
Iteration 1095 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0, 0.0]
enemy won!
Iteration 1096 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 1097 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 1098 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 1099 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 9]
Iteration 1100 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 9]
Iteration 1101 ended with reward tensor([-0.5000]), enemy health [5.0, 6.0], model health [0.0, 9]
Iteration 1102 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 9.0]
Iteration 1103 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 1104 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 8.0]
Iteration 1105 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 7.0]
Iteration 1106 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 6.0]
Iteration 1107 ended with reward tensor([1.]), enemy health [1.0, 0], model health [0.0, 4.0]
Iteration 1108 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 4.0]
Iteration 1109 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 4.0]
Iteration 1110 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 4.0]
model won!
Iteration 1111 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1112 ended with reward tensor([-0.3000]), enemy health [5.0, 9], model health [4.0, 9]
Iteration 1113 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 9]
Iteration 1114 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 9]
Iteration 1115 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 8.0]
Iteration 1116 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 5.0]
Iteration 1117 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 2.0]
Iteration 1118 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 1119 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 2.0]
Iteration 1120 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 2.0]
Iteration 1121 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 2.0]
Iteration 1122 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 2.0]
Iteration 1123 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 2.0]
Iteration 1124 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 2.0]
Iteration 1125 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 2.0]
Iteration 1126 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 1127 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1128 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [8, 9]
Iteration 1129 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [8, 9]
Iteration 1130 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [3.0, 9]
Iteration 1131 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 9]
Iteration 1132 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 9]
Iteration 1133 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 9.0]
Iteration 1134 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9.0]
Iteration 1135 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 9.0]
Iteration 1136 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9.0]
Iteration 1137 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9.0]
Iteration 1138 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 1139 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 1140 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 1141 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 1.0]
Iteration 1142 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 1143 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1144 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 1145 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1146 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1147 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1148 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 6.0]
Iteration 1149 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 6.0]
Iteration 1150 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 4.0]
Iteration 1151 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 1.0]
Iteration 1152 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 1.0]
Iteration 1153 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0.0, 1.0]
Iteration 1154 ended with reward tensor([-1.]), enemy health [4.0, 1.0], model health [0.0, 0]
enemy won!
Iteration 1155 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [8, 9.0]
Iteration 1156 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [2.0, 9.0]
Iteration 1157 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0, 6.0]
Iteration 1158 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0, 6.0]
Iteration 1159 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0, 5.0]
Iteration 1160 ended with reward tensor([0.7000]), enemy health [6.0, 9.0], model health [0, 5.0]
Iteration 1161 ended with reward tensor([0.7000]), enemy health [6.0, 9.0], model health [0, 5.0]
Iteration 1162 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0, 5.0]
Iteration 1163 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 5.0]
Iteration 1164 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0, 5.0]
Iteration 1165 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0, 5.0]
Iteration 1166 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 5.0]
Iteration 1167 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 5.0]
Iteration 1168 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0, 5.0]
Iteration 1169 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0, 5.0]
Iteration 1170 ended with reward tensor([1.]), enemy health [0, 9.0], model health [0, 5.0]
Iteration 1171 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0, 2.0]
Iteration 1172 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 1.0]
Iteration 1173 ended with reward tensor([-1.]), enemy health [0, 7.0], model health [0, 0.0]
enemy won!
Iteration 1174 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9.0]
Iteration 1175 ended with reward tensor([0]), enemy health [4.0, 9], model health [8, 4.0]
Iteration 1176 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [4.0, 3.0]
Iteration 1177 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [4.0, 3.0]
Iteration 1178 ended with reward tensor([-0.3000]), enemy health [0, 7.0], model health [4.0, 3.0]
Iteration 1179 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 1.0]
Iteration 1180 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 1181 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1182 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [8, 9]
Iteration 1183 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [4.0, 9]
Iteration 1184 ended with reward tensor([0.4000]), enemy health [2.0, 7.0], model health [0, 9]
Iteration 1185 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 7.0]
Iteration 1186 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 1187 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 1188 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 1189 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 1190 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 1191 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 8.0]
Iteration 1192 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [6.0, 5.0]
Iteration 1193 ended with reward tensor([0.4000]), enemy health [0, 9], model health [6.0, 3.0]
Iteration 1194 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [6.0, 3.0]
Iteration 1195 ended with reward tensor([0]), enemy health [0, 9], model health [4.0, 3.0]
Iteration 1196 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 2.0]
Iteration 1197 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 2.0]
Iteration 1198 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 2.0]
Iteration 1199 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 2.0]
Iteration 1200 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1201 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1202 ended with reward tensor([0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 1203 ended with reward tensor([0.2000]), enemy health [8, 9], model health [1.0, 9]
Iteration 1204 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1205 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [0, 9]
Iteration 1206 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [0, 9]
Iteration 1207 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 9]
Iteration 1208 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 9]
Iteration 1209 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0, 9]
Iteration 1210 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [0, 9]
Iteration 1211 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0, 9]
Iteration 1212 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9]
Iteration 1213 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 1214 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 1215 ended with reward tensor([1.7000]), enemy health [-7.0, 6.0], model health [0, 4.0]
model won!
Iteration 1216 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 1217 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [3.0, 8.0]
Iteration 1218 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [1.0, 8.0]
Iteration 1219 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 1220 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 1221 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 1222 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 8.0]
Iteration 1223 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 8.0]
Iteration 1224 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 1225 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 6.0]
Iteration 1226 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 1227 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 4.0]
Iteration 1228 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 2.0]
Iteration 1229 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 1.0]
Iteration 1230 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0, 0]
enemy won!
Iteration 1231 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 1232 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8, 8.0]
Iteration 1233 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [4.0, 8.0]
Iteration 1234 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [4.0, 5.0]
Iteration 1235 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [4.0, 5.0]
Iteration 1236 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 5.0]
Iteration 1237 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 5.0]
Iteration 1238 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0.0, 5.0]
Iteration 1239 ended with reward tensor([0]), enemy health [0, 6.0], model health [0.0, 1.0]
Iteration 1240 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 1241 ended with reward tensor([-0.3000]), enemy health [8, 9], model health [7.0, 9]
Iteration 1242 ended with reward tensor([0.4000]), enemy health [8, 6.0], model health [2.0, 9]
Iteration 1243 ended with reward tensor([0.4000]), enemy health [3.0, 6.0], model health [2.0, 8.0]
Iteration 1244 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 8.0]
Iteration 1245 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0.0, 8.0]
Iteration 1246 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0.0, 7.0]
Iteration 1247 ended with reward tensor([-0.5000]), enemy health [-5.0, 6.0], model health [0.0, 7.0]
Iteration 1248 ended with reward tensor([-0.5000]), enemy health [-5.0, 6.0], model health [0.0, 7.0]
Iteration 1249 ended with reward tensor([-0.5000]), enemy health [-5.0, 6.0], model health [0.0, 3.0]
Iteration 1250 ended with reward tensor([-1.]), enemy health [-5.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 1251 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 8.0]
Iteration 1252 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [5.0, 8.0]
Iteration 1253 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [5.0, 8.0]
Iteration 1254 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [5.0, 8.0]
Iteration 1255 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [3.0, 8.0]
Iteration 1256 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [3.0, 8.0]
Iteration 1257 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [0.0, 8.0]
Iteration 1258 ended with reward tensor([0.7000]), enemy health [7.0, 5.0], model health [0, 8.0]
Iteration 1259 ended with reward tensor([-0.5000]), enemy health [7.0, 5.0], model health [0, 8.0]
Iteration 1260 ended with reward tensor([-0.5000]), enemy health [7.0, 5.0], model health [0, 8.0]
Iteration 1261 ended with reward tensor([-0.5000]), enemy health [7.0, 5.0], model health [0, 8.0]
Iteration 1262 ended with reward tensor([-0.5000]), enemy health [7.0, 5.0], model health [0, 8.0]
Iteration 1263 ended with reward tensor([-0.5000]), enemy health [7.0, 5.0], model health [0, 8.0]
Iteration 1264 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [0, 8.0]
Iteration 1265 ended with reward tensor([-0.5000]), enemy health [6.0, 5.0], model health [0, 8.0]
Iteration 1266 ended with reward tensor([-0.5000]), enemy health [6.0, 5.0], model health [0, 8.0]
Iteration 1267 ended with reward tensor([-0.5000]), enemy health [6.0, 5.0], model health [0, 5.0]
Iteration 1268 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0, 5.0]
Iteration 1269 ended with reward tensor([0]), enemy health [4.0, 5.0], model health [0, 2.0]
Iteration 1270 ended with reward tensor([-0.5000]), enemy health [4.0, 5.0], model health [0, 2.0]
Iteration 1271 ended with reward tensor([-0.5000]), enemy health [4.0, 5.0], model health [0, 2.0]
Iteration 1272 ended with reward tensor([-1.]), enemy health [4.0, 5.0], model health [0, 0]
enemy won!
Iteration 1273 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 9.0]
Iteration 1274 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8.0, 6.0]
Iteration 1275 ended with reward tensor([-1.]), enemy health [0, 9], model health [8.0, 5.0]
Iteration 1276 ended with reward tensor([-2.]), enemy health [0, 9], model health [6.0, 5.0]
Iteration 1277 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 5.0]
Iteration 1278 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 5.0]
Iteration 1279 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 1280 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1281 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 1282 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [1.0, 9]
Iteration 1283 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 1284 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1285 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1286 ended with reward tensor([0]), enemy health [5.0, 9], model health [0.0, 3.0]
Iteration 1287 ended with reward tensor([-1.]), enemy health [5.0, 9], model health [0.0, 0]
enemy won!
Iteration 1288 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1289 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 1290 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 9]
Iteration 1291 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 9]
Iteration 1292 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 1293 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 1294 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 1295 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 8.0]
Iteration 1296 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 1297 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 1298 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 2.0]
Iteration 1299 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 2.0]
Iteration 1300 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 2.0]
Iteration 1301 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 2.0]
Iteration 1302 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1303 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1304 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1305 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1306 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1307 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1308 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1309 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 1310 ended with reward tensor([-1.]), enemy health [3.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1311 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8.0, 9]
Iteration 1312 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [5.0, 9]
Iteration 1313 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 9]
Iteration 1314 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 9]
Iteration 1315 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9]
Iteration 1316 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 6.0]
Iteration 1317 ended with reward tensor([0]), enemy health [2.0, 5.0], model health [0, 2.0]
Iteration 1318 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0, 2.0]
Iteration 1319 ended with reward tensor([-0.5000]), enemy health [1.0, 5.0], model health [0, 2.0]
Iteration 1320 ended with reward tensor([1.]), enemy health [0, 5.0], model health [0, 2.0]
Iteration 1321 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [0, 0.0]
enemy won!
Iteration 1322 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 1323 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0, 9]
Iteration 1324 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 9]
Iteration 1325 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 9.0]
Iteration 1326 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 9.0]
Iteration 1327 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 1328 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 1329 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 1330 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 3.0]
Iteration 1331 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 3.0]
Iteration 1332 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 3.0]
Iteration 1333 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 1334 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 1.0]
Iteration 1335 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 1.0]
Iteration 1336 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 1337 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 1338 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 1339 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [5.0, 9]
Iteration 1340 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [2.0, 9]
Iteration 1341 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 1342 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 1343 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 1344 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 7.0]
Iteration 1345 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 2.0]
Iteration 1346 ended with reward tensor([-1.]), enemy health [3.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1347 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [8, 7.0]
Iteration 1348 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [8, 7.0]
Iteration 1349 ended with reward tensor([-1.]), enemy health [8, 8.0], model health [6.0, 7.0]
Iteration 1350 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [2.0, 7.0]
Iteration 1351 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0.0, 7.0]
Iteration 1352 ended with reward tensor([0]), enemy health [5.0, 8.0], model health [0.0, 2.0]
Iteration 1353 ended with reward tensor([-1.]), enemy health [5.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1354 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1355 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 1356 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [7.0, 7.0]
Iteration 1357 ended with reward tensor([0.4000]), enemy health [8, 6.0], model health [4.0, 7.0]
Iteration 1358 ended with reward tensor([0.2000]), enemy health [8, 6.0], model health [0, 7.0]
Iteration 1359 ended with reward tensor([0.]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1360 ended with reward tensor([-0.5000]), enemy health [2.0, 6.0], model health [0, 4.0]
Iteration 1361 ended with reward tensor([-1.]), enemy health [2.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 1362 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1363 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 1364 ended with reward tensor([-1.]), enemy health [8, 9], model health [6.0, 7.0]
Iteration 1365 ended with reward tensor([-1.]), enemy health [8, 9], model health [3.0, 7.0]
Iteration 1366 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 1367 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1368 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1369 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1370 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1371 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1372 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1373 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1374 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1375 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 4.0]
Iteration 1376 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 3.0]
Iteration 1377 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 3.0]
Iteration 1378 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 3.0]
Iteration 1379 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 3.0]
Iteration 1380 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 3.0]
Iteration 1381 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 2.0]
Iteration 1382 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 2.0]
Iteration 1383 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 1.0]
Iteration 1384 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1385 ended with reward tensor([0.7000]), enemy health [8, 9], model health [0.0, 9]
Iteration 1386 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 1387 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 1388 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 1389 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 1390 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 3.0]
Iteration 1391 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 1392 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 1393 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0]
enemy won!
Iteration 1394 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [3.0, 9]
Iteration 1395 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [2.0, 9]
Iteration 1396 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1397 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1398 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 8.0]
Iteration 1399 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 8.0]
Iteration 1400 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 1401 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 1402 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 1403 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 1404 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 4.0]
Iteration 1405 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 4.0]
Iteration 1406 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 4.0]
Iteration 1407 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 4.0]
Iteration 1408 ended with reward tensor([0]), enemy health [2.0, 9], model health [0.0, 2.0]
Iteration 1409 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1410 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1411 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1412 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1413 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1414 ended with reward tensor([-1.]), enemy health [2.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1415 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1416 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 9]
Iteration 1417 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 9]
Iteration 1418 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [5.0, 9]
Iteration 1419 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 5.0]
Iteration 1420 ended with reward tensor([0]), enemy health [0.0, 9], model health [1.0, 4.0]
Iteration 1421 ended with reward tensor([0]), enemy health [0.0, 9], model health [1.0, 3.0]
Iteration 1422 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 2.0]
Iteration 1423 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0]
enemy won!
Iteration 1424 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1425 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1426 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1427 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1428 ended with reward tensor([0]), enemy health [8, 9], model health [8, 6.0]
Iteration 1429 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 6.0]
Iteration 1430 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [8, 3.0]
Iteration 1431 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [8.0, 2.0]
Iteration 1432 ended with reward tensor([0]), enemy health [4.0, 9], model health [8.0, 0]
Iteration 1433 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4.0, 0]
Iteration 1434 ended with reward tensor([-1.]), enemy health [4.0, 9], model health [0, 0]
enemy won!
Iteration 1435 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 1436 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 4.0]
Iteration 1437 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 4.0]
Iteration 1438 ended with reward tensor([1.2000]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 1439 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8.0, 3.0]
Iteration 1440 ended with reward tensor([0]), enemy health [0.0, 9], model health [4.0, 3.0]
Iteration 1441 ended with reward tensor([0]), enemy health [0.0, 9], model health [1.0, 0]
Iteration 1442 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 0]
Iteration 1443 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0]
enemy won!
Iteration 1444 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 1445 ended with reward tensor([0.4000]), enemy health [8, 8.0], model health [4.0, 8.0]
Iteration 1446 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [2.0, 8.0]
Iteration 1447 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [0, 8.0]
Iteration 1448 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 8.0]
Iteration 1449 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 8.0]
Iteration 1450 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1451 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1452 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1453 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1454 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1455 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 5.0]
Iteration 1456 ended with reward tensor([0.7000]), enemy health [8.0, 6.0], model health [0, 5.0]
Iteration 1457 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0, 5.0]
Iteration 1458 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0, 5.0]
Iteration 1459 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 1460 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0, 5.0]
Iteration 1461 ended with reward tensor([1.]), enemy health [0.0, 6.0], model health [0, 5.0]
Iteration 1462 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 4.0]
Iteration 1463 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 3.0]
Iteration 1464 ended with reward tensor([-0.5000]), enemy health [0.0, 3.0], model health [0, 3.0]
Iteration 1465 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0, 0.0]
enemy won!
Iteration 1466 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1467 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1468 ended with reward tensor([-1.]), enemy health [8, 9], model health [6.0, 9]
Iteration 1469 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 1470 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1471 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 9.0]
Iteration 1472 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 9.0]
Iteration 1473 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 8.0]
Iteration 1474 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 5.0]
Iteration 1475 ended with reward tensor([-1.]), enemy health [8, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1476 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1477 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1478 ended with reward tensor([-1.]), enemy health [8, 9], model health [1.0, 9]
Iteration 1479 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1480 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1481 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1482 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 5.0]
Iteration 1483 ended with reward tensor([0]), enemy health [8, 9], model health [0, 3.0]
Iteration 1484 ended with reward tensor([0]), enemy health [8, 9], model health [0, 3.0]
Iteration 1485 ended with reward tensor([0]), enemy health [8, 9], model health [0, 2.0]
Iteration 1486 ended with reward tensor([-1.]), enemy health [8, 9], model health [0, 0.0]
enemy won!
Iteration 1487 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1488 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 1489 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 7.0]
Iteration 1490 ended with reward tensor([0]), enemy health [8, 9], model health [8, 6.0]
Iteration 1491 ended with reward tensor([0]), enemy health [8, 9], model health [8, 6.0]
Iteration 1492 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 6.0]
Iteration 1493 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 6.0]
Iteration 1494 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 6.0]
Iteration 1495 ended with reward tensor([0.2000]), enemy health [7.0, 6.0], model health [0, 6.0]
Iteration 1496 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [0, 6.0]
Iteration 1497 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [0.0, 5.0]
Iteration 1498 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [0.0, 5.0]
Iteration 1499 ended with reward tensor([-0.5000]), enemy health [6.0, 6.0], model health [0.0, 5.0]
Iteration 1500 ended with reward tensor([0]), enemy health [6.0, 6.0], model health [0.0, 2.0]
Iteration 1501 ended with reward tensor([0]), enemy health [6.0, 6.0], model health [0.0, 2.0]
Iteration 1502 ended with reward tensor([-1.]), enemy health [6.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 1503 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 1504 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 9.0]
Iteration 1505 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [0, 9.0]
Iteration 1506 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0, 9.0]
Iteration 1507 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0, 8.0]
Iteration 1508 ended with reward tensor([0.7000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1509 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1510 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1511 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1512 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1513 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1514 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1515 ended with reward tensor([-0.5000]), enemy health [8.0, 8.0], model health [0, 5.0]
Iteration 1516 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1517 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1518 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1519 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1520 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1521 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1522 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1523 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1524 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0, 5.0]
Iteration 1525 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 1526 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 1527 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 1528 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 1529 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1530 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1531 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1532 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1533 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1534 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1535 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1536 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1537 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1538 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1539 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1540 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1541 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1542 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1543 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1544 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1545 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1546 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1547 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1548 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1549 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1550 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1551 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1552 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1553 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1554 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1555 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1556 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1557 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1558 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1559 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 1560 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 2.0]
Iteration 1561 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [0, 1.0]
Iteration 1562 ended with reward tensor([-1.]), enemy health [3.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 1563 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1564 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [8, 9]
Iteration 1565 ended with reward tensor([0.2000]), enemy health [6.0, 9.0], model health [8, 8.0]
Iteration 1566 ended with reward tensor([0.2000]), enemy health [0.0, 9.0], model health [2.0, 8.0]
Iteration 1567 ended with reward tensor([0.4000]), enemy health [0.0, 6.0], model health [0, 8.0]
Iteration 1568 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 6.0]
Iteration 1569 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 3.0]
Iteration 1570 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 1571 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1572 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 1573 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [1.0, 9]
Iteration 1574 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 1575 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1576 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1577 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1578 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1579 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 5.0]
Iteration 1580 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 5.0]
Iteration 1581 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 5.0]
Iteration 1582 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 1583 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 1584 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1585 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 7.0]
Iteration 1586 ended with reward tensor([-0.3000]), enemy health [6.0, 9], model health [7.0, 6.0]
Iteration 1587 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [5.0, 6.0]
Iteration 1588 ended with reward tensor([0]), enemy health [1.0, 9], model health [5.0, 4.0]
Iteration 1589 ended with reward tensor([0]), enemy health [1.0, 9], model health [5.0, 2.0]
Iteration 1590 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 2.0]
Iteration 1591 ended with reward tensor([-1.]), enemy health [1.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1592 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1593 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 1594 ended with reward tensor([-0.3000]), enemy health [5.0, 9], model health [4.0, 8.0]
Iteration 1595 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [1.0, 8.0]
Iteration 1596 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 8.0]
Iteration 1597 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 1598 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 1599 ended with reward tensor([0]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1600 ended with reward tensor([0]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1601 ended with reward tensor([-1.]), enemy health [2.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1602 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 1603 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 4.0]
Iteration 1604 ended with reward tensor([1.]), enemy health [0, 9], model health [3.0, 4.0]
Iteration 1605 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 3.0]
Iteration 1606 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 1607 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1608 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 1609 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [3.0, 9.0]
Iteration 1610 ended with reward tensor([-0.3000]), enemy health [4.0, 9.0], model health [0.0, 9.0]
Iteration 1611 ended with reward tensor([0.2000]), enemy health [2.0, 9.0], model health [0.0, 8.0]
Iteration 1612 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 8.0]
Iteration 1613 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0, 8.0]
Iteration 1614 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0.0, 8.0]
Iteration 1615 ended with reward tensor([-0.5000]), enemy health [2.0, 6.0], model health [0.0, 8.0]
Iteration 1616 ended with reward tensor([-0.5000]), enemy health [2.0, 6.0], model health [0, 8.0]
Iteration 1617 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0, 8.0]
Iteration 1618 ended with reward tensor([0.]), enemy health [2.0, 6.0], model health [0, 8.0]
Iteration 1619 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0, 7.0]
Iteration 1620 ended with reward tensor([0.5000]), enemy health [0, 6.0], model health [0, 4.0]
Iteration 1621 ended with reward tensor([0.5000]), enemy health [0, 6.0], model health [0, 3.0]
Iteration 1622 ended with reward tensor([0.5000]), enemy health [0, 6.0], model health [0, 2.0]
Iteration 1623 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0, 0.0]
enemy won!
Iteration 1624 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1625 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9]
Iteration 1626 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 7.0]
Iteration 1627 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [3.0, 7.0]
Iteration 1628 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 1629 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 1630 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 1631 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 1632 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 2.0]
Iteration 1633 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1634 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1635 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 9]
Iteration 1636 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [6.0, 9]
Iteration 1637 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 1638 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1639 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1640 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9.0]
Iteration 1641 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 6.0]
Iteration 1642 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 4.0]
Iteration 1643 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 2.0]
Iteration 1644 ended with reward tensor([-1.]), enemy health [1.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 1645 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 1646 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [5.0, 9]
Iteration 1647 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 1648 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [3.0, 9]
Iteration 1649 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [1.0, 9]
Iteration 1650 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1651 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1652 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1653 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 1654 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 8.0]
Iteration 1655 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 8.0]
Iteration 1656 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 1657 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 8.0]
Iteration 1658 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 1659 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 6.0]
Iteration 1660 ended with reward tensor([0]), enemy health [0.0, 9.0], model health [0.0, 4.0]
Iteration 1661 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 1662 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1663 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 1664 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [8, 7.0]
Iteration 1665 ended with reward tensor([0]), enemy health [8, 8.0], model health [8, 7.0]
Iteration 1666 ended with reward tensor([0.2000]), enemy health [4.0, 8.0], model health [8, 7.0]
Iteration 1667 ended with reward tensor([-0.3000]), enemy health [4.0, 8.0], model health [6.0, 7.0]
Iteration 1668 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [5.0, 7.0]
Iteration 1669 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [3.0, 6.0]
Iteration 1670 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 6.0]
Iteration 1671 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 6.0]
Iteration 1672 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 6.0]
Iteration 1673 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 6.0]
Iteration 1674 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 6.0]
Iteration 1675 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0.0, 1.0]
Iteration 1676 ended with reward tensor([-1.5000]), enemy health [2.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1677 ended with reward tensor([0.4000]), enemy health [8, 6.0], model health [5.0, 9]
Iteration 1678 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [1.0, 9]
Iteration 1679 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [0, 9]
Iteration 1680 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [0, 8.0]
Iteration 1681 ended with reward tensor([0.2000]), enemy health [1.0, 4.0], model health [0, 6.0]
Iteration 1682 ended with reward tensor([0.]), enemy health [1.0, 4.0], model health [0, 4.0]
Iteration 1683 ended with reward tensor([-1.]), enemy health [1.0, 4.0], model health [0, 0.0]
enemy won!
Iteration 1684 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1685 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 9]
Iteration 1686 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8, 9.0]
Iteration 1687 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [6.0, 9.0]
Iteration 1688 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [5.0, 9.0]
Iteration 1689 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [3.0, 9.0]
Iteration 1690 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0.0, 8.0]
Iteration 1691 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0.0, 8.0]
Iteration 1692 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0.0, 8.0]
Iteration 1693 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 8.0]
Iteration 1694 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 8.0]
Iteration 1695 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 8.0]
Iteration 1696 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 8.0]
Iteration 1697 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 8.0]
Iteration 1698 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 1699 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 1700 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 1701 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 1702 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 6.0]
Iteration 1703 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 5.0]
Iteration 1704 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 5.0]
Iteration 1705 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 4.0]
Iteration 1706 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 1.0]
model won!
Iteration 1707 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 1708 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [0.0, 9]
Iteration 1709 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0.0, 9]
Iteration 1710 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0.0, 9.0]
Iteration 1711 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0.0, 9.0]
Iteration 1712 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0.0, 9.0]
Iteration 1713 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0.0, 9.0]
Iteration 1714 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0.0, 9.0]
Iteration 1715 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 6.0]
Iteration 1716 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 3.0]
Iteration 1717 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 3.0]
Iteration 1718 ended with reward tensor([-0.3000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 1719 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 2.0]
Iteration 1720 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0.0, 0]
enemy won!
Iteration 1721 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 1722 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [8, 9]
Iteration 1723 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 1724 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 1725 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 1726 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 1727 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 6.0]
Iteration 1728 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 1729 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 1730 ended with reward tensor([0.7000]), enemy health [-7.0, 9.0], model health [0.0, 5.0]
Iteration 1731 ended with reward tensor([0.7000]), enemy health [-7.0, 8.0], model health [0.0, 3.0]
Iteration 1732 ended with reward tensor([0]), enemy health [-7.0, 8.0], model health [0.0, 3.0]
Iteration 1733 ended with reward tensor([-1.]), enemy health [-7.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 1734 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 1735 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 1736 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 1737 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 1738 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 1739 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 1740 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 1741 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 1742 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 1743 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 1.0]
Iteration 1744 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 1745 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 1746 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8.0, 9]
Iteration 1747 ended with reward tensor([0]), enemy health [0.0, 9], model health [8.0, 9]
Iteration 1748 ended with reward tensor([0]), enemy health [0.0, 9], model health [8.0, 9]
Iteration 1749 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 9]
Iteration 1750 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 1751 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 1752 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 1753 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 1.0]
Iteration 1754 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1755 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1756 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 1757 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 9]
Iteration 1758 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 9]
Iteration 1759 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 9]
Iteration 1760 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 9]
Iteration 1761 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 1762 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 1763 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 1764 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 1765 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 1.0]
Iteration 1766 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 1767 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 1768 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [1.0, 9]
Iteration 1769 ended with reward tensor([0.4000]), enemy health [0, 9], model health [0.0, 8.0]
Iteration 1770 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 8.0]
Iteration 1771 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 8.0]
Iteration 1772 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 6.0]
Iteration 1773 ended with reward tensor([0]), enemy health [0, 9], model health [0, 3.0]
Iteration 1774 ended with reward tensor([0]), enemy health [0, 9], model health [0, 3.0]
Iteration 1775 ended with reward tensor([0]), enemy health [0, 9], model health [0, 3.0]
Iteration 1776 ended with reward tensor([-1.]), enemy health [0, 9], model health [0, 0.0]
enemy won!
Iteration 1777 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1778 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 7.0]
Iteration 1779 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 7.0]
Iteration 1780 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 6.0]
Iteration 1781 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [8, 2.0]
Iteration 1782 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [8, 1.0]
Iteration 1783 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [5.0, 0]
Iteration 1784 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [5.0, 0]
Iteration 1785 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [3.0, 0]
Iteration 1786 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0]
enemy won!
Iteration 1787 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 1788 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 1789 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 1790 ended with reward tensor([-0.3000]), enemy health [8, 9.0], model health [8.0, 7.0]
Iteration 1791 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [5.0, 7.0]
Iteration 1792 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 7.0]
Iteration 1793 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1794 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1795 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1796 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1797 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1798 ended with reward tensor([0]), enemy health [8, 9.0], model health [0.0, 3.0]
Iteration 1799 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0.0, 3.0]
Iteration 1800 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 3.0]
Iteration 1801 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 3.0]
Iteration 1802 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 3.0]
Iteration 1803 ended with reward tensor([0]), enemy health [4.0, 8.0], model health [0.0, 1.0]
Iteration 1804 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 1.0]
Iteration 1805 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 1.0]
Iteration 1806 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 1807 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 1808 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 1809 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 1810 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1811 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 7.0]
Iteration 1812 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [8, 4.0]
Iteration 1813 ended with reward tensor([0.4000]), enemy health [3.0, 8.0], model health [8, 4.0]
Iteration 1814 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [7.0, 4.0]
Iteration 1815 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [7.0, 2.0]
Iteration 1816 ended with reward tensor([0.5000]), enemy health [0.0, 5.0], model health [7.0, 0.0]
Iteration 1817 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [7.0, 0.0]
Iteration 1818 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [5.0, 0]
Iteration 1819 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [5.0, 0]
Iteration 1820 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [1.0, 0]
Iteration 1821 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0.0, 0]
enemy won!
Iteration 1822 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 1823 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1824 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1825 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9]
Iteration 1826 ended with reward tensor([0.2000]), enemy health [0, 9], model health [5.0, 9]
Iteration 1827 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [1.0, 9.0]
Iteration 1828 ended with reward tensor([0.]), enemy health [0, 9], model health [0, 8.0]
Iteration 1829 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 7.0]
Iteration 1830 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 5.0]
Iteration 1831 ended with reward tensor([0]), enemy health [0, 9], model health [0, 4.0]
Iteration 1832 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 1833 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 2.0]
Iteration 1834 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0]
enemy won!
Iteration 1835 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 1836 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [8, 4.0]
Iteration 1837 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [5.0, 4.0]
Iteration 1838 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [2.0, 4.0]
Iteration 1839 ended with reward tensor([0.2000]), enemy health [4.0, 7.0], model health [0.0, 4.0]
Iteration 1840 ended with reward tensor([-0.5000]), enemy health [4.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 1841 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1842 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1843 ended with reward tensor([-0.3000]), enemy health [5.0, 9], model health [4.0, 9.0]
Iteration 1844 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [4.0, 9.0]
Iteration 1845 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [2.0, 8.0]
Iteration 1846 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 1847 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 1848 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 1849 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 1.0]
Iteration 1850 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 0]
enemy won!
Iteration 1851 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1852 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9.0]
Iteration 1853 ended with reward tensor([0.2000]), enemy health [0, 9], model health [7.0, 9.0]
Iteration 1854 ended with reward tensor([0.9000]), enemy health [0, 7.0], model health [7.0, 9.0]
Iteration 1855 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [5.0, 9.0]
Iteration 1856 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [5.0, 8.0]
Iteration 1857 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [5.0, 5.0]
Iteration 1858 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 5.0]
Iteration 1859 ended with reward tensor([0]), enemy health [0, 5.0], model health [0, 2.0]
Iteration 1860 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [0, 0.0]
enemy won!
Iteration 1861 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 1862 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [5.0, 9]
Iteration 1863 ended with reward tensor([1.]), enemy health [0.0, 9], model health [4.0, 9]
Iteration 1864 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 1865 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 1866 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 1867 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 2.0]
Iteration 1868 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1869 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1870 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [5.0, 9.0]
Iteration 1871 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1872 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1873 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1874 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1875 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1876 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1877 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1878 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 1879 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 1880 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 8.0]
Iteration 1881 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 8.0]
Iteration 1882 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 8.0]
Iteration 1883 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 8.0]
Iteration 1884 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 8.0]
Iteration 1885 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 7.0]
Iteration 1886 ended with reward tensor([0.2000]), enemy health [0.0, 1.0], model health [0.0, 7.0]
Iteration 1887 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 6.0]
model won!
Iteration 1888 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 1889 ended with reward tensor([0]), enemy health [4.0, 9], model health [8, 9]
Iteration 1890 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8.0, 9]
Iteration 1891 ended with reward tensor([-1.]), enemy health [0, 9], model health [8.0, 8.0]
Iteration 1892 ended with reward tensor([-1.]), enemy health [0, 9], model health [8.0, 8.0]
Iteration 1893 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [5.0, 8.0]
Iteration 1894 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [5.0, 6.0]
Iteration 1895 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [4.0, 6.0]
Iteration 1896 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0, 5.0]
Iteration 1897 ended with reward tensor([0.]), enemy health [0, 6.0], model health [0, 4.0]
Iteration 1898 ended with reward tensor([0]), enemy health [0, 6.0], model health [0, 2.0]
Iteration 1899 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0, 0.0]
enemy won!
Iteration 1900 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 1901 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1902 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1903 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 1904 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9.0]
Iteration 1905 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 9.0]
Iteration 1906 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0, 6.0]
Iteration 1907 ended with reward tensor([0.7000]), enemy health [7.0, 5.0], model health [0, 6.0]
Iteration 1908 ended with reward tensor([0.7000]), enemy health [7.0, 5.0], model health [0, 3.0]
Iteration 1909 ended with reward tensor([0.7000]), enemy health [7.0, 4.0], model health [0, 2.0]
Iteration 1910 ended with reward tensor([0.7000]), enemy health [7.0, 3.0], model health [0, 1.0]
Iteration 1911 ended with reward tensor([-1.]), enemy health [7.0, 3.0], model health [0, 0.0]
enemy won!
Iteration 1912 ended with reward tensor([0.2000]), enemy health [8.0, 9], model health [5.0, 9]
Iteration 1913 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [5.0, 8.0]
Iteration 1914 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [3.0, 8.0]
Iteration 1915 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [3.0, 8.0]
Iteration 1916 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 8.0]
Iteration 1917 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 6.0]
Iteration 1918 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 1919 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1920 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 1921 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 1922 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [8, 6.0]
Iteration 1923 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [8, 6.0]
Iteration 1924 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 1925 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [8, 6.0]
Iteration 1926 ended with reward tensor([1.]), enemy health [0.0, 9], model health [4.0, 6.0]
Iteration 1927 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 1928 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 1929 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 4.0]
Iteration 1930 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 2.0]
Iteration 1931 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 1932 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 1933 ended with reward tensor([-0.3000]), enemy health [3.0, 9], model health [1.0, 9]
Iteration 1934 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 9]
Iteration 1935 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 9.0]
Iteration 1936 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 1937 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 6.0]
Iteration 1938 ended with reward tensor([0.2000]), enemy health [0, 9.0], model health [0.0, 6.0]
Iteration 1939 ended with reward tensor([-0.5000]), enemy health [0, 9.0], model health [0.0, 6.0]
Iteration 1940 ended with reward tensor([-0.5000]), enemy health [0, 9.0], model health [0.0, 6.0]
Iteration 1941 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 1.0]
Iteration 1942 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 1.0]
Iteration 1943 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [0.0, 0]
enemy won!
Iteration 1944 ended with reward tensor([0.]), enemy health [8, 9], model health [2.0, 9]
Iteration 1945 ended with reward tensor([0]), enemy health [8, 9], model health [0.0, 9]
Iteration 1946 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 9.0]
Iteration 1947 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0.0, 7.0]
Iteration 1948 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0.0, 4.0]
Iteration 1949 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1950 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1951 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 1.0]
Iteration 1952 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1953 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1954 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1955 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [5.0, 9]
Iteration 1956 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [1.0, 9]
Iteration 1957 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 1958 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 1959 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 1960 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 1961 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 1962 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 1963 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 1964 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 2.0]
Iteration 1965 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 2.0]
Iteration 1966 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 2.0]
Iteration 1967 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 0]
enemy won!
Iteration 1968 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1969 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 1970 ended with reward tensor([0.2000]), enemy health [8, 9], model health [2.0, 9]
Iteration 1971 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 9]
Iteration 1972 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 9]
Iteration 1973 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1974 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1975 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [0.0, 6.0]
Iteration 1976 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 4.0]
Iteration 1977 ended with reward tensor([-1.]), enemy health [8, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 1978 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 1979 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 7.0]
Iteration 1980 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [0, 7.0]
Iteration 1981 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 1982 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 1983 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 1984 ended with reward tensor([0]), enemy health [1.0, 9], model health [0.0, 3.0]
Iteration 1985 ended with reward tensor([1.]), enemy health [0, 9], model health [0.0, 3.0]
Iteration 1986 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 1987 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 1988 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 8.0]
Iteration 1989 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 7.0]
Iteration 1990 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 5.0]
Iteration 1991 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 1992 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 1993 ended with reward tensor([0.]), enemy health [0.0, 9], model health [8, 2.0]
Iteration 1994 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [8, 0.0]
Iteration 1995 ended with reward tensor([0]), enemy health [0.0, 9], model health [4.0, 0.0]
Iteration 1996 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 1997 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 1998 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 1999 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 2000 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 2001 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [4.0, 8.0]
Iteration 2002 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [1.0, 8.0]
Iteration 2003 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 8.0]
Iteration 2004 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 8.0]
Iteration 2005 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 8.0]
Iteration 2006 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 3.0]
Iteration 2007 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 2.0]
Iteration 2008 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 2009 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 2.0]
Iteration 2010 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 2.0]
Iteration 2011 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 2.0]
Iteration 2012 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0]
enemy won!
Iteration 2013 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2014 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [6.0, 9]
Iteration 2015 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [2.0, 9]
Iteration 2016 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [0, 9.0]
Iteration 2017 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0, 9.0]
Iteration 2018 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [0, 5.0]
Iteration 2019 ended with reward tensor([-0.5000]), enemy health [6.0, 5.0], model health [0, 4.0]
Iteration 2020 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [0, 2.0]
Iteration 2021 ended with reward tensor([-1.]), enemy health [6.0, 5.0], model health [0, 0.0]
enemy won!
Iteration 2022 ended with reward tensor([0]), enemy health [8, 9], model health [8, 6.0]
Iteration 2023 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8.0, 6.0]
Iteration 2024 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [8.0, 6.0]
Iteration 2025 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [2.0, 6.0]
Iteration 2026 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 6.0]
Iteration 2027 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 2028 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 2029 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 6.0]
Iteration 2030 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 6.0]
Iteration 2031 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 6.0]
Iteration 2032 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 6.0]
Iteration 2033 ended with reward tensor([0.7000]), enemy health [5.0, 3.0], model health [0.0, 6.0]
Iteration 2034 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 6.0]
Iteration 2035 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [0.0, 6.0]
Iteration 2036 ended with reward tensor([0]), enemy health [5.0, 0.0], model health [0.0, 6.0]
Iteration 2037 ended with reward tensor([1.2000]), enemy health [0, 0.0], model health [0.0, 6.0]
model won!
Iteration 2038 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2039 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8, 9]
Iteration 2040 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [4.0, 9]
Iteration 2041 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 9]
Iteration 2042 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0.0, 9]
Iteration 2043 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0.0, 6.0]
Iteration 2044 ended with reward tensor([0.2000]), enemy health [5.0, 7.0], model health [0.0, 4.0]
Iteration 2045 ended with reward tensor([0.2000]), enemy health [4.0, 7.0], model health [0.0, 4.0]
Iteration 2046 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 4.0]
Iteration 2047 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 4.0]
Iteration 2048 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 2049 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 2.0]
Iteration 2050 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 2051 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 2052 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 2053 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 2054 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [4.0, 9.0]
Iteration 2055 ended with reward tensor([0.9000]), enemy health [0, 9], model health [1.0, 9.0]
Iteration 2056 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [1.0, 5.0]
Iteration 2057 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 5.0]
Iteration 2058 ended with reward tensor([0]), enemy health [0, 9], model health [0, 2.0]
Iteration 2059 ended with reward tensor([-1.]), enemy health [0, 9], model health [0, 0.0]
enemy won!
Iteration 2060 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2061 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 2062 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [4.0, 6.0]
Iteration 2063 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 3.0]
Iteration 2064 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 2065 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 2066 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 2.0]
Iteration 2067 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 1.0]
Iteration 2068 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 0]
enemy won!
Iteration 2069 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2070 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [8.0, 9]
Iteration 2071 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [7.0, 9]
Iteration 2072 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0, 9]
Iteration 2073 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 2074 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 6.0]
Iteration 2075 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 6.0]
Iteration 2076 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 3.0]
Iteration 2077 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 3.0]
Iteration 2078 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 2079 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 2080 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 2081 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 2082 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2083 ended with reward tensor([0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 2084 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [0, 9]
Iteration 2085 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [0, 8.0]
Iteration 2086 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [0.0, 5.0]
Iteration 2087 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 3.0]
Iteration 2088 ended with reward tensor([0]), enemy health [6.0, 7.0], model health [0.0, 1.0]
Iteration 2089 ended with reward tensor([0]), enemy health [6.0, 7.0], model health [0.0, 1.0]
Iteration 2090 ended with reward tensor([0.7000]), enemy health [6.0, 4.0], model health [0.0, 1.0]
Iteration 2091 ended with reward tensor([0.7000]), enemy health [6.0, 2.0], model health [0.0, 1.0]
Iteration 2092 ended with reward tensor([-1.]), enemy health [6.0, 2.0], model health [0.0, 0]
enemy won!
Iteration 2093 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 6.0]
Iteration 2094 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 3.0]
Iteration 2095 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 2.0]
Iteration 2096 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 2.0]
Iteration 2097 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 1.0]
Iteration 2098 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 1.0]
Iteration 2099 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [4.0, 1.0]
Iteration 2100 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 0.0]
Iteration 2101 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 2102 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2103 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2104 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2105 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [5.0, 6.0]
Iteration 2106 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 2107 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 2108 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 2109 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 5.0]
Iteration 2110 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 5.0]
Iteration 2111 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 5.0]
Iteration 2112 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 2113 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 2114 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 2115 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 2116 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 2117 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 8.0]
Iteration 2118 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [1.0, 8.0]
Iteration 2119 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 2120 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 2121 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 2122 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 2123 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 2124 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2125 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 2126 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 2127 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 2128 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 2129 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 2130 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 7.0]
Iteration 2131 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 6.0]
Iteration 2132 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [3.0, 6.0]
Iteration 2133 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [3.0, 5.0]
Iteration 2134 ended with reward tensor([0.4000]), enemy health [1.0, 4.0], model health [3.0, 5.0]
Iteration 2135 ended with reward tensor([1.]), enemy health [0.0, 4.0], model health [3.0, 3.0]
Iteration 2136 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [3.0, 1.0]
Iteration 2137 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [3.0, 0.0]
Iteration 2138 ended with reward tensor([0.]), enemy health [0.0, 4.0], model health [3.0, 0.0]
Iteration 2139 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [1.0, 0.0]
Iteration 2140 ended with reward tensor([0.5000]), enemy health [0.0, 4.0], model health [1.0, 0.0]
Iteration 2141 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0, 0]
enemy won!
Iteration 2142 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2143 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 2144 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 9]
Iteration 2145 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8, 9]
Iteration 2146 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [4.0, 9]
Iteration 2147 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 8.0]
Iteration 2148 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [1.0, 7.0]
Iteration 2149 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 2150 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 2151 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 2152 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 2153 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 7.0]
Iteration 2154 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [2.0, 5.0]
Iteration 2155 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 2156 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 2157 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 2158 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 5.0]
Iteration 2159 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 2160 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 2161 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 2162 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 2163 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 2164 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 2165 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 2.0]
Iteration 2166 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 2167 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2168 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 8.0]
Iteration 2169 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [8, 8.0]
Iteration 2170 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [6.0, 5.0]
Iteration 2171 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [3.0, 5.0]
Iteration 2172 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 2173 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 5.0]
Iteration 2174 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 2.0]
Iteration 2175 ended with reward tensor([0]), enemy health [3.0, 9], model health [0.0, 1.0]
Iteration 2176 ended with reward tensor([-1.]), enemy health [3.0, 9], model health [0.0, 0]
enemy won!
Iteration 2177 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 2178 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [0.0, 9]
Iteration 2179 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 2180 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 2181 ended with reward tensor([0.]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 2182 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 2183 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 2184 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 2.0]
Iteration 2185 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 2186 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0]
enemy won!
Iteration 2187 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [8, 7.0]
Iteration 2188 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 2189 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8.0, 6.0]
Iteration 2190 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [3.0, 4.0]
Iteration 2191 ended with reward tensor([0]), enemy health [0, 9.0], model health [3.0, 2.0]
Iteration 2192 ended with reward tensor([-1.]), enemy health [0, 9.0], model health [0, 2.0]
Iteration 2193 ended with reward tensor([0]), enemy health [0, 9.0], model health [0, 2.0]
Iteration 2194 ended with reward tensor([0]), enemy health [0, 9.0], model health [0, 1.0]
Iteration 2195 ended with reward tensor([-1.]), enemy health [0, 9.0], model health [0, 0.0]
enemy won!
Iteration 2196 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2197 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [5.0, 9]
Iteration 2198 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [5.0, 7.0]
Iteration 2199 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [3.0, 7.0]
Iteration 2200 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 2201 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 2202 ended with reward tensor([0]), enemy health [2.0, 9], model health [0.0, 2.0]
Iteration 2203 ended with reward tensor([-1.]), enemy health [2.0, 9], model health [0.0, 0]
enemy won!
Iteration 2204 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 7.0]
Iteration 2205 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 2206 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 2207 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [3.0, 7.0]
Iteration 2208 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 2209 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2210 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 2211 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 2212 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 2.0]
Iteration 2213 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 2.0]
Iteration 2214 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 2.0]
Iteration 2215 ended with reward tensor([0]), enemy health [1.0, 6.0], model health [0.0, 2.0]
Iteration 2216 ended with reward tensor([-0.5000]), enemy health [1.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 2217 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2218 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2219 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [2.0, 9]
Iteration 2220 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [1.0, 6.0]
Iteration 2221 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 6.0]
Iteration 2222 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0.0, 6.0]
Iteration 2223 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 2224 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 2225 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 2226 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [0.0, 3.0]
Iteration 2227 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 3.0]
Iteration 2228 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 3.0]
Iteration 2229 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 3.0]
Iteration 2230 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 2231 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [7.0, 9]
Iteration 2232 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 2233 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9]
Iteration 2234 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9]
Iteration 2235 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9]
Iteration 2236 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9]
Iteration 2237 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0, 9]
Iteration 2238 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9.0]
Iteration 2239 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9.0]
Iteration 2240 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9.0]
Iteration 2241 ended with reward tensor([1.]), enemy health [0, 9], model health [0, 9.0]
Iteration 2242 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0, 7.0]
Iteration 2243 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 6.0]
Iteration 2244 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 5.0]
Iteration 2245 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0, 5.0]
Iteration 2246 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 3.0]
Iteration 2247 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 3.0]
Iteration 2248 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 2.0]
Iteration 2249 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [0, 0]
enemy won!
Iteration 2250 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2251 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2252 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 2253 ended with reward tensor([0.9000]), enemy health [1.0, 9], model health [8, 9]
Iteration 2254 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [8.0, 9]
Iteration 2255 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [7.0, 9.0]
Iteration 2256 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [4.0, 9.0]
Iteration 2257 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 6.0]
Iteration 2258 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 6.0]
Iteration 2259 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 6.0]
Iteration 2260 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 6.0]
Iteration 2261 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 6.0]
Iteration 2262 ended with reward tensor([1.]), enemy health [0.0, 4.0], model health [0.0, 6.0]
Iteration 2263 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 6.0]
Iteration 2264 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 6.0]
Iteration 2265 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 6.0]
Iteration 2266 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 6.0]
Iteration 2267 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 6.0]
model won!
Iteration 2268 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 2269 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [4.0, 9]
Iteration 2270 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [4.0, 7.0]
Iteration 2271 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 7.0]
Iteration 2272 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 2273 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0, 2.0]
Iteration 2274 ended with reward tensor([0.2000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 2275 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 2276 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 2.0]
Iteration 2277 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 2.0]
Iteration 2278 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2279 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2280 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2281 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 2.0]
model won!
Iteration 2282 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 2283 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [2.0, 9.0]
Iteration 2284 ended with reward tensor([0.9000]), enemy health [1.0, 9], model health [2.0, 9.0]
Iteration 2285 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 6.0]
Iteration 2286 ended with reward tensor([0]), enemy health [1.0, 9], model health [0.0, 2.0]
Iteration 2287 ended with reward tensor([-1.]), enemy health [1.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 2288 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [6.0, 7.0]
Iteration 2289 ended with reward tensor([0.2000]), enemy health [5.0, 7.0], model health [6.0, 7.0]
Iteration 2290 ended with reward tensor([0.7000]), enemy health [5.0, 3.0], model health [6.0, 5.0]
Iteration 2291 ended with reward tensor([-0.5000]), enemy health [5.0, 3.0], model health [6.0, 2.0]
Iteration 2292 ended with reward tensor([0]), enemy health [5.0, 3.0], model health [2.0, 2.0]
Iteration 2293 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [0, 1.0]
Iteration 2294 ended with reward tensor([-0.5000]), enemy health [4.0, 3.0], model health [0, 0.0]
enemy won!
Iteration 2295 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 2296 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 4.0]
Iteration 2297 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [4.0, 4.0]
Iteration 2298 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [4.0, 2.0]
Iteration 2299 ended with reward tensor([1.]), enemy health [0, 9], model health [1.0, 1.0]
Iteration 2300 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 1.0]
Iteration 2301 ended with reward tensor([-1.]), enemy health [0, 9], model health [0, 0.0]
enemy won!
Iteration 2302 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [2.0, 9]
Iteration 2303 ended with reward tensor([0]), enemy health [8, 8.0], model health [0, 9]
Iteration 2304 ended with reward tensor([0.5000]), enemy health [8, 8.0], model health [0, 9]
Iteration 2305 ended with reward tensor([0.2000]), enemy health [6.0, 8.0], model health [0, 9]
Iteration 2306 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 6.0]
Iteration 2307 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 2308 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0, 4.0]
Iteration 2309 ended with reward tensor([-0.5000]), enemy health [6.0, 8.0], model health [0.0, 4.0]
Iteration 2310 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 4.0]
Iteration 2311 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 4.0]
Iteration 2312 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 4.0]
Iteration 2313 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0.0, 4.0]
Iteration 2314 ended with reward tensor([0.7000]), enemy health [6.0, 1.0], model health [0.0, 4.0]
Iteration 2315 ended with reward tensor([0.7000]), enemy health [6.0, 1.0], model health [0.0, 4.0]
Iteration 2316 ended with reward tensor([1.]), enemy health [6.0, 0], model health [0, 4.0]
Iteration 2317 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0, 4.0]
Iteration 2318 ended with reward tensor([1.]), enemy health [2.0, 0], model health [0, 4.0]
Iteration 2319 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0, 4.0]
Iteration 2320 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0, 4.0]
Iteration 2321 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 4.0]
model won!
Iteration 2322 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2323 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 9]
Iteration 2324 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 9.0]
Iteration 2325 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [5.0, 9.0]
Iteration 2326 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [2.0, 9.0]
Iteration 2327 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [2.0, 9.0]
Iteration 2328 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 9.0]
Iteration 2329 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 9.0]
Iteration 2330 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 9.0]
Iteration 2331 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 9.0]
Iteration 2332 ended with reward tensor([1.]), enemy health [1.0, 0.0], model health [0.0, 9.0]
Iteration 2333 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 9.0]
Iteration 2334 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 9.0]
model won!
Iteration 2335 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [1.0, 9]
Iteration 2336 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 6.0]
Iteration 2337 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 5.0]
Iteration 2338 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0.0, 4.0]
Iteration 2339 ended with reward tensor([0.7000]), enemy health [8, 3.0], model health [0.0, 3.0]
Iteration 2340 ended with reward tensor([0.7000]), enemy health [8, 1.0], model health [0.0, 3.0]
Iteration 2341 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 3.0]
Iteration 2342 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [0.0, 3.0]
Iteration 2343 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 3.0]
Iteration 2344 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2345 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2346 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 3.0]
Iteration 2347 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 3.0]
Iteration 2348 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 2349 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2350 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9.0]
Iteration 2351 ended with reward tensor([0.4000]), enemy health [0, 9], model health [3.0, 9.0]
Iteration 2352 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 6.0]
Iteration 2353 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 6.0]
Iteration 2354 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 5.0]
Iteration 2355 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 2.0]
Iteration 2356 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 2.0]
Iteration 2357 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 1.0]
Iteration 2358 ended with reward tensor([-1.]), enemy health [0, 3.0], model health [0.0, 0]
enemy won!
Iteration 2359 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 2360 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [7.0, 9]
Iteration 2361 ended with reward tensor([0.4000]), enemy health [0, 9], model health [7.0, 9.0]
Iteration 2362 ended with reward tensor([-1.]), enemy health [0, 9], model health [3.0, 9.0]
Iteration 2363 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 7.0]
Iteration 2364 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 6.0]
Iteration 2365 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 3.0]
Iteration 2366 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 2.0]
Iteration 2367 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0, 0]
enemy won!
Iteration 2368 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 2369 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 2370 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 9]
Iteration 2371 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 9.0]
Iteration 2372 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 2373 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 6.0]
Iteration 2374 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 2375 ended with reward tensor([0.9000]), enemy health [0.0, 7.0], model health [8, 1.0]
Iteration 2376 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [5.0, 1.0]
Iteration 2377 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [5.0, 1.0]
Iteration 2378 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [5.0, 0.0]
Iteration 2379 ended with reward tensor([0.]), enemy health [0.0, 7.0], model health [3.0, 0.0]
Iteration 2380 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 2381 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 9.0]
Iteration 2382 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [3.0, 9.0]
Iteration 2383 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [1.0, 8.0]
Iteration 2384 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 2385 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 2386 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 2387 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 2388 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 4.0]
Iteration 2389 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0, 0]
enemy won!
Iteration 2390 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 6.0]
Iteration 2391 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 3.0]
Iteration 2392 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [6.0, 0.0]
Iteration 2393 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [3.0, 0.0]
Iteration 2394 ended with reward tensor([-1.]), enemy health [4.0, 9], model health [0, 0.0]
enemy won!
Iteration 2395 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2396 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2397 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 2398 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 9]
Iteration 2399 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [8, 9]
Iteration 2400 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [8.0, 9]
Iteration 2401 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [8.0, 9]
Iteration 2402 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [8.0, 9.0]
Iteration 2403 ended with reward tensor([-1.]), enemy health [0, 9], model health [6.0, 9.0]
Iteration 2404 ended with reward tensor([-1.]), enemy health [0, 9], model health [1.0, 9.0]
Iteration 2405 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 9.0]
Iteration 2406 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 8.0]
Iteration 2407 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 6.0]
Iteration 2408 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 2409 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0]
enemy won!
Iteration 2410 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2411 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 2412 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 9.0]
Iteration 2413 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 2414 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [4.0, 8.0]
Iteration 2415 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 7.0]
Iteration 2416 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 7.0]
Iteration 2417 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 5.0]
Iteration 2418 ended with reward tensor([0]), enemy health [0.0, 9], model health [1.0, 2.0]
Iteration 2419 ended with reward tensor([0.]), enemy health [0.0, 9], model health [1.0, 1.0]
Iteration 2420 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 1.0]
Iteration 2421 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 1.0]
Iteration 2422 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [1.0, 1.0]
Iteration 2423 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 1.0]
Iteration 2424 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 2425 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 2426 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 2427 ended with reward tensor([0.9000]), enemy health [3.0, 9], model health [3.0, 9.0]
Iteration 2428 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 2429 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 2430 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 2431 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 5.0]
Iteration 2432 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 5.0]
Iteration 2433 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 5.0]
Iteration 2434 ended with reward tensor([0.7000]), enemy health [3.0, 4.0], model health [0.0, 5.0]
Iteration 2435 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 5.0]
Iteration 2436 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2437 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2438 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2439 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2440 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2441 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2442 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2443 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2444 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2445 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2446 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2447 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 2448 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 4.0]
Iteration 2449 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 4.0]
Iteration 2450 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 4.0]
Iteration 2451 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2452 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2453 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2454 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2455 ended with reward tensor([1.5000]), enemy health [-5.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 2456 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2457 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 2458 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [7.0, 9]
Iteration 2459 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [6.0, 9]
Iteration 2460 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [4.0, 9]
Iteration 2461 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [2.0, 9]
Iteration 2462 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [2.0, 6.0]
Iteration 2463 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [2.0, 4.0]
Iteration 2464 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [2.0, 4.0]
Iteration 2465 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [2.0, 3.0]
Iteration 2466 ended with reward tensor([0.5000]), enemy health [1.0, 8.0], model health [2.0, 0.0]
Iteration 2467 ended with reward tensor([0.5000]), enemy health [1.0, 8.0], model health [2.0, 0.0]
Iteration 2468 ended with reward tensor([-1.]), enemy health [1.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 2469 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 9.0]
Iteration 2470 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 9.0]
Iteration 2471 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [6.0, 8.0]
Iteration 2472 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [6.0, 8.0]
Iteration 2473 ended with reward tensor([-0.3000]), enemy health [2.0, 9], model health [6.0, 6.0]
Iteration 2474 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 6.0]
Iteration 2475 ended with reward tensor([0.]), enemy health [0, 9], model health [0.0, 2.0]
Iteration 2476 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 2.0]
Iteration 2477 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 2478 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 2479 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 7.0]
Iteration 2480 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [3.0, 6.0]
Iteration 2481 ended with reward tensor([-1.]), enemy health [2.0, 9], model health [3.0, 4.0]
Iteration 2482 ended with reward tensor([0.2000]), enemy health [0, 9], model health [3.0, 4.0]
Iteration 2483 ended with reward tensor([0]), enemy health [0, 9], model health [3.0, 1.0]
Iteration 2484 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 1.0]
Iteration 2485 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 1.0]
Iteration 2486 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0, 1.0]
model won!
Iteration 2487 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2488 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2489 ended with reward tensor([-0.3000]), enemy health [6.0, 9], model health [5.0, 8.0]
Iteration 2490 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [5.0, 6.0]
Iteration 2491 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [3.0, 6.0]
Iteration 2492 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 6.0]
Iteration 2493 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 5.0]
Iteration 2494 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0, 1.0]
Iteration 2495 ended with reward tensor([-1.]), enemy health [2.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 2496 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 2497 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 2498 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 2499 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 7.0]
Iteration 2500 ended with reward tensor([0.4000]), enemy health [0, 9], model health [5.0, 7.0]
Iteration 2501 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [5.0, 5.0]
Iteration 2502 ended with reward tensor([-1.]), enemy health [0, 9], model health [2.0, 5.0]
Iteration 2503 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 5.0]
Iteration 2504 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 3.0]
Iteration 2505 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 2506 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 2507 ended with reward tensor([0.5000]), enemy health [8, 9], model health [0.0, 9]
Iteration 2508 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 2509 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0.0, 8.0]
Iteration 2510 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 8.0]
Iteration 2511 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2512 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2513 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2514 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2515 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 2516 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 6.0]
Iteration 2517 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 5.0]
Iteration 2518 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 5.0]
Iteration 2519 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 1.0]
Iteration 2520 ended with reward tensor([-1.]), enemy health [0.0, 5.0], model health [0.0, 1.0]
Iteration 2521 ended with reward tensor([-1.]), enemy health [0.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 2522 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9]
Iteration 2523 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 9]
Iteration 2524 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [0.0, 9.0]
Iteration 2525 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 9.0]
Iteration 2526 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 8.0]
Iteration 2527 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 7.0]
Iteration 2528 ended with reward tensor([-0.5000]), enemy health [4.0, 8.0], model health [0.0, 5.0]
Iteration 2529 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 1.0]
Iteration 2530 ended with reward tensor([-1.]), enemy health [3.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 2531 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2532 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2533 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 9]
Iteration 2534 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 2535 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 2536 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 9.0]
Iteration 2537 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 9.0]
Iteration 2538 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 8.0]
Iteration 2539 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 8.0]
Iteration 2540 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 8.0]
Iteration 2541 ended with reward tensor([-0.5000]), enemy health [1.0, 4.0], model health [0.0, 8.0]
Iteration 2542 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 6.0]
Iteration 2543 ended with reward tensor([-0.5000]), enemy health [1.0, 2.0], model health [0.0, 5.0]
Iteration 2544 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 3.0]
Iteration 2545 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 3.0]
Iteration 2546 ended with reward tensor([1.]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2547 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2548 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2549 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2550 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2551 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2552 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2553 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2554 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2555 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2556 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2557 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2558 ended with reward tensor([1.2000]), enemy health [0, 0], model health [0.0, 3.0]
model won!
Iteration 2559 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2560 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2561 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [6.0, 9]
Iteration 2562 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [2.0, 9]
Iteration 2563 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0.0, 9]
Iteration 2564 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0.0, 9]
Iteration 2565 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [0.0, 9]
Iteration 2566 ended with reward tensor([-0.5000]), enemy health [7.0, 8.0], model health [0.0, 9]
Iteration 2567 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 9]
Iteration 2568 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0.0, 9.0]
Iteration 2569 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 2570 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 9.0]
Iteration 2571 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 9.0]
Iteration 2572 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 9.0]
Iteration 2573 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 2574 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 7.0]
Iteration 2575 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0]
Iteration 2576 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2577 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2578 ended with reward tensor([-0.5000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2579 ended with reward tensor([-1.]), enemy health [0.0, 1.0], model health [0.0, 0.0]
enemy won!
Iteration 2580 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 2581 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [3.0, 9.0]
Iteration 2582 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 2583 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 2584 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 7.0]
Iteration 2585 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0.0, 7.0]
Iteration 2586 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 7.0]
Iteration 2587 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 7.0]
Iteration 2588 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 7.0]
Iteration 2589 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 7.0]
Iteration 2590 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 7.0]
Iteration 2591 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 2592 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 2593 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [1.0, 7.0]
Iteration 2594 ended with reward tensor([0.7000]), enemy health [0, 9], model health [1.0, 5.0]
Iteration 2595 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [1.0, 4.0]
Iteration 2596 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [1.0, 4.0]
Iteration 2597 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 4.0]
Iteration 2598 ended with reward tensor([0.]), enemy health [0, 9], model health [0.0, 3.0]
Iteration 2599 ended with reward tensor([-1.]), enemy health [0, 9], model health [0.0, 0]
enemy won!
Iteration 2600 ended with reward tensor([0.2000]), enemy health [8, 6.0], model health [4.0, 9]
Iteration 2601 ended with reward tensor([-0.5000]), enemy health [8, 6.0], model health [1.0, 9]
Iteration 2602 ended with reward tensor([0.2000]), enemy health [6.0, 6.0], model health [1.0, 8.0]
Iteration 2603 ended with reward tensor([0.9000]), enemy health [2.0, 6.0], model health [1.0, 7.0]
Iteration 2604 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 7.0]
Iteration 2605 ended with reward tensor([0.]), enemy health [0, 6.0], model health [0.0, 7.0]
Iteration 2606 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0.0, 5.0]
Iteration 2607 ended with reward tensor([0]), enemy health [0, 6.0], model health [0.0, 2.0]
Iteration 2608 ended with reward tensor([0]), enemy health [0, 6.0], model health [0.0, 1.0]
Iteration 2609 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 1.0]
Iteration 2610 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 2611 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2612 ended with reward tensor([0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 2613 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [0, 9]
Iteration 2614 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 2615 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0, 7.0]
Iteration 2616 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 7.0]
Iteration 2617 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 6.0]
Iteration 2618 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 6.0]
Iteration 2619 ended with reward tensor([0]), enemy health [0, 9], model health [0, 3.0]
Iteration 2620 ended with reward tensor([0]), enemy health [0, 9], model health [0, 2.0]
Iteration 2621 ended with reward tensor([-1.]), enemy health [0, 9], model health [0, 0.0]
enemy won!
Iteration 2622 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 2623 ended with reward tensor([0]), enemy health [8, 9], model health [0.0, 9]
Iteration 2624 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 2625 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 6.0]
Iteration 2626 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 6.0]
Iteration 2627 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [0.0, 6.0]
Iteration 2628 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 2629 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 2630 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 6.0]
Iteration 2631 ended with reward tensor([-0.5000]), enemy health [2.0, 0.0], model health [0.0, 6.0]
Iteration 2632 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 6.0]
model won!
Iteration 2633 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [6.0, 9]
Iteration 2634 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [6.0, 9]
Iteration 2635 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [6.0, 9]
Iteration 2636 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9]
Iteration 2637 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9]
Iteration 2638 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9]
Iteration 2639 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [2.0, 9]
Iteration 2640 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [2.0, 6.0]
Iteration 2641 ended with reward tensor([0.7000]), enemy health [6.0, 4.0], model health [2.0, 6.0]
Iteration 2642 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [2.0, 5.0]
Iteration 2643 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [2.0, 1.0]
Iteration 2644 ended with reward tensor([0.5000]), enemy health [4.0, 4.0], model health [2.0, 0.0]
Iteration 2645 ended with reward tensor([0.5000]), enemy health [4.0, 4.0], model health [2.0, 0.0]
Iteration 2646 ended with reward tensor([-0.5000]), enemy health [4.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 2647 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 2648 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 2649 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 8.0]
Iteration 2650 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [5.0, 5.0]
Iteration 2651 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [1.0, 5.0]
Iteration 2652 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [1.0, 3.0]
Iteration 2653 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [1.0, 3.0]
Iteration 2654 ended with reward tensor([0]), enemy health [3.0, 6.0], model health [1.0, 0.0]
Iteration 2655 ended with reward tensor([0.5000]), enemy health [3.0, 6.0], model health [1.0, 0.0]
Iteration 2656 ended with reward tensor([0]), enemy health [3.0, 6.0], model health [1.0, 0.0]
Iteration 2657 ended with reward tensor([-1.]), enemy health [3.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 2658 ended with reward tensor([0.5000]), enemy health [8, 9], model health [1.0, 9]
Iteration 2659 ended with reward tensor([0.5000]), enemy health [8, 9], model health [1.0, 9.0]
Iteration 2660 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9.0]
Iteration 2661 ended with reward tensor([0.]), enemy health [8, 9], model health [0, 8.0]
Iteration 2662 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0, 5.0]
Iteration 2663 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0, 5.0]
Iteration 2664 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0, 5.0]
Iteration 2665 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0, 5.0]
Iteration 2666 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 4.0]
Iteration 2667 ended with reward tensor([-0.3000]), enemy health [0, 7.0], model health [0.0, 4.0]
Iteration 2668 ended with reward tensor([0]), enemy health [0, 7.0], model health [0.0, 2.0]
Iteration 2669 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 1.0]
Iteration 2670 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 2671 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 2672 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 2673 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 2674 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [5.0, 8.0]
Iteration 2675 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [1.0, 8.0]
Iteration 2676 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 2677 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 5.0]
Iteration 2678 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 2679 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 3.0]
Iteration 2680 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 1.0]
Iteration 2681 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 2682 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2683 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [5.0, 9.0]
Iteration 2684 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [1.0, 9.0]
Iteration 2685 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 9.0]
Iteration 2686 ended with reward tensor([-0.5000]), enemy health [-6.0, 9], model health [0.0, 5.0]
Iteration 2687 ended with reward tensor([0]), enemy health [-6.0, 9], model health [0.0, 3.0]
Iteration 2688 ended with reward tensor([0.7000]), enemy health [-6.0, 8.0], model health [0.0, 1.0]
Iteration 2689 ended with reward tensor([1.7000]), enemy health [-6.0, 4.0], model health [0.0, 1.0]
model won!
Iteration 2690 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 2691 ended with reward tensor([-1.]), enemy health [8, 9], model health [5.0, 8.0]
Iteration 2692 ended with reward tensor([-0.3000]), enemy health [5.0, 9], model health [5.0, 6.0]
Iteration 2693 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 6.0]
Iteration 2694 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0, 6.0]
Iteration 2695 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0.0, 6.0]
Iteration 2696 ended with reward tensor([-0.5000]), enemy health [3.0, 9.0], model health [0.0, 5.0]
Iteration 2697 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 5.0]
Iteration 2698 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 5.0]
Iteration 2699 ended with reward tensor([0.7000]), enemy health [3.0, 4.0], model health [0.0, 4.0]
Iteration 2700 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 4.0]
Iteration 2701 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 4.0]
Iteration 2702 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 4.0]
Iteration 2703 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2704 ended with reward tensor([1.7000]), enemy health [0, 0.0], model health [0.0, 3.0]
model won!
Iteration 2705 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 2706 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [4.0, 9]
Iteration 2707 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [2.0, 9]
Iteration 2708 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 2709 ended with reward tensor([-0.5000]), enemy health [-7.0, 9], model health [0.0, 7.0]
Iteration 2710 ended with reward tensor([-0.5000]), enemy health [-7.0, 9], model health [0.0, 6.0]
Iteration 2711 ended with reward tensor([-0.5000]), enemy health [-7.0, 9], model health [0.0, 5.0]
Iteration 2712 ended with reward tensor([-1.]), enemy health [-7.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 2713 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 2714 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [1.0, 9]
Iteration 2715 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 2716 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 2717 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 2718 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 2719 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 2720 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 2721 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 2722 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 2723 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 1.0]
Iteration 2724 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 1.0]
Iteration 2725 ended with reward tensor([-1.]), enemy health [0.0, 2.0], model health [0.0, 0]
enemy won!
Iteration 2726 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2727 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2728 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2729 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2730 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [6.0, 9]
Iteration 2731 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [6.0, 9]
Iteration 2732 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [3.0, 9]
Iteration 2733 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [2.0, 9]
Iteration 2734 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0, 8.0]
Iteration 2735 ended with reward tensor([0.7000]), enemy health [7.0, 8.0], model health [0, 7.0]
Iteration 2736 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0, 5.0]
Iteration 2737 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0, 3.0]
Iteration 2738 ended with reward tensor([0.7000]), enemy health [7.0, 3.0], model health [0, 1.0]
Iteration 2739 ended with reward tensor([-1.]), enemy health [7.0, 3.0], model health [0, 0]
enemy won!
Iteration 2740 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 2741 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 7.0]
Iteration 2742 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [3.0, 7.0]
Iteration 2743 ended with reward tensor([-0.5000]), enemy health [-6.0, 9], model health [0.0, 6.0]
Iteration 2744 ended with reward tensor([-0.5000]), enemy health [-6.0, 9], model health [0.0, 6.0]
Iteration 2745 ended with reward tensor([0.7000]), enemy health [-6.0, 9.0], model health [0.0, 6.0]
Iteration 2746 ended with reward tensor([1.7000]), enemy health [-6.0, 5.0], model health [0.0, 5.0]
model won!
Iteration 2747 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2748 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 2749 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [5.0, 7.0]
Iteration 2750 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 2751 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 2752 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 7.0]
Iteration 2753 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 5.0]
Iteration 2754 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 5.0]
Iteration 2755 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 5.0]
Iteration 2756 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 4.0]
Iteration 2757 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 2.0]
Iteration 2758 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [0.0, 2.0]
Iteration 2759 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 2760 ended with reward tensor([0.2000]), enemy health [8, 9], model health [8, 9]
Iteration 2761 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [8, 9]
Iteration 2762 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [7.0, 9]
Iteration 2763 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [2.0, 9]
Iteration 2764 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0, 9.0]
Iteration 2765 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0, 9.0]
Iteration 2766 ended with reward tensor([-0.5000]), enemy health [8.0, 9], model health [0, 9.0]
Iteration 2767 ended with reward tensor([0.7000]), enemy health [8.0, 9], model health [0, 6.0]
Iteration 2768 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0, 6.0]
Iteration 2769 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 6.0]
Iteration 2770 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 2771 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 6.0]
Iteration 2772 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 5.0]
Iteration 2773 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 5.0]
Iteration 2774 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 5.0]
Iteration 2775 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 5.0]
Iteration 2776 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 4.0]
Iteration 2777 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 4.0]
Iteration 2778 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 2.0]
Iteration 2779 ended with reward tensor([-1.]), enemy health [3.0, 9.0], model health [0, 0.0]
enemy won!
Iteration 2780 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8.0, 8.0]
Iteration 2781 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8.0, 7.0]
Iteration 2782 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [5.0, 7.0]
Iteration 2783 ended with reward tensor([0]), enemy health [0.0, 9], model health [5.0, 7.0]
Iteration 2784 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [2.0, 7.0]
Iteration 2785 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 2786 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 2787 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 2788 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 2.0]
Iteration 2789 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 2.0]
Iteration 2790 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 2.0]
Iteration 2791 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2792 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 2793 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 2.0]
model won!
Iteration 2794 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2795 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 2796 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 7.0]
Iteration 2797 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [3.0, 3.0]
Iteration 2798 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [3.0, 3.0]
Iteration 2799 ended with reward tensor([0.7000]), enemy health [8.0, 6.0], model health [3.0, 3.0]
Iteration 2800 ended with reward tensor([0]), enemy health [8.0, 6.0], model health [3.0, 1.0]
Iteration 2801 ended with reward tensor([-1.]), enemy health [8.0, 6.0], model health [3.0, 1.0]
Iteration 2802 ended with reward tensor([0]), enemy health [8.0, 6.0], model health [0.0, 1.0]
Iteration 2803 ended with reward tensor([-0.5000]), enemy health [8.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 2804 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2805 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [6.0, 9]
Iteration 2806 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [6.0, 9.0]
Iteration 2807 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0.0, 9.0]
Iteration 2808 ended with reward tensor([0.7000]), enemy health [2.0, 4.0], model health [0.0, 9.0]
Iteration 2809 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0.0, 9.0]
Iteration 2810 ended with reward tensor([1.]), enemy health [2.0, 0], model health [0.0, 9.0]
Iteration 2811 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 9.0]
Iteration 2812 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 9.0]
model won!
Iteration 2813 ended with reward tensor([-1.]), enemy health [8, 9], model health [5.0, 9]
Iteration 2814 ended with reward tensor([-1.]), enemy health [8, 9], model health [1.0, 9]
Iteration 2815 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [1.0, 8.0]
Iteration 2816 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0, 8.0]
Iteration 2817 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 8.0]
Iteration 2818 ended with reward tensor([-0.5000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 2819 ended with reward tensor([-1.]), enemy health [5.0, 8.0], model health [0, 0]
enemy won!
Iteration 2820 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 2821 ended with reward tensor([0]), enemy health [8, 9], model health [8, 5.0]
Iteration 2822 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 5.0]
Iteration 2823 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 4.0]
Iteration 2824 ended with reward tensor([0.9000]), enemy health [3.0, 8.0], model health [8, 3.0]
Iteration 2825 ended with reward tensor([-0.5000]), enemy health [3.0, 8.0], model health [3.0, 3.0]
Iteration 2826 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 3.0]
Iteration 2827 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 3.0]
Iteration 2828 ended with reward tensor([1.]), enemy health [0, 8.0], model health [0, 3.0]
Iteration 2829 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 1.0]
Iteration 2830 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0, 1.0]
Iteration 2831 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 1.0]
Iteration 2832 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [0, 0.0]
enemy won!
Iteration 2833 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2834 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2835 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 2836 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 2837 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [8, 3.0]
Iteration 2838 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [8, 1.0]
Iteration 2839 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [7.0, 0.0]
Iteration 2840 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [7.0, 0.0]
Iteration 2841 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [7.0, 0]
Iteration 2842 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0]
Iteration 2843 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0.0]
Iteration 2844 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0.0]
Iteration 2845 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0.0]
Iteration 2846 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0.0]
Iteration 2847 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0]
Iteration 2848 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0]
Iteration 2849 ended with reward tensor([0]), enemy health [1.0, 8.0], model health [6.0, 0]
Iteration 2850 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [3.0, 0]
Iteration 2851 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 0]
enemy won!
Iteration 2852 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2853 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 8.0]
Iteration 2854 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [3.0, 8.0]
Iteration 2855 ended with reward tensor([1.]), enemy health [0.0, 9], model health [3.0, 8.0]
Iteration 2856 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [3.0, 3.0]
Iteration 2857 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [3.0, 2.0]
Iteration 2858 ended with reward tensor([0.5000]), enemy health [0.0, 9.0], model health [3.0, 0]
Iteration 2859 ended with reward tensor([0]), enemy health [0.0, 9.0], model health [3.0, 0]
Iteration 2860 ended with reward tensor([-1.5000]), enemy health [0.0, 9.0], model health [0.0, 0]
enemy won!
Iteration 2861 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2862 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 2863 ended with reward tensor([0.]), enemy health [8, 9], model health [0.0, 7.0]
Iteration 2864 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 2865 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 3.0]
Iteration 2866 ended with reward tensor([-0.5000]), enemy health [5.0, 6.0], model health [0.0, 2.0]
Iteration 2867 ended with reward tensor([-1.]), enemy health [5.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 2868 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2869 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2870 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [4.0, 9]
Iteration 2871 ended with reward tensor([-0.5000]), enemy health [5.0, 9], model health [4.0, 9.0]
Iteration 2872 ended with reward tensor([-0.3000]), enemy health [2.0, 9], model health [2.0, 9.0]
Iteration 2873 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 2874 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 2875 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 7.0]
Iteration 2876 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 6.0]
Iteration 2877 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 2878 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 4.0]
Iteration 2879 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 3.0]
Iteration 2880 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 1.0]
Iteration 2881 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 1.0]
Iteration 2882 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0, 0.0]
enemy won!
Iteration 2883 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9]
Iteration 2884 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [6.0, 9]
Iteration 2885 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 2886 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 2887 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 8.0]
Iteration 2888 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0.0, 8.0]
Iteration 2889 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0.0, 5.0]
Iteration 2890 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 4.0]
Iteration 2891 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 2892 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 2.0]
Iteration 2893 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 1.0]
Iteration 2894 ended with reward tensor([-0.5000]), enemy health [0.0, 3.0], model health [0.0, 0]
enemy won!
Iteration 2895 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 2896 ended with reward tensor([0]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 2897 ended with reward tensor([0]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 2898 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [3.0, 7.0]
Iteration 2899 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 2900 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 2901 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 2902 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 2903 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 4.0]
Iteration 2904 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 4.0]
Iteration 2905 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 4.0]
Iteration 2906 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 4.0]
Iteration 2907 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 4.0]
Iteration 2908 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 4.0]
Iteration 2909 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 4.0]
model won!
Iteration 2910 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 2911 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 2912 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [4.0, 9]
Iteration 2913 ended with reward tensor([0.9000]), enemy health [1.0, 9], model health [2.0, 9]
Iteration 2914 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [2.0, 7.0]
Iteration 2915 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [2.0, 6.0]
Iteration 2916 ended with reward tensor([-0.5000]), enemy health [1.0, 7.0], model health [2.0, 6.0]
Iteration 2917 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 3.0]
Iteration 2918 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 3.0]
Iteration 2919 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 3.0]
Iteration 2920 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 3.0]
Iteration 2921 ended with reward tensor([1.]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2922 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2923 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2924 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2925 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2926 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2927 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2928 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2929 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2930 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 3.0]
Iteration 2931 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 2.0]
Iteration 2932 ended with reward tensor([0]), enemy health [1.0, 0], model health [0.0, 2.0]
Iteration 2933 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 2.0]
Iteration 2934 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 2.0]
Iteration 2935 ended with reward tensor([0.5000]), enemy health [1.0, 0], model health [0.0, 2.0]
Iteration 2936 ended with reward tensor([1.7000]), enemy health [0, 0], model health [0.0, 2.0]
model won!
Iteration 2937 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 8.0]
Iteration 2938 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 2939 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8, 7.0]
Iteration 2940 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [8, 6.0]
Iteration 2941 ended with reward tensor([-1.]), enemy health [0, 9], model health [8, 6.0]
Iteration 2942 ended with reward tensor([-1.]), enemy health [0, 9], model health [2.0, 6.0]
Iteration 2943 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [2.0, 1.0]
Iteration 2944 ended with reward tensor([0]), enemy health [0, 7.0], model health [2.0, 1.0]
Iteration 2945 ended with reward tensor([0]), enemy health [0, 7.0], model health [1.0, 0.0]
Iteration 2946 ended with reward tensor([-1.]), enemy health [0, 7.0], model health [0, 0.0]
enemy won!
Iteration 2947 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 2948 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 2949 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [0, 9]
Iteration 2950 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [0, 9]
Iteration 2951 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 9]
Iteration 2952 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 9]
Iteration 2953 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9]
Iteration 2954 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 2955 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 2956 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 2957 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 5.0]
Iteration 2958 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 4.0]
Iteration 2959 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 4.0]
Iteration 2960 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 4.0]
Iteration 2961 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 3.0]
Iteration 2962 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 3.0]
Iteration 2963 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 2.0]
model won!
Iteration 2964 ended with reward tensor([0.]), enemy health [8, 9], model health [8, 6.0]
Iteration 2965 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [4.0, 6.0]
Iteration 2966 ended with reward tensor([-1.]), enemy health [8, 8.0], model health [2.0, 6.0]
Iteration 2967 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [2.0, 5.0]
Iteration 2968 ended with reward tensor([0.7000]), enemy health [8.0, 6.0], model health [2.0, 3.0]
Iteration 2969 ended with reward tensor([0.7000]), enemy health [8.0, 5.0], model health [0, 3.0]
Iteration 2970 ended with reward tensor([0.7000]), enemy health [8.0, 3.0], model health [0, 3.0]
Iteration 2971 ended with reward tensor([0.7000]), enemy health [8.0, 1.0], model health [0.0, 3.0]
Iteration 2972 ended with reward tensor([1.]), enemy health [8.0, 0.0], model health [0.0, 3.0]
Iteration 2973 ended with reward tensor([0.7000]), enemy health [8.0, 0.0], model health [0.0, 3.0]
Iteration 2974 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 3.0]
Iteration 2975 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 3.0]
Iteration 2976 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 3.0]
Iteration 2977 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 3.0]
Iteration 2978 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 3.0]
Iteration 2979 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 3.0]
Iteration 2980 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 2981 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 2982 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 2983 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 2984 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 2985 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [7.0, 8.0]
Iteration 2986 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [6.0, 8.0]
Iteration 2987 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [6.0, 7.0]
Iteration 2988 ended with reward tensor([1.]), enemy health [0.0, 9], model health [5.0, 7.0]
Iteration 2989 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 7.0]
Iteration 2990 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 2991 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 2992 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 2993 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 2994 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 2995 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 2996 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 2997 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0]
Iteration 2998 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0]
Iteration 2999 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 3.0]
Iteration 3000 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 3001 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3002 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [2.0, 9.0]
Iteration 3003 ended with reward tensor([0.9000]), enemy health [0, 9], model health [2.0, 7.0]
Iteration 3004 ended with reward tensor([0]), enemy health [0, 9], model health [0, 7.0]
Iteration 3005 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 7.0]
Iteration 3006 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 6.0]
Iteration 3007 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 2.0]
Iteration 3008 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 1.0]
Iteration 3009 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0, 1.0]
Iteration 3010 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0, 0.0]
enemy won!
Iteration 3011 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3012 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [6.0, 9.0]
Iteration 3013 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [6.0, 8.0]
Iteration 3014 ended with reward tensor([1.]), enemy health [0, 9], model health [1.0, 8.0]
Iteration 3015 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 8.0]
Iteration 3016 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 8.0]
Iteration 3017 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 8.0]
Iteration 3018 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0, 3.0]
Iteration 3019 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 3.0]
Iteration 3020 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 0.0]
enemy won!
Iteration 3021 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3022 ended with reward tensor([0.2000]), enemy health [8, 9], model health [8, 9]
Iteration 3023 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [5.0, 9]
Iteration 3024 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 3025 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 3026 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 3027 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 3028 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 3029 ended with reward tensor([1.]), enemy health [0, 9], model health [0.0, 9]
Iteration 3030 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 7.0]
Iteration 3031 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [0.0, 5.0]
Iteration 3032 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 4.0]
Iteration 3033 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 4.0]
Iteration 3034 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 2.0]
Iteration 3035 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 2.0]
Iteration 3036 ended with reward tensor([-1.]), enemy health [0, 3.0], model health [0.0, 0]
enemy won!
Iteration 3037 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3038 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3039 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 3040 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 3041 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 6.0]
Iteration 3042 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [6.0, 6.0]
Iteration 3043 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 6.0]
Iteration 3044 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 6.0]
Iteration 3045 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 6.0]
Iteration 3046 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 6.0]
Iteration 3047 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 6.0]
Iteration 3048 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 6.0]
Iteration 3049 ended with reward tensor([1.]), enemy health [1.0, 0], model health [0.0, 6.0]
Iteration 3050 ended with reward tensor([1.2000]), enemy health [0, 0], model health [0.0, 6.0]
model won!
Iteration 3051 ended with reward tensor([0.2000]), enemy health [8, 8.0], model health [8, 9]
Iteration 3052 ended with reward tensor([0.4000]), enemy health [5.0, 8.0], model health [8, 5.0]
Iteration 3053 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [5.0, 5.0]
Iteration 3054 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [3.0, 5.0]
Iteration 3055 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0, 5.0]
Iteration 3056 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 4.0]
Iteration 3057 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 4.0]
Iteration 3058 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 4.0]
Iteration 3059 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0, 4.0]
Iteration 3060 ended with reward tensor([-0.5000]), enemy health [4.0, 5.0], model health [0, 4.0]
Iteration 3061 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0, 4.0]
Iteration 3062 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0, 4.0]
Iteration 3063 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 4.0]
Iteration 3064 ended with reward tensor([0.7000]), enemy health [3.0, 4.0], model health [0, 4.0]
Iteration 3065 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 4.0]
Iteration 3066 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 4.0]
Iteration 3067 ended with reward tensor([1.]), enemy health [0.0, 2.0], model health [0.0, 4.0]
Iteration 3068 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 3.0]
model won!
Iteration 3069 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 3070 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 8.0]
Iteration 3071 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [4.0, 8.0]
Iteration 3072 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0.0, 8.0]
Iteration 3073 ended with reward tensor([0.7000]), enemy health [8, 2.0], model health [0.0, 8.0]
Iteration 3074 ended with reward tensor([1.]), enemy health [8, 0.0], model health [0.0, 8.0]
Iteration 3075 ended with reward tensor([0.7000]), enemy health [8.0, 0.0], model health [0.0, 8.0]
Iteration 3076 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 8.0]
Iteration 3077 ended with reward tensor([0.7000]), enemy health [6.0, 0.0], model health [0.0, 8.0]
Iteration 3078 ended with reward tensor([0.7000]), enemy health [5.0, 0.0], model health [0.0, 8.0]
Iteration 3079 ended with reward tensor([0.7000]), enemy health [5.0, 0.0], model health [0.0, 7.0]
Iteration 3080 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 7.0]
Iteration 3081 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3082 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 3083 ended with reward tensor([0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 3084 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3085 ended with reward tensor([0.2000]), enemy health [8, 9], model health [6.0, 9]
Iteration 3086 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [2.0, 9]
Iteration 3087 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0.0, 9]
Iteration 3088 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0.0, 9]
Iteration 3089 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0.0, 9]
Iteration 3090 ended with reward tensor([0.7000]), enemy health [7.0, 4.0], model health [0.0, 9]
Iteration 3091 ended with reward tensor([0.7000]), enemy health [7.0, 2.0], model health [0.0, 9]
Iteration 3092 ended with reward tensor([0.7000]), enemy health [7.0, 1.0], model health [0.0, 9]
Iteration 3093 ended with reward tensor([0.7000]), enemy health [7.0, 1.0], model health [0.0, 9]
Iteration 3094 ended with reward tensor([1.]), enemy health [7.0, 0.0], model health [0.0, 9]
Iteration 3095 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 9]
Iteration 3096 ended with reward tensor([-0.5000]), enemy health [7.0, 0.0], model health [0.0, 9.0]
Iteration 3097 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 9.0]
Iteration 3098 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 9.0]
Iteration 3099 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 9.0]
Iteration 3100 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 9.0]
Iteration 3101 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 9.0]
Iteration 3102 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 9.0]
model won!
Iteration 3103 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3104 ended with reward tensor([0.2000]), enemy health [8, 9], model health [6.0, 9]
Iteration 3105 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [5.0, 9]
Iteration 3106 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [1.0, 9]
Iteration 3107 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 3108 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 3109 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 9]
Iteration 3110 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9]
Iteration 3111 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 6.0]
Iteration 3112 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 6.0]
Iteration 3113 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 5.0]
Iteration 3114 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 3.0]
Iteration 3115 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 3.0]
model won!
Iteration 3116 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 3117 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [1.0, 9]
Iteration 3118 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 3119 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 3120 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 3121 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9]
Iteration 3122 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 9]
Iteration 3123 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 3124 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 7.0]
Iteration 3125 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 7.0]
Iteration 3126 ended with reward tensor([0.2000]), enemy health [0.0, 4.0], model health [0.0, 6.0]
Iteration 3127 ended with reward tensor([0.5000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 3128 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 3129 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 3130 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3131 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3132 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [8, 9.0]
Iteration 3133 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [7.0, 9.0]
Iteration 3134 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [3.0, 9.0]
Iteration 3135 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [3.0, 9.0]
Iteration 3136 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [2.0, 9.0]
Iteration 3137 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [1.0, 9.0]
Iteration 3138 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0, 9.0]
Iteration 3139 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0, 9.0]
Iteration 3140 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [0, 9.0]
Iteration 3141 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0, 9.0]
Iteration 3142 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0, 9.0]
Iteration 3143 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0, 9.0]
Iteration 3144 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [0, 9.0]
Iteration 3145 ended with reward tensor([0.5000]), enemy health [4.0, 0.0], model health [0, 9.0]
Iteration 3146 ended with reward tensor([0.5000]), enemy health [4.0, 0.0], model health [0, 8.0]
Iteration 3147 ended with reward tensor([1.2000]), enemy health [0.0, 0.0], model health [0, 8.0]
model won!
Iteration 3148 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 3149 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 8.0]
Iteration 3150 ended with reward tensor([0.4000]), enemy health [0, 9], model health [1.0, 5.0]
Iteration 3151 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [1.0, 5.0]
Iteration 3152 ended with reward tensor([-1.]), enemy health [0, 9], model health [1.0, 2.0]
Iteration 3153 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 2.0]
Iteration 3154 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 2.0]
Iteration 3155 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 2.0]
Iteration 3156 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 2.0]
Iteration 3157 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 2.0]
Iteration 3158 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 2.0]
model won!
Iteration 3159 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 3160 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 3161 ended with reward tensor([-1.]), enemy health [8, 9], model health [4.0, 9.0]
Iteration 3162 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [4.0, 8.0]
Iteration 3163 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0, 7.0]
Iteration 3164 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0, 6.0]
Iteration 3165 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [0.0, 6.0]
Iteration 3166 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0.0, 6.0]
Iteration 3167 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0.0, 6.0]
Iteration 3168 ended with reward tensor([0.7000]), enemy health [6.0, 1.0], model health [0.0, 6.0]
Iteration 3169 ended with reward tensor([1.]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3170 ended with reward tensor([0.5000]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3171 ended with reward tensor([0]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3172 ended with reward tensor([0.5000]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3173 ended with reward tensor([0.5000]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3174 ended with reward tensor([0.5000]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3175 ended with reward tensor([0]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3176 ended with reward tensor([0.5000]), enemy health [6.0, 0], model health [0, 6.0]
Iteration 3177 ended with reward tensor([0.5000]), enemy health [6.0, 0], model health [0, 5.0]
Iteration 3178 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [0, 5.0]
model won!
Iteration 3179 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3180 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [2.0, 9.0]
Iteration 3181 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 3182 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 9.0]
Iteration 3183 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 9.0]
Iteration 3184 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 9.0]
Iteration 3185 ended with reward tensor([1.]), enemy health [1.0, 0.0], model health [0.0, 8.0]
Iteration 3186 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0.0, 8.0]
Iteration 3187 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0.0, 8.0]
Iteration 3188 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3189 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3190 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3191 ended with reward tensor([0.5000]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3192 ended with reward tensor([0.5000]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3193 ended with reward tensor([0.5000]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3194 ended with reward tensor([0.5000]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3195 ended with reward tensor([0.5000]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3196 ended with reward tensor([1.2000]), enemy health [0, 0.0], model health [0.0, 7.0]
model won!
Iteration 3197 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3198 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 3199 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [1.0, 9]
Iteration 3200 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 3201 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 3202 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 3203 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 9]
Iteration 3204 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0.0, 9]
Iteration 3205 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 9.0]
Iteration 3206 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 9.0]
Iteration 3207 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 9.0]
Iteration 3208 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 9.0]
Iteration 3209 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 9.0]
Iteration 3210 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 9.0]
model won!
Iteration 3211 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 3212 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9.0]
Iteration 3213 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [2.0, 9.0]
Iteration 3214 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0, 9.0]
Iteration 3215 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 9.0]
Iteration 3216 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [0.0, 9.0]
Iteration 3217 ended with reward tensor([0.7000]), enemy health [6.0, 5.0], model health [0.0, 9.0]
Iteration 3218 ended with reward tensor([0.7000]), enemy health [6.0, 2.0], model health [0.0, 9.0]
Iteration 3219 ended with reward tensor([0.7000]), enemy health [6.0, 1.0], model health [0.0, 8.0]
Iteration 3220 ended with reward tensor([1.]), enemy health [6.0, 0.0], model health [0.0, 8.0]
Iteration 3221 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 8.0]
Iteration 3222 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 8.0]
Iteration 3223 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 8.0]
Iteration 3224 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 8.0]
model won!
Iteration 3225 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3226 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 3227 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [1.0, 9]
Iteration 3228 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [1.0, 9]
Iteration 3229 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [1.0, 9]
Iteration 3230 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 9]
Iteration 3231 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 9.0]
Iteration 3232 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 8.0]
Iteration 3233 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 6.0]
Iteration 3234 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0, 3.0]
Iteration 3235 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 2.0]
Iteration 3236 ended with reward tensor([-0.5000]), enemy health [0.0, 1.0], model health [0, 0]
enemy won!
Iteration 3237 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3238 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3239 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 3240 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [4.0, 9]
Iteration 3241 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 7.0]
Iteration 3242 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 6.0]
Iteration 3243 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 3244 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 3245 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 2.0]
Iteration 3246 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 2.0]
Iteration 3247 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 2.0]
Iteration 3248 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 2.0]
Iteration 3249 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 2.0]
Iteration 3250 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 3251 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 3252 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 3253 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 3254 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 2.0]
Iteration 3255 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 2.0]
Iteration 3256 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 2.0]
Iteration 3257 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 2.0]
Iteration 3258 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 2.0]
model won!
Iteration 3259 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3260 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 9]
Iteration 3261 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [8.0, 9]
Iteration 3262 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8.0, 9]
Iteration 3263 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [5.0, 9]
Iteration 3264 ended with reward tensor([1.]), enemy health [0, 9], model health [1.0, 9]
Iteration 3265 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 9]
Iteration 3266 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 7.0]
Iteration 3267 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 4.0]
Iteration 3268 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 4.0]
Iteration 3269 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 2.0]
Iteration 3270 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 2.0]
Iteration 3271 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0, 2.0]
Iteration 3272 ended with reward tensor([-0.5000]), enemy health [0, 3.0], model health [0, 0]
enemy won!
Iteration 3273 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 3274 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [6.0, 9]
Iteration 3275 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [1.0, 9.0]
Iteration 3276 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9.0]
Iteration 3277 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0, 9.0]
Iteration 3278 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0, 9.0]
Iteration 3279 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0, 9.0]
Iteration 3280 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [0, 9.0]
Iteration 3281 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 4.0]
Iteration 3282 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 4.0]
Iteration 3283 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0, 4.0]
Iteration 3284 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0, 4.0]
Iteration 3285 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0, 2.0]
Iteration 3286 ended with reward tensor([0.2000]), enemy health [0, 1.0], model health [0, 1.0]
Iteration 3287 ended with reward tensor([-1.]), enemy health [0, 1.0], model health [0, 0]
enemy won!
Iteration 3288 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3289 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3290 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 9]
Iteration 3291 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [4.0, 6.0]
Iteration 3292 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [1.0, 6.0]
Iteration 3293 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 6.0]
Iteration 3294 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 6.0]
Iteration 3295 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0.0, 6.0]
Iteration 3296 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 6.0]
Iteration 3297 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0.0, 6.0]
Iteration 3298 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 3299 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 6.0]
Iteration 3300 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 6.0]
Iteration 3301 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 6.0]
Iteration 3302 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 6.0]
model won!
Iteration 3303 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [8, 8.0]
Iteration 3304 ended with reward tensor([-0.3000]), enemy health [8, 7.0], model health [4.0, 8.0]
Iteration 3305 ended with reward tensor([0.9000]), enemy health [7.0, 7.0], model health [4.0, 8.0]
Iteration 3306 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [4.0, 6.0]
Iteration 3307 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [4.0, 5.0]
Iteration 3308 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [4.0, 3.0]
Iteration 3309 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [4.0, 1.0]
Iteration 3310 ended with reward tensor([0]), enemy health [3.0, 7.0], model health [4.0, 1.0]
Iteration 3311 ended with reward tensor([0]), enemy health [3.0, 7.0], model health [4.0, 0.0]
Iteration 3312 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [4.0, 0.0]
Iteration 3313 ended with reward tensor([-1.]), enemy health [3.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 3314 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3315 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 9.0]
Iteration 3316 ended with reward tensor([0.9000]), enemy health [8, 8.0], model health [1.0, 9.0]
Iteration 3317 ended with reward tensor([-0.3000]), enemy health [2.0, 8.0], model health [0.0, 9.0]
Iteration 3318 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0.0, 7.0]
Iteration 3319 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0.0, 7.0]
Iteration 3320 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 7.0]
Iteration 3321 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 7.0]
Iteration 3322 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 7.0]
Iteration 3323 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0.0, 7.0]
Iteration 3324 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0, 7.0]
Iteration 3325 ended with reward tensor([1.]), enemy health [0.0, 2.0], model health [0, 7.0]
Iteration 3326 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 6.0]
Iteration 3327 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 5.0]
Iteration 3328 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 3.0]
model won!
Iteration 3329 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [4.0, 9]
Iteration 3330 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [0, 9]
Iteration 3331 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0, 9]
Iteration 3332 ended with reward tensor([0.7000]), enemy health [6.0, 8.0], model health [0, 9]
Iteration 3333 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0, 9]
Iteration 3334 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [0, 9]
Iteration 3335 ended with reward tensor([0.7000]), enemy health [6.0, 6.0], model health [0, 9]
Iteration 3336 ended with reward tensor([0.7000]), enemy health [6.0, 4.0], model health [0.0, 9]
Iteration 3337 ended with reward tensor([0.7000]), enemy health [6.0, 4.0], model health [0.0, 9]
Iteration 3338 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0.0, 9]
Iteration 3339 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0.0, 9]
Iteration 3340 ended with reward tensor([0.7000]), enemy health [6.0, 3.0], model health [0.0, 9]
Iteration 3341 ended with reward tensor([0.7000]), enemy health [6.0, 1.0], model health [0.0, 9]
Iteration 3342 ended with reward tensor([1.]), enemy health [6.0, 0.0], model health [0.0, 9]
Iteration 3343 ended with reward tensor([1.2000]), enemy health [3.0, 0.0], model health [0.0, 9]
Iteration 3344 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 9]
Iteration 3345 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 9]
model won!
Iteration 3346 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 3347 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 3348 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 3349 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 3350 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 3351 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 3352 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 7.0]
Iteration 3353 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [0.0, 7.0]
Iteration 3354 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [0.0, 7.0]
Iteration 3355 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [0.0, 7.0]
Iteration 3356 ended with reward tensor([0.7000]), enemy health [8, 3.0], model health [0.0, 7.0]
Iteration 3357 ended with reward tensor([0.7000]), enemy health [8, 1.0], model health [0.0, 7.0]
Iteration 3358 ended with reward tensor([1.]), enemy health [8, 0], model health [0.0, 7.0]
Iteration 3359 ended with reward tensor([0.7000]), enemy health [7.0, 0], model health [0.0, 7.0]
Iteration 3360 ended with reward tensor([0.7000]), enemy health [5.0, 0], model health [0.0, 7.0]
Iteration 3361 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [0.0, 7.0]
Iteration 3362 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0.0, 7.0]
Iteration 3363 ended with reward tensor([1.2000]), enemy health [0, 0], model health [0.0, 7.0]
model won!
Iteration 3364 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3365 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [4.0, 9]
Iteration 3366 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [1.0, 9]
Iteration 3367 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 3368 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9]
Iteration 3369 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 3370 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9]
Iteration 3371 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 3372 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 4.0]
Iteration 3373 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 4.0]
Iteration 3374 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 4.0]
Iteration 3375 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 4.0]
model won!
Iteration 3376 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 3377 ended with reward tensor([0]), enemy health [8, 9], model health [0, 9]
Iteration 3378 ended with reward tensor([0]), enemy health [8, 9], model health [0, 9]
Iteration 3379 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 7.0]
Iteration 3380 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 3381 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 3382 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 7.0]
Iteration 3383 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 3384 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 7.0]
Iteration 3385 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 3386 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 7.0]
Iteration 3387 ended with reward tensor([0.2000]), enemy health [0.0, 9.0], model health [0, 7.0]
Iteration 3388 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 7.0]
Iteration 3389 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 7.0]
Iteration 3390 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 3.0]
Iteration 3391 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 3.0]
Iteration 3392 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 2.0]
Iteration 3393 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0, 0]
enemy won!
Iteration 3394 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 3395 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 4.0]
Iteration 3396 ended with reward tensor([0.9000]), enemy health [0, 9], model health [2.0, 4.0]
Iteration 3397 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [2.0, 2.0]
Iteration 3398 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [2.0, 1.0]
Iteration 3399 ended with reward tensor([0]), enemy health [0, 3.0], model health [2.0, 0.0]
Iteration 3400 ended with reward tensor([-0.5000]), enemy health [0, 3.0], model health [2.0, 0.0]
Iteration 3401 ended with reward tensor([-1.]), enemy health [0, 3.0], model health [0.0, 0.0]
enemy won!
Iteration 3402 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 3403 ended with reward tensor([0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 3404 ended with reward tensor([-1.]), enemy health [8, 9], model health [2.0, 8.0]
Iteration 3405 ended with reward tensor([-0.6000]), enemy health [5.0, 9], model health [2.0, 5.0]
Iteration 3406 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 5.0]
Iteration 3407 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 5.0]
Iteration 3408 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0, 5.0]
Iteration 3409 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0, 5.0]
Iteration 3410 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 5.0]
Iteration 3411 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 5.0]
Iteration 3412 ended with reward tensor([0.7000]), enemy health [5.0, 3.0], model health [0.0, 5.0]
Iteration 3413 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 5.0]
Iteration 3414 ended with reward tensor([1.]), enemy health [5.0, 0], model health [0.0, 5.0]
Iteration 3415 ended with reward tensor([1.2000]), enemy health [3.0, 0], model health [0.0, 5.0]
Iteration 3416 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0.0, 5.0]
Iteration 3417 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 5.0]
model won!
Iteration 3418 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 3419 ended with reward tensor([-0.3000]), enemy health [4.0, 9], model health [8, 9.0]
Iteration 3420 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [8, 7.0]
Iteration 3421 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [8.0, 6.0]
Iteration 3422 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [8.0, 5.0]
Iteration 3423 ended with reward tensor([-0.5000]), enemy health [2.0, 9.0], model health [8.0, 5.0]
Iteration 3424 ended with reward tensor([0.9000]), enemy health [0.0, 9.0], model health [8.0, 3.0]
Iteration 3425 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [7.0, 3.0]
Iteration 3426 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [5.0, 2.0]
Iteration 3427 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [5.0, 2.0]
Iteration 3428 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [5.0, 1.0]
Iteration 3429 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [5.0, 1.0]
Iteration 3430 ended with reward tensor([0]), enemy health [0.0, 3.0], model health [5.0, 0.0]
Iteration 3431 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [5.0, 0.0]
Iteration 3432 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0.0, 0.0]
enemy won!
Iteration 3433 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 3434 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 3435 ended with reward tensor([0.9000]), enemy health [2.0, 9], model health [3.0, 9]
Iteration 3436 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [1.0, 9]
Iteration 3437 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0, 9]
Iteration 3438 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 9]
Iteration 3439 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [0.0, 9]
Iteration 3440 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0.0, 9]
Iteration 3441 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 9]
Iteration 3442 ended with reward tensor([1.]), enemy health [2.0, 0.0], model health [0.0, 9]
Iteration 3443 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 9]
Iteration 3444 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 9]
Iteration 3445 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 9]
model won!
Iteration 3446 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3447 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 3448 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [4.0, 9.0]
Iteration 3449 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 3450 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 3451 ended with reward tensor([0]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 3452 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 8.0]
Iteration 3453 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 8.0]
Iteration 3454 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 8.0]
Iteration 3455 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 8.0]
model won!
Iteration 3456 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9]
Iteration 3457 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [2.0, 5.0]
Iteration 3458 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 3459 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 3460 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 3461 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 5.0]
Iteration 3462 ended with reward tensor([-0.5000]), enemy health [4.0, 9.0], model health [0.0, 5.0]
Iteration 3463 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0, 1.0]
Iteration 3464 ended with reward tensor([0]), enemy health [4.0, 8.0], model health [0, 1.0]
Iteration 3465 ended with reward tensor([-1.]), enemy health [4.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 3466 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3467 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3468 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [6.0, 9]
Iteration 3469 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9]
Iteration 3470 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0.0, 9]
Iteration 3471 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 9]
Iteration 3472 ended with reward tensor([0.7000]), enemy health [2.0, 4.0], model health [0.0, 9]
Iteration 3473 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [0.0, 9]
Iteration 3474 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0.0, 9]
Iteration 3475 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 9]
Iteration 3476 ended with reward tensor([1.]), enemy health [2.0, 0], model health [0.0, 9]
Iteration 3477 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 9]
model won!
Iteration 3478 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 3479 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [6.0, 9]
Iteration 3480 ended with reward tensor([0.4000]), enemy health [0, 9], model health [6.0, 8.0]
Iteration 3481 ended with reward tensor([-1.]), enemy health [0, 9], model health [1.0, 7.0]
Iteration 3482 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [1.0, 4.0]
Iteration 3483 ended with reward tensor([-2.]), enemy health [0, 8.0], model health [1.0, 4.0]
Iteration 3484 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 4.0]
Iteration 3485 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 4.0]
Iteration 3486 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 4.0]
Iteration 3487 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 4.0]
Iteration 3488 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 4.0]
Iteration 3489 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 4.0]
Iteration 3490 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 4.0]
model won!
Iteration 3491 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3492 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 3493 ended with reward tensor([0.4000]), enemy health [0, 9], model health [4.0, 7.0]
Iteration 3494 ended with reward tensor([0.]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 3495 ended with reward tensor([0.]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 3496 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0.0, 7.0]
Iteration 3497 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 7.0]
Iteration 3498 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 7.0]
Iteration 3499 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 7.0]
Iteration 3500 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 7.0]
Iteration 3501 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 7.0]
model won!
Iteration 3502 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3503 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 3504 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 3505 ended with reward tensor([0.4000]), enemy health [8, 9.0], model health [3.0, 7.0]
Iteration 3506 ended with reward tensor([-0.3000]), enemy health [4.0, 9.0], model health [0.0, 7.0]
Iteration 3507 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 7.0]
Iteration 3508 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 7.0]
Iteration 3509 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 7.0]
Iteration 3510 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 7.0]
Iteration 3511 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0.0, 7.0]
Iteration 3512 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 7.0]
Iteration 3513 ended with reward tensor([1.]), enemy health [3.0, 0], model health [0.0, 7.0]
Iteration 3514 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0.0, 7.0]
Iteration 3515 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0.0, 7.0]
Iteration 3516 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 7.0]
Iteration 3517 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 7.0]
Iteration 3518 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 7.0]
Iteration 3519 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 7.0]
Iteration 3520 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 7.0]
model won!
Iteration 3521 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3522 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 3523 ended with reward tensor([-0.3000]), enemy health [3.0, 9], model health [6.0, 9]
Iteration 3524 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [6.0, 4.0]
Iteration 3525 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [6.0, 3.0]
Iteration 3526 ended with reward tensor([0.2000]), enemy health [3.0, 6.0], model health [6.0, 0.0]
Iteration 3527 ended with reward tensor([0]), enemy health [3.0, 6.0], model health [6.0, 0.0]
Iteration 3528 ended with reward tensor([0]), enemy health [3.0, 6.0], model health [1.0, 0.0]
Iteration 3529 ended with reward tensor([0.5000]), enemy health [3.0, 6.0], model health [1.0, 0.0]
Iteration 3530 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 0]
enemy won!
Iteration 3531 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 3532 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 3533 ended with reward tensor([0.7000]), enemy health [0, 9], model health [0.0, 9.0]
Iteration 3534 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 8.0]
Iteration 3535 ended with reward tensor([0.]), enemy health [0, 9], model health [0.0, 8.0]
Iteration 3536 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 1.0]
Iteration 3537 ended with reward tensor([-1.]), enemy health [0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 3538 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3539 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 9]
Iteration 3540 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [8, 8.0]
Iteration 3541 ended with reward tensor([1.]), enemy health [0, 9], model health [4.0, 8.0]
Iteration 3542 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 5.0]
Iteration 3543 ended with reward tensor([-2.]), enemy health [0, 9], model health [4.0, 3.0]
Iteration 3544 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 3.0]
Iteration 3545 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 3.0]
Iteration 3546 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 3.0]
Iteration 3547 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 3.0]
model won!
Iteration 3548 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3549 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [5.0, 9]
Iteration 3550 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9]
Iteration 3551 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 9]
Iteration 3552 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 9]
Iteration 3553 ended with reward tensor([-0.5000]), enemy health [2.0, 8.0], model health [0, 8.0]
Iteration 3554 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0, 4.0]
Iteration 3555 ended with reward tensor([-0.5000]), enemy health [2.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 3556 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3557 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 3558 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 8.0]
Iteration 3559 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 3560 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 3561 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [6.0, 6.0]
Iteration 3562 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [3.0, 6.0]
Iteration 3563 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 6.0]
Iteration 3564 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 6.0]
Iteration 3565 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0, 6.0]
Iteration 3566 ended with reward tensor([0.7000]), enemy health [1.0, 4.0], model health [0, 6.0]
Iteration 3567 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 6.0]
Iteration 3568 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 6.0]
Iteration 3569 ended with reward tensor([1.]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 3570 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 3571 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 3572 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 3573 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 3574 ended with reward tensor([0]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 3575 ended with reward tensor([1.2000]), enemy health [0, 0.0], model health [0, 6.0]
model won!
Iteration 3576 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3577 ended with reward tensor([-1.]), enemy health [8, 9], model health [0, 9]
Iteration 3578 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [0, 8.0]
Iteration 3579 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0, 8.0]
Iteration 3580 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 8.0]
Iteration 3581 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [0.0, 8.0]
Iteration 3582 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0, 8.0]
Iteration 3583 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [0, 8.0]
Iteration 3584 ended with reward tensor([0.7000]), enemy health [8, 2.0], model health [0.0, 8.0]
Iteration 3585 ended with reward tensor([0.7000]), enemy health [8, 2.0], model health [0.0, 8.0]
Iteration 3586 ended with reward tensor([0.7000]), enemy health [8, 1.0], model health [0.0, 8.0]
Iteration 3587 ended with reward tensor([1.]), enemy health [8, 0.0], model health [0.0, 8.0]
Iteration 3588 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 5.0]
Iteration 3589 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 5.0]
Iteration 3590 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0.0, 5.0]
Iteration 3591 ended with reward tensor([0.7000]), enemy health [6.0, 0.0], model health [0.0, 5.0]
Iteration 3592 ended with reward tensor([0.7000]), enemy health [6.0, 0.0], model health [0.0, 5.0]
Iteration 3593 ended with reward tensor([0.7000]), enemy health [6.0, 0.0], model health [0.0, 5.0]
Iteration 3594 ended with reward tensor([0.7000]), enemy health [6.0, 0.0], model health [0.0, 5.0]
Iteration 3595 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 5.0]
Iteration 3596 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 5.0]
Iteration 3597 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 5.0]
Iteration 3598 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 5.0]
model won!
Iteration 3599 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3600 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3601 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3602 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3603 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 3604 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [5.0, 8.0]
Iteration 3605 ended with reward tensor([1.]), enemy health [0.0, 9], model health [5.0, 8.0]
Iteration 3606 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [1.0, 8.0]
Iteration 3607 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 8.0]
Iteration 3608 ended with reward tensor([0.4000]), enemy health [0.0, 9.0], model health [1.0, 7.0]
Iteration 3609 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [1.0, 6.0]
Iteration 3610 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [1.0, 4.0]
Iteration 3611 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0.0, 4.0]
Iteration 3612 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 4.0]
Iteration 3613 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 4.0]
Iteration 3614 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 4.0]
Iteration 3615 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 4.0]
Iteration 3616 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 4.0]
Iteration 3617 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 4.0]
Iteration 3618 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 4.0]
model won!
Iteration 3619 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 3620 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [6.0, 5.0]
Iteration 3621 ended with reward tensor([-1.5000]), enemy health [0.0, 9], model health [4.0, 4.0]
Iteration 3622 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 4.0]
Iteration 3623 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 4.0]
Iteration 3624 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 4.0]
Iteration 3625 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 4.0]
Iteration 3626 ended with reward tensor([-0.5000]), enemy health [0.0, 3.0], model health [0.0, 4.0]
Iteration 3627 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 3628 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 3629 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 3630 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 3631 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 3632 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0.0, 9]
Iteration 3633 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 3634 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 3635 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 7.0]
Iteration 3636 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 7.0]
Iteration 3637 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 7.0]
Iteration 3638 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 7.0]
model won!
Iteration 3639 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3640 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 3641 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [5.0, 9.0]
Iteration 3642 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 3643 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 3644 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 3645 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 9.0]
Iteration 3646 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 9.0]
Iteration 3647 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 9.0]
Iteration 3648 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 9.0]
Iteration 3649 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 9.0]
Iteration 3650 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 9.0]
model won!
Iteration 3651 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 9.0]
Iteration 3652 ended with reward tensor([0.2000]), enemy health [0, 9], model health [8, 8.0]
Iteration 3653 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [8, 7.0]
Iteration 3654 ended with reward tensor([-1.]), enemy health [0, 9], model health [6.0, 7.0]
Iteration 3655 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [2.0, 7.0]
Iteration 3656 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [1.0, 7.0]
Iteration 3657 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 7.0]
Iteration 3658 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 7.0]
Iteration 3659 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 7.0]
Iteration 3660 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 7.0]
Iteration 3661 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 7.0]
model won!
Iteration 3662 ended with reward tensor([0]), enemy health [8, 9], model health [3.0, 9]
Iteration 3663 ended with reward tensor([-1.]), enemy health [8, 9], model health [3.0, 7.0]
Iteration 3664 ended with reward tensor([0.]), enemy health [8, 9], model health [0, 7.0]
Iteration 3665 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0, 6.0]
Iteration 3666 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 6.0]
Iteration 3667 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 3668 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 3669 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 6.0]
Iteration 3670 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0, 6.0]
Iteration 3671 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 6.0]
Iteration 3672 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0, 6.0]
Iteration 3673 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 6.0]
Iteration 3674 ended with reward tensor([-0.5000]), enemy health [2.0, 1.0], model health [0.0, 6.0]
Iteration 3675 ended with reward tensor([1.]), enemy health [2.0, 0.0], model health [0.0, 6.0]
Iteration 3676 ended with reward tensor([0]), enemy health [2.0, 0.0], model health [0.0, 6.0]
Iteration 3677 ended with reward tensor([0]), enemy health [2.0, 0.0], model health [0.0, 6.0]
Iteration 3678 ended with reward tensor([1.2000]), enemy health [0.0, 0.0], model health [0.0, 6.0]
model won!
Iteration 3679 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 6.0]
Iteration 3680 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [6.0, 6.0]
Iteration 3681 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [5.0, 6.0]
Iteration 3682 ended with reward tensor([1.]), enemy health [0, 9], model health [2.0, 6.0]
Iteration 3683 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 4.0]
Iteration 3684 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 3.0]
Iteration 3685 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 3.0]
Iteration 3686 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 3.0]
Iteration 3687 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 1.0]
Iteration 3688 ended with reward tensor([-1.]), enemy health [0, 4.0], model health [0, 0.0]
enemy won!
Iteration 3689 ended with reward tensor([0.2000]), enemy health [8, 9], model health [5.0, 9]
Iteration 3690 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [0, 9]
Iteration 3691 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 8.0]
Iteration 3692 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 3693 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 3694 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 6.0]
Iteration 3695 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 4.0]
Iteration 3696 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 2.0]
Iteration 3697 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 0]
enemy won!
Iteration 3698 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3699 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3700 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3701 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3702 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9.0]
Iteration 3703 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8, 9.0]
Iteration 3704 ended with reward tensor([-0.3000]), enemy health [0.0, 9], model health [5.0, 9.0]
Iteration 3705 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [5.0, 8.0]
Iteration 3706 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [5.0, 8.0]
Iteration 3707 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [5.0, 8.0]
Iteration 3708 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [5.0, 8.0]
Iteration 3709 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [5.0, 6.0]
Iteration 3710 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [5.0, 2.0]
Iteration 3711 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [5.0, 1.0]
Iteration 3712 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [5.0, 0.0]
Iteration 3713 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [5.0, 0.0]
Iteration 3714 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [1.0, 0]
Iteration 3715 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [1.0, 0]
Iteration 3716 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0, 0.0]
enemy won!
Iteration 3717 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3718 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 3719 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 6.0]
Iteration 3720 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 6.0]
Iteration 3721 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 6.0]
Iteration 3722 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 6.0]
Iteration 3723 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0.0, 6.0]
Iteration 3724 ended with reward tensor([0.7000]), enemy health [3.0, 4.0], model health [0.0, 6.0]
Iteration 3725 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 6.0]
Iteration 3726 ended with reward tensor([1.]), enemy health [3.0, 0], model health [0.0, 6.0]
Iteration 3727 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0.0, 6.0]
Iteration 3728 ended with reward tensor([-0.5000]), enemy health [3.0, 0], model health [0.0, 6.0]
Iteration 3729 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0.0, 6.0]
Iteration 3730 ended with reward tensor([1.2000]), enemy health [0, 0], model health [0.0, 6.0]
model won!
Iteration 3731 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 3732 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [7.0, 8.0]
Iteration 3733 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [5.0, 8.0]
Iteration 3734 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 8.0]
Iteration 3735 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 7.0]
Iteration 3736 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 7.0]
Iteration 3737 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 3738 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 3739 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 3740 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 1.0]
Iteration 3741 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 3742 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9.0]
Iteration 3743 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [2.0, 9.0]
Iteration 3744 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [2.0, 7.0]
Iteration 3745 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [2.0, 7.0]
Iteration 3746 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [2.0, 5.0]
Iteration 3747 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [2.0, 3.0]
Iteration 3748 ended with reward tensor([-1.5000]), enemy health [0.0, 1.0], model health [2.0, 3.0]
Iteration 3749 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 3750 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 8.0]
Iteration 3751 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [8, 8.0]
Iteration 3752 ended with reward tensor([-1.]), enemy health [6.0, 9], model health [0, 8.0]
Iteration 3753 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0, 7.0]
Iteration 3754 ended with reward tensor([0.2000]), enemy health [3.0, 7.0], model health [0, 7.0]
Iteration 3755 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 1.0]
Iteration 3756 ended with reward tensor([-1.]), enemy health [3.0, 5.0], model health [0, 0.0]
enemy won!
Iteration 3757 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3758 ended with reward tensor([-0.3000]), enemy health [8, 9], model health [5.0, 9]
Iteration 3759 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [2.0, 8.0]
Iteration 3760 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [2.0, 7.0]
Iteration 3761 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 7.0]
Iteration 3762 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 7.0]
Iteration 3763 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 7.0]
Iteration 3764 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 7.0]
Iteration 3765 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0, 7.0]
Iteration 3766 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0, 7.0]
Iteration 3767 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 7.0]
Iteration 3768 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 7.0]
Iteration 3769 ended with reward tensor([1.]), enemy health [1.0, 0.0], model health [0.0, 7.0]
Iteration 3770 ended with reward tensor([1.7000]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 3771 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 3772 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 7.0]
Iteration 3773 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [4.0, 7.0]
Iteration 3774 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 3775 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 1.0]
Iteration 3776 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 3777 ended with reward tensor([0.5000]), enemy health [8, 9], model health [6.0, 9]
Iteration 3778 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [4.0, 9]
Iteration 3779 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [2.0, 9]
Iteration 3780 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 9]
Iteration 3781 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 9]
Iteration 3782 ended with reward tensor([-0.5000]), enemy health [1.0, 9.0], model health [0.0, 9]
Iteration 3783 ended with reward tensor([1.]), enemy health [0, 9.0], model health [0.0, 9]
Iteration 3784 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 8.0]
Iteration 3785 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 8.0]
Iteration 3786 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 7.0]
Iteration 3787 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 7.0]
Iteration 3788 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 5.0]
Iteration 3789 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 5.0]
Iteration 3790 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 3.0]
model won!
Iteration 3791 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 3792 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [1.0, 9]
Iteration 3793 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [1.0, 8.0]
Iteration 3794 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [1.0, 7.0]
Iteration 3795 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [1.0, 5.0]
Iteration 3796 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [1.0, 3.0]
Iteration 3797 ended with reward tensor([1.]), enemy health [0, 5.0], model health [1.0, 3.0]
Iteration 3798 ended with reward tensor([0.5000]), enemy health [0, 5.0], model health [1.0, 1.0]
Iteration 3799 ended with reward tensor([0.5000]), enemy health [0, 5.0], model health [1.0, 1.0]
Iteration 3800 ended with reward tensor([0]), enemy health [0, 5.0], model health [1.0, 1.0]
Iteration 3801 ended with reward tensor([0]), enemy health [0, 5.0], model health [1.0, 0]
Iteration 3802 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [1.0, 0]
Iteration 3803 ended with reward tensor([0.5000]), enemy health [0, 5.0], model health [1.0, 0.0]
Iteration 3804 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [1.0, 0.0]
Iteration 3805 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 3806 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 3807 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [5.0, 8.0]
Iteration 3808 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 3809 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 8.0]
Iteration 3810 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 3811 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 3.0]
Iteration 3812 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0]
enemy won!
Iteration 3813 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3814 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3815 ended with reward tensor([0.4000]), enemy health [8, 8.0], model health [4.0, 9]
Iteration 3816 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 9.0]
Iteration 3817 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 9.0]
Iteration 3818 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 9.0]
Iteration 3819 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0.0, 9.0]
Iteration 3820 ended with reward tensor([0.7000]), enemy health [5.0, 3.0], model health [0.0, 9.0]
Iteration 3821 ended with reward tensor([0.7000]), enemy health [5.0, 2.0], model health [0.0, 9.0]
Iteration 3822 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [0.0, 9.0]
Iteration 3823 ended with reward tensor([0.7000]), enemy health [5.0, 0.0], model health [0.0, 6.0]
Iteration 3824 ended with reward tensor([1.2000]), enemy health [1.0, 0.0], model health [0.0, 6.0]
Iteration 3825 ended with reward tensor([1.]), enemy health [1.0, 0], model health [0.0, 6.0]
Iteration 3826 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 6.0]
model won!
Iteration 3827 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 3828 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 6.0]
Iteration 3829 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [5.0, 6.0]
Iteration 3830 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [5.0, 6.0]
Iteration 3831 ended with reward tensor([-0.3000]), enemy health [0, 9], model health [2.0, 6.0]
Iteration 3832 ended with reward tensor([-1.]), enemy health [0, 9], model health [0, 6.0]
Iteration 3833 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 4.0]
Iteration 3834 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 2.0]
Iteration 3835 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [0, 0]
enemy won!
Iteration 3836 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3837 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 3838 ended with reward tensor([0.]), enemy health [8, 9], model health [3.0, 8.0]
Iteration 3839 ended with reward tensor([0.]), enemy health [8, 9], model health [0.0, 8.0]
Iteration 3840 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 7.0]
Iteration 3841 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [0.0, 4.0]
Iteration 3842 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0.0, 4.0]
Iteration 3843 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 4.0]
Iteration 3844 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 4.0]
Iteration 3845 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 4.0]
Iteration 3846 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 3.0]
Iteration 3847 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 2.0]
Iteration 3848 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 0]
enemy won!
Iteration 3849 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 3850 ended with reward tensor([0.5000]), enemy health [8, 9], model health [0, 9]
Iteration 3851 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 3852 ended with reward tensor([-0.5000]), enemy health [8, 8.0], model health [0.0, 9]
Iteration 3853 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 7.0]
Iteration 3854 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 4.0]
Iteration 3855 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0.0, 3.0]
Iteration 3856 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0.0, 2.0]
Iteration 3857 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0.0, 1.0]
Iteration 3858 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [0.0, 1.0]
Iteration 3859 ended with reward tensor([-0.5000]), enemy health [8, 4.0], model health [0.0, 0]
enemy won!
Iteration 3860 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3861 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [8, 9]
Iteration 3862 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 3863 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9.0]
Iteration 3864 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9.0]
Iteration 3865 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 3866 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 8.0]
Iteration 3867 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 8.0]
Iteration 3868 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 6.0]
Iteration 3869 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 4.0]
Iteration 3870 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 1.0]
Iteration 3871 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [0, 0]
enemy won!
Iteration 3872 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3873 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 3874 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9]
Iteration 3875 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 3876 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9]
Iteration 3877 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 9]
Iteration 3878 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 9]
Iteration 3879 ended with reward tensor([0.7000]), enemy health [1.0, 3.0], model health [0.0, 9]
Iteration 3880 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 9]
Iteration 3881 ended with reward tensor([1.]), enemy health [1.0, 0.0], model health [0.0, 9]
Iteration 3882 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 9]
model won!
Iteration 3883 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 8.0]
Iteration 3884 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 5.0]
Iteration 3885 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [8, 4.0]
Iteration 3886 ended with reward tensor([0.7000]), enemy health [-7.0, 9.0], model health [8, 2.0]
Iteration 3887 ended with reward tensor([1.7000]), enemy health [-7.0, 7.0], model health [8, 2.0]
model won!
Iteration 3888 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 9]
Iteration 3889 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [1.0, 9]
Iteration 3890 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 9]
Iteration 3891 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 9]
Iteration 3892 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 9]
Iteration 3893 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 9]
Iteration 3894 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 8.0]
Iteration 3895 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 8.0]
Iteration 3896 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 8.0]
Iteration 3897 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 6.0]
Iteration 3898 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 5.0]
Iteration 3899 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0.0, 5.0]
Iteration 3900 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 3901 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 3902 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 3903 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 3904 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [4.0, 7.0]
Iteration 3905 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 3906 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 7.0]
Iteration 3907 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 3908 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 3909 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 3910 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 3911 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 3912 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 3.0]
model won!
Iteration 3913 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 3914 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 3915 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 3916 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 3917 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [5.0, 8.0]
Iteration 3918 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [2.0, 8.0]
Iteration 3919 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 3920 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 3921 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 8.0]
Iteration 3922 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 3923 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 5.0]
Iteration 3924 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 3925 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 3926 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 3927 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 1.0]
Iteration 3928 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 1.0]
Iteration 3929 ended with reward tensor([-1.]), enemy health [0.0, 1.0], model health [0.0, 0]
enemy won!
Iteration 3930 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 3931 ended with reward tensor([0.]), enemy health [8, 9], model health [2.0, 8.0]
Iteration 3932 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 7.0]
Iteration 3933 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 3934 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0.0, 7.0]
Iteration 3935 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 7.0]
Iteration 3936 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 7.0]
Iteration 3937 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 7.0]
Iteration 3938 ended with reward tensor([1.]), enemy health [4.0, 0], model health [0.0, 7.0]
Iteration 3939 ended with reward tensor([0]), enemy health [4.0, 0], model health [0.0, 7.0]
Iteration 3940 ended with reward tensor([0]), enemy health [4.0, 0], model health [0.0, 7.0]
Iteration 3941 ended with reward tensor([0.5000]), enemy health [4.0, 0], model health [0.0, 6.0]
Iteration 3942 ended with reward tensor([0]), enemy health [4.0, 0], model health [0.0, 6.0]
Iteration 3943 ended with reward tensor([0.5000]), enemy health [4.0, 0], model health [0.0, 6.0]
Iteration 3944 ended with reward tensor([0.5000]), enemy health [4.0, 0], model health [0.0, 6.0]
Iteration 3945 ended with reward tensor([1.2000]), enemy health [1.0, 0], model health [0.0, 6.0]
Iteration 3946 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 6.0]
model won!
Iteration 3947 ended with reward tensor([0.]), enemy health [8, 9], model health [3.0, 9]
Iteration 3948 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 3949 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 3950 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 3951 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 3952 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 3953 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 3954 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 1.0]
Iteration 3955 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 1.0]
Iteration 3956 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0]
enemy won!
Iteration 3957 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 3958 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 9]
Iteration 3959 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 9]
Iteration 3960 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 9]
Iteration 3961 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 7.0]
Iteration 3962 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 7.0]
Iteration 3963 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [8, 6.0]
Iteration 3964 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [2.0, 6.0]
Iteration 3965 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 3966 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 3.0]
Iteration 3967 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0, 3.0]
Iteration 3968 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [0, 0.0]
enemy won!
Iteration 3969 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [8, 7.0]
Iteration 3970 ended with reward tensor([0.2000]), enemy health [2.0, 8.0], model health [8, 3.0]
Iteration 3971 ended with reward tensor([-0.3000]), enemy health [1.0, 8.0], model health [8, 3.0]
Iteration 3972 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [5.0, 3.0]
Iteration 3973 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 3974 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 3975 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 3976 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 3977 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 3978 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 3979 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 3980 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 9.0]
Iteration 3981 ended with reward tensor([0.4000]), enemy health [0, 9], model health [7.0, 9.0]
Iteration 3982 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 9.0]
Iteration 3983 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [3.0, 8.0]
Iteration 3984 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [2.0, 8.0]
Iteration 3985 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 8.0]
Iteration 3986 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 8.0]
Iteration 3987 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 8.0]
model won!
Iteration 3988 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 3989 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [3.0, 9.0]
Iteration 3990 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [1.0, 9.0]
Iteration 3991 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0.0, 5.0]
Iteration 3992 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 3993 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 1.0]
Iteration 3994 ended with reward tensor([-1.]), enemy health [0.0, 5.0], model health [0.0, 0.0]
enemy won!
Iteration 3995 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3996 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 3997 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 3998 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9]
Iteration 3999 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 9]
Iteration 4000 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 9]
Iteration 4001 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 9]
Iteration 4002 ended with reward tensor([-0.5000]), enemy health [4.0, 5.0], model health [0.0, 9]
Iteration 4003 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 6.0]
Iteration 4004 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 6.0]
Iteration 4005 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 6.0]
Iteration 4006 ended with reward tensor([0.7000]), enemy health [4.0, 2.0], model health [0.0, 6.0]
Iteration 4007 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4008 ended with reward tensor([0.5000]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4009 ended with reward tensor([0]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4010 ended with reward tensor([0]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4011 ended with reward tensor([0.5000]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4012 ended with reward tensor([-0.5000]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4013 ended with reward tensor([1.2000]), enemy health [0.0, 0.0], model health [0.0, 6.0]
model won!
Iteration 4014 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4015 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8.0, 8.0]
Iteration 4016 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [5.0, 8.0]
Iteration 4017 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 8.0]
Iteration 4018 ended with reward tensor([1.]), enemy health [0, 9], model health [0, 8.0]
Iteration 4019 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0, 7.0]
Iteration 4020 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 5.0]
Iteration 4021 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 5.0]
Iteration 4022 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 5.0]
Iteration 4023 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0, 4.0]
Iteration 4024 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 4.0]
Iteration 4025 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 4.0]
Iteration 4026 ended with reward tensor([-1.]), enemy health [0, 2.0], model health [0, 0]
enemy won!
Iteration 4027 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 4028 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [2.0, 9]
Iteration 4029 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 4030 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 9]
Iteration 4031 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 8.0]
Iteration 4032 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0.0, 8.0]
Iteration 4033 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 8.0]
Iteration 4034 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 8.0]
Iteration 4035 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 8.0]
Iteration 4036 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4037 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4038 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4039 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4040 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4041 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4042 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4043 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4044 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4045 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4046 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4047 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4048 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4049 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4050 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4051 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4052 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4053 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4054 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4055 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4056 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4057 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4058 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4059 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4060 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4061 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4062 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4063 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4064 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4065 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4066 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4067 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4068 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4069 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4070 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4071 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4072 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4073 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4074 ended with reward tensor([1.2000]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 4075 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4076 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9.0]
Iteration 4077 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 8.0]
Iteration 4078 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [5.0, 8.0]
Iteration 4079 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 8.0]
Iteration 4080 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0.0, 8.0]
Iteration 4081 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0.0, 8.0]
Iteration 4082 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 8.0]
Iteration 4083 ended with reward tensor([1.]), enemy health [0.0, 3.0], model health [0, 8.0]
Iteration 4084 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 8.0]
Iteration 4085 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 7.0]
model won!
Iteration 4086 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 4087 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [8, 7.0]
Iteration 4088 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 7.0]
Iteration 4089 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 7.0]
Iteration 4090 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 7.0]
Iteration 4091 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 7.0]
Iteration 4092 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4093 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4094 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4095 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4096 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4097 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4098 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 4099 ended with reward tensor([1.2000]), enemy health [0, 0.0], model health [0.0, 7.0]
model won!
Iteration 4100 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8, 9]
Iteration 4101 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9.0]
Iteration 4102 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0.0, 9.0]
Iteration 4103 ended with reward tensor([-0.5000]), enemy health [6.0, 9], model health [0.0, 9.0]
Iteration 4104 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 4105 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 4106 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9.0]
Iteration 4107 ended with reward tensor([1.]), enemy health [0, 9], model health [0.0, 9.0]
Iteration 4108 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0.0, 8.0]
Iteration 4109 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 8.0]
Iteration 4110 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 8.0]
Iteration 4111 ended with reward tensor([-1.]), enemy health [0, 5.0], model health [0.0, 8.0]
Iteration 4112 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 8.0]
Iteration 4113 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 8.0]
Iteration 4114 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 6.0]
Iteration 4115 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 6.0]
Iteration 4116 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 3.0]
model won!
Iteration 4117 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 4118 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9.0]
Iteration 4119 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 9.0]
Iteration 4120 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [3.0, 7.0]
Iteration 4121 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [2.0, 7.0]
Iteration 4122 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [2.0, 7.0]
Iteration 4123 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [2.0, 7.0]
Iteration 4124 ended with reward tensor([1.7000]), enemy health [-5.0, 4.0], model health [0.0, 7.0]
model won!
Iteration 4125 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 6.0]
Iteration 4126 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 3.0]
Iteration 4127 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 4128 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 4129 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 3.0]
Iteration 4130 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [3.0, 3.0]
Iteration 4131 ended with reward tensor([0.9000]), enemy health [0.0, 9.0], model health [1.0, 3.0]
Iteration 4132 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [1.0, 3.0]
Iteration 4133 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [1.0, 3.0]
Iteration 4134 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 3.0]
Iteration 4135 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 4136 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 4137 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 4138 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 4139 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 4140 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0]
Iteration 4141 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 3.0]
model won!
Iteration 4142 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 4143 ended with reward tensor([-0.3000]), enemy health [8, 9], model health [8.0, 9.0]
Iteration 4144 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [3.0, 9.0]
Iteration 4145 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9.0]
Iteration 4146 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9.0]
Iteration 4147 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9.0]
Iteration 4148 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9.0]
Iteration 4149 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9.0]
Iteration 4150 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 4151 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 5.0]
Iteration 4152 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 4153 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 5.0]
Iteration 4154 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 3.0]
Iteration 4155 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 2.0]
Iteration 4156 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0, 2.0]
Iteration 4157 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0, 0]
enemy won!
Iteration 4158 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4159 ended with reward tensor([0.9000]), enemy health [8, 7.0], model health [8, 9]
Iteration 4160 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [3.0, 9]
Iteration 4161 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0.0, 9.0]
Iteration 4162 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 9.0]
Iteration 4163 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 9.0]
Iteration 4164 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 8.0]
Iteration 4165 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [0.0, 8.0]
Iteration 4166 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 8.0]
Iteration 4167 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0.0, 8.0]
Iteration 4168 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 8.0]
Iteration 4169 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 8.0]
Iteration 4170 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 8.0]
Iteration 4171 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 6.0]
Iteration 4172 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 6.0]
Iteration 4173 ended with reward tensor([0.7000]), enemy health [1.0, 2.0], model health [0.0, 6.0]
Iteration 4174 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 5.0]
Iteration 4175 ended with reward tensor([1.]), enemy health [1.0, 0.0], model health [0.0, 4.0]
Iteration 4176 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 4.0]
model won!
Iteration 4177 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4178 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 4179 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 4180 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8, 6.0]
Iteration 4181 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [8, 4.0]
Iteration 4182 ended with reward tensor([0.]), enemy health [0, 9], model health [3.0, 4.0]
Iteration 4183 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [3.0, 3.0]
Iteration 4184 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0, 3.0]
Iteration 4185 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 3.0]
Iteration 4186 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 3.0]
Iteration 4187 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 3.0]
Iteration 4188 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 3.0]
Iteration 4189 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 3.0]
Iteration 4190 ended with reward tensor([2.]), enemy health [0, 0], model health [0.0, 3.0]
model won!
Iteration 4191 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9.0]
Iteration 4192 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 9.0]
Iteration 4193 ended with reward tensor([0]), enemy health [2.0, 9], model health [8, 9.0]
Iteration 4194 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 9.0]
Iteration 4195 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 4196 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [4.0, 8.0]
Iteration 4197 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 8.0]
Iteration 4198 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 4199 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 6.0]
Iteration 4200 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 5.0]
Iteration 4201 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 2.0]
Iteration 4202 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 1.0]
Iteration 4203 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0, 0.0]
enemy won!
Iteration 4204 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4205 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [5.0, 9]
Iteration 4206 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [5.0, 9]
Iteration 4207 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [5.0, 9]
Iteration 4208 ended with reward tensor([1.]), enemy health [0.0, 9], model health [5.0, 9]
Iteration 4209 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 9]
Iteration 4210 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 9]
Iteration 4211 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4212 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 4213 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 4214 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 5.0]
Iteration 4215 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 5.0]
Iteration 4216 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 5.0]
Iteration 4217 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 5.0]
Iteration 4218 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 5.0]
Iteration 4219 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 5.0]
model won!
Iteration 4220 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4221 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [2.0, 9.0]
Iteration 4222 ended with reward tensor([-0.3000]), enemy health [7.0, 9], model health [2.0, 8.0]
Iteration 4223 ended with reward tensor([-0.3000]), enemy health [4.0, 9], model health [1.0, 4.0]
Iteration 4224 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [1.0, 3.0]
Iteration 4225 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [1.0, 2.0]
Iteration 4226 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [1.0, 2.0]
Iteration 4227 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [1.0, 1.0]
Iteration 4228 ended with reward tensor([0.5000]), enemy health [3.0, 7.0], model health [1.0, 0.0]
Iteration 4229 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [1.0, 0.0]
Iteration 4230 ended with reward tensor([-1.]), enemy health [3.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 4231 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 9]
Iteration 4232 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [4.0, 9]
Iteration 4233 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 4234 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9]
Iteration 4235 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 7.0]
Iteration 4236 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 7.0]
Iteration 4237 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 4.0]
Iteration 4238 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 1.0]
model won!
Iteration 4239 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 4240 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 3.0]
Iteration 4241 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [6.0, 3.0]
Iteration 4242 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [3.0, 3.0]
Iteration 4243 ended with reward tensor([1.]), enemy health [0, 9], model health [0, 3.0]
Iteration 4244 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 1.0]
Iteration 4245 ended with reward tensor([-1.]), enemy health [0, 8.0], model health [0, 1.0]
Iteration 4246 ended with reward tensor([-1.]), enemy health [0, 8.0], model health [0, 0]
enemy won!
Iteration 4247 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4248 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4249 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4250 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 4251 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [2.0, 9]
Iteration 4252 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [2.0, 9]
Iteration 4253 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9]
Iteration 4254 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 3.0]
Iteration 4255 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 0]
enemy won!
Iteration 4256 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [4.0, 9]
Iteration 4257 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [3.0, 9]
Iteration 4258 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [3.0, 9]
Iteration 4259 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [0, 9]
Iteration 4260 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [0, 9]
Iteration 4261 ended with reward tensor([0.7000]), enemy health [8, 2.0], model health [0, 9]
Iteration 4262 ended with reward tensor([1.]), enemy health [8, 0.0], model health [0, 9]
Iteration 4263 ended with reward tensor([0.7000]), enemy health [8.0, 0.0], model health [0, 9]
Iteration 4264 ended with reward tensor([0.7000]), enemy health [7.0, 0.0], model health [0, 9]
Iteration 4265 ended with reward tensor([0.7000]), enemy health [5.0, 0.0], model health [0, 9]
Iteration 4266 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0, 9]
Iteration 4267 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0, 9]
Iteration 4268 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0, 9.0]
Iteration 4269 ended with reward tensor([1.2000]), enemy health [2.0, 0.0], model health [0, 9.0]
Iteration 4270 ended with reward tensor([1.]), enemy health [2.0, 0], model health [0, 9.0]
Iteration 4271 ended with reward tensor([2.]), enemy health [0, 0], model health [0, 9.0]
model won!
Iteration 4272 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4273 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4274 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 4275 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [2.0, 9.0]
Iteration 4276 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 4277 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 4278 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9.0]
Iteration 4279 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 9.0]
Iteration 4280 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 9.0]
Iteration 4281 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 9.0]
Iteration 4282 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9.0]
Iteration 4283 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9.0]
Iteration 4284 ended with reward tensor([-0.5000]), enemy health [1.0, 8.0], model health [0.0, 9.0]
Iteration 4285 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 9.0]
Iteration 4286 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 8.0]
Iteration 4287 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 6.0]
Iteration 4288 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 5.0]
Iteration 4289 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0.0, 5.0]
Iteration 4290 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 4.0]
Iteration 4291 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 4.0]
Iteration 4292 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 4.0]
Iteration 4293 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 4.0]
model won!
Iteration 4294 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 5.0]
Iteration 4295 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 4296 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 4297 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 3.0]
Iteration 4298 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 4299 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 4300 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 4301 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 4302 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 4303 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0]
Iteration 4304 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 4305 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 4306 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 3.0]
Iteration 4307 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 4308 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [8, 9.0]
Iteration 4309 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [3.0, 9.0]
Iteration 4310 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 4311 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4312 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 2.0]
Iteration 4313 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 2.0]
Iteration 4314 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0, 0.0]
enemy won!
Iteration 4315 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4316 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4317 ended with reward tensor([0.9000]), enemy health [3.0, 9], model health [3.0, 9]
Iteration 4318 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9]
Iteration 4319 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9]
Iteration 4320 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 4321 ended with reward tensor([1.]), enemy health [0, 9], model health [0, 9]
Iteration 4322 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0, 7.0]
Iteration 4323 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 7.0]
Iteration 4324 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 6.0]
Iteration 4325 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 5.0]
Iteration 4326 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0, 4.0]
Iteration 4327 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0, 4.0]
Iteration 4328 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 3.0]
Iteration 4329 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0, 3.0]
Iteration 4330 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0, 2.0]
Iteration 4331 ended with reward tensor([2.]), enemy health [0, 0], model health [0, 1.0]
model won!
Iteration 4332 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 8.0]
Iteration 4333 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 6.0]
Iteration 4334 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [5.0, 6.0]
Iteration 4335 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [3.0, 4.0]
Iteration 4336 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [3.0, 3.0]
Iteration 4337 ended with reward tensor([0.5000]), enemy health [0.0, 6.0], model health [3.0, 0.0]
Iteration 4338 ended with reward tensor([0.]), enemy health [0.0, 6.0], model health [3.0, 0.0]
Iteration 4339 ended with reward tensor([0]), enemy health [0.0, 6.0], model health [1.0, 0.0]
Iteration 4340 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 4341 ended with reward tensor([-0.3000]), enemy health [7.0, 9], model health [3.0, 9]
Iteration 4342 ended with reward tensor([-0.5000]), enemy health [7.0, 9], model health [0.0, 9]
Iteration 4343 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [0.0, 9]
Iteration 4344 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0, 9]
Iteration 4345 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0, 9]
Iteration 4346 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0, 9.0]
Iteration 4347 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0, 9.0]
Iteration 4348 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0, 8.0]
Iteration 4349 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0, 8.0]
Iteration 4350 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0, 7.0]
Iteration 4351 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [0, 4.0]
Iteration 4352 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0, 2.0]
Iteration 4353 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 4354 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 4355 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 8.0]
Iteration 4356 ended with reward tensor([0.9000]), enemy health [2.0, 9], model health [2.0, 8.0]
Iteration 4357 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 8.0]
Iteration 4358 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0.0, 8.0]
Iteration 4359 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 8.0]
Iteration 4360 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0.0, 8.0]
Iteration 4361 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0.0, 8.0]
Iteration 4362 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 8.0]
Iteration 4363 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 8.0]
Iteration 4364 ended with reward tensor([1.]), enemy health [2.0, 0.0], model health [0.0, 8.0]
Iteration 4365 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 8.0]
Iteration 4366 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 8.0]
model won!
Iteration 4367 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [8, 7.0]
Iteration 4368 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [6.0, 7.0]
Iteration 4369 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [5.0, 7.0]
Iteration 4370 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [4.0, 7.0]
Iteration 4371 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 7.0]
Iteration 4372 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 7.0]
Iteration 4373 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0.0, 7.0]
Iteration 4374 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0.0, 7.0]
Iteration 4375 ended with reward tensor([0.7000]), enemy health [5.0, 2.0], model health [0.0, 7.0]
Iteration 4376 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 7.0]
Iteration 4377 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 7.0]
Iteration 4378 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0.0, 7.0]
Iteration 4379 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 7.0]
Iteration 4380 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 7.0]
Iteration 4381 ended with reward tensor([1.]), enemy health [0.0, 1.0], model health [0.0, 7.0]
Iteration 4382 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 4383 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [5.0, 9]
Iteration 4384 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [5.0, 5.0]
Iteration 4385 ended with reward tensor([0.9000]), enemy health [1.0, 7.0], model health [5.0, 3.0]
Iteration 4386 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [4.0, 3.0]
Iteration 4387 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [2.0, 3.0]
Iteration 4388 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [2.0, 3.0]
Iteration 4389 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [2.0, 3.0]
Iteration 4390 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [2.0, 3.0]
Iteration 4391 ended with reward tensor([2.]), enemy health [0, 0.0], model health [1.0, 3.0]
model won!
Iteration 4392 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4393 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 4394 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 4395 ended with reward tensor([0]), enemy health [8, 9], model health [8, 8.0]
Iteration 4396 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8, 8.0]
Iteration 4397 ended with reward tensor([1.4000]), enemy health [6.0, 9], model health [2.0, 8.0]
Iteration 4398 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [2.0, 8.0]
Iteration 4399 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [1.0, 8.0]
Iteration 4400 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [1.0, 8.0]
Iteration 4401 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 8.0]
Iteration 4402 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 8.0]
Iteration 4403 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 8.0]
Iteration 4404 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 8.0]
Iteration 4405 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 8.0]
Iteration 4406 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 8.0]
Iteration 4407 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 8.0]
Iteration 4408 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 8.0]
Iteration 4409 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 5.0]
Iteration 4410 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 4411 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 4412 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4413 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [6.0, 9]
Iteration 4414 ended with reward tensor([-0.3000]), enemy health [3.0, 9], model health [6.0, 9.0]
Iteration 4415 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [5.0, 6.0]
Iteration 4416 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [5.0, 6.0]
Iteration 4417 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [5.0, 6.0]
Iteration 4418 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [4.0, 6.0]
Iteration 4419 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [1.0, 6.0]
Iteration 4420 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 6.0]
Iteration 4421 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 6.0]
Iteration 4422 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0.0, 6.0]
Iteration 4423 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0.0, 6.0]
Iteration 4424 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0, 6.0]
Iteration 4425 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0, 6.0]
Iteration 4426 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0, 6.0]
Iteration 4427 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0, 6.0]
Iteration 4428 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0, 6.0]
Iteration 4429 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 4430 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0, 6.0]
Iteration 4431 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 6.0]
model won!
Iteration 4432 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4433 ended with reward tensor([0.4000]), enemy health [8, 8.0], model health [8, 9]
Iteration 4434 ended with reward tensor([0.7000]), enemy health [8, 6.0], model health [2.0, 9]
Iteration 4435 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [2.0, 9]
Iteration 4436 ended with reward tensor([0.7000]), enemy health [8, 1.0], model health [0, 9]
Iteration 4437 ended with reward tensor([1.]), enemy health [8, 0], model health [0, 9]
Iteration 4438 ended with reward tensor([0.7000]), enemy health [8.0, 0], model health [0, 6.0]
Iteration 4439 ended with reward tensor([0.7000]), enemy health [7.0, 0], model health [0, 6.0]
Iteration 4440 ended with reward tensor([0.7000]), enemy health [7.0, 0], model health [0, 6.0]
Iteration 4441 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0, 6.0]
Iteration 4442 ended with reward tensor([1.]), enemy health [2.0, 0.0], model health [0, 6.0]
Iteration 4443 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0, 6.0]
Iteration 4444 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 6.0]
model won!
Iteration 4445 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4446 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [5.0, 9.0]
Iteration 4447 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [1.0, 9.0]
Iteration 4448 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 4449 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 9.0]
Iteration 4450 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 9.0]
Iteration 4451 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 9.0]
Iteration 4452 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9.0]
Iteration 4453 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9.0]
Iteration 4454 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 9.0]
Iteration 4455 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 9.0]
Iteration 4456 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 9.0]
Iteration 4457 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 9.0]
Iteration 4458 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 9.0]
Iteration 4459 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 9.0]
Iteration 4460 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 9.0]
Iteration 4461 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 9.0]
Iteration 4462 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 9.0]
model won!
Iteration 4463 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 7.0]
Iteration 4464 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [8, 7.0]
Iteration 4465 ended with reward tensor([0.2000]), enemy health [0, 9], model health [8, 6.0]
Iteration 4466 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 6.0]
Iteration 4467 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 4.0]
Iteration 4468 ended with reward tensor([0.2000]), enemy health [0, 6.0], model health [0, 4.0]
Iteration 4469 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 3.0]
Iteration 4470 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 3.0]
Iteration 4471 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 3.0]
Iteration 4472 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0.0, 3.0]
model won!
Iteration 4473 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4474 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4475 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4476 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4477 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 4478 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [1.0, 9]
Iteration 4479 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9]
Iteration 4480 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0, 8.0]
Iteration 4481 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 8.0]
Iteration 4482 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4483 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4484 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4485 ended with reward tensor([0]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4486 ended with reward tensor([0.5000]), enemy health [3.0, 0.0], model health [0.0, 8.0]
Iteration 4487 ended with reward tensor([1.]), enemy health [-5.0, 0.0], model health [0.0, 8.0]
model won!
Iteration 4488 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 4489 ended with reward tensor([0]), enemy health [8, 9], model health [2.0, 9]
Iteration 4490 ended with reward tensor([0.9000]), enemy health [0.0, 9], model health [1.0, 9]
Iteration 4491 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 9]
Iteration 4492 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 9]
Iteration 4493 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 9]
Iteration 4494 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 9]
Iteration 4495 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 9]
Iteration 4496 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 9]
Iteration 4497 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 9]
Iteration 4498 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 9]
Iteration 4499 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 9]
Iteration 4500 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 9]
model won!
Iteration 4501 ended with reward tensor([0]), enemy health [8, 9], model health [8, 6.0]
Iteration 4502 ended with reward tensor([0]), enemy health [8, 9], model health [8, 6.0]
Iteration 4503 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [8, 6.0]
Iteration 4504 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [5.0, 6.0]
Iteration 4505 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [5.0, 6.0]
Iteration 4506 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [5.0, 6.0]
Iteration 4507 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [1.0, 6.0]
Iteration 4508 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 4509 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 4510 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 6.0]
Iteration 4511 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 6.0]
Iteration 4512 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0, 6.0]
Iteration 4513 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 3.0]
Iteration 4514 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 1.0]
model won!
Iteration 4515 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4516 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 4517 ended with reward tensor([0.4000]), enemy health [0, 9], model health [5.0, 8.0]
Iteration 4518 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [3.0, 8.0]
Iteration 4519 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 7.0]
Iteration 4520 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 7.0]
Iteration 4521 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0.0, 6.0]
Iteration 4522 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0.0, 6.0]
Iteration 4523 ended with reward tensor([2.]), enemy health [0, 0], model health [0.0, 5.0]
model won!
Iteration 4524 ended with reward tensor([0.2000]), enemy health [8, 9], model health [3.0, 9]
Iteration 4525 ended with reward tensor([0]), enemy health [8, 9], model health [0.0, 9]
Iteration 4526 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 5.0]
Iteration 4527 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 4.0]
Iteration 4528 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 4529 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 4.0]
Iteration 4530 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 4531 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 1.0]
Iteration 4532 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 4533 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4534 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 9]
Iteration 4535 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 4536 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [2.0, 8.0]
Iteration 4537 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [2.0, 8.0]
Iteration 4538 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 4539 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 4.0]
Iteration 4540 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 4.0]
Iteration 4541 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 4.0]
Iteration 4542 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 3.0]
Iteration 4543 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 3.0]
Iteration 4544 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 4545 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 4546 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [3.0, 9]
Iteration 4547 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [3.0, 8.0]
Iteration 4548 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [3.0, 8.0]
Iteration 4549 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [3.0, 5.0]
Iteration 4550 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [3.0, 3.0]
Iteration 4551 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [3.0, 3.0]
Iteration 4552 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [3.0, 2.0]
Iteration 4553 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [3.0, 2.0]
Iteration 4554 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [3.0, 2.0]
Iteration 4555 ended with reward tensor([0]), enemy health [0.0, 4.0], model health [3.0, 0.0]
Iteration 4556 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [3.0, 0.0]
Iteration 4557 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 4558 ended with reward tensor([0.2000]), enemy health [8, 9], model health [8, 9]
Iteration 4559 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [0, 9]
Iteration 4560 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4561 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4562 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 6.0]
Iteration 4563 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 6.0]
Iteration 4564 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 3.0]
Iteration 4565 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 4566 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 4567 ended with reward tensor([0]), enemy health [8, 9], model health [6.0, 9]
Iteration 4568 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 4569 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0.0, 6.0]
Iteration 4570 ended with reward tensor([-0.3000]), enemy health [1.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 4571 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 9.0]
Iteration 4572 ended with reward tensor([-1.]), enemy health [8, 9], model health [6.0, 9.0]
Iteration 4573 ended with reward tensor([0.4000]), enemy health [8, 9.0], model health [6.0, 8.0]
Iteration 4574 ended with reward tensor([0.7000]), enemy health [7.0, 6.0], model health [0.0, 8.0]
Iteration 4575 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 8.0]
Iteration 4576 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 8.0]
Iteration 4577 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0, 8.0]
Iteration 4578 ended with reward tensor([0.7000]), enemy health [5.0, 2.0], model health [0, 8.0]
Iteration 4579 ended with reward tensor([0.7000]), enemy health [5.0, 2.0], model health [0, 8.0]
Iteration 4580 ended with reward tensor([1.]), enemy health [5.0, 0], model health [0.0, 8.0]
Iteration 4581 ended with reward tensor([0.5000]), enemy health [5.0, 0], model health [0.0, 8.0]
Iteration 4582 ended with reward tensor([0.5000]), enemy health [5.0, 0], model health [0.0, 7.0]
Iteration 4583 ended with reward tensor([0]), enemy health [5.0, 0], model health [0.0, 7.0]
Iteration 4584 ended with reward tensor([0.5000]), enemy health [5.0, 0], model health [0.0, 7.0]
Iteration 4585 ended with reward tensor([0]), enemy health [5.0, 0], model health [0.0, 7.0]
Iteration 4586 ended with reward tensor([0]), enemy health [5.0, 0], model health [0.0, 7.0]
Iteration 4587 ended with reward tensor([1.2000]), enemy health [0.0, 0], model health [0.0, 7.0]
model won!
Iteration 4588 ended with reward tensor([0]), enemy health [8, 9], model health [8, 7.0]
Iteration 4589 ended with reward tensor([0.2000]), enemy health [8, 9.0], model health [8, 6.0]
Iteration 4590 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [5.0, 6.0]
Iteration 4591 ended with reward tensor([0.9000]), enemy health [2.0, 9.0], model health [3.0, 6.0]
Iteration 4592 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [1.0, 6.0]
Iteration 4593 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 6.0]
Iteration 4594 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0.0, 6.0]
Iteration 4595 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0.0, 4.0]
Iteration 4596 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0.0, 3.0]
Iteration 4597 ended with reward tensor([1.]), enemy health [0.0, 6.0], model health [0.0, 1.0]
Iteration 4598 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0.0, 1.0]
Iteration 4599 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 4600 ended with reward tensor([0.5000]), enemy health [8, 9], model health [2.0, 9]
Iteration 4601 ended with reward tensor([0.7000]), enemy health [7.0, 9], model health [2.0, 9]
Iteration 4602 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [2.0, 8.0]
Iteration 4603 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [0, 8.0]
Iteration 4604 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 8.0]
Iteration 4605 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 4606 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 6.0]
Iteration 4607 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 5.0]
Iteration 4608 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 2.0]
Iteration 4609 ended with reward tensor([0]), enemy health [0.0, 3.0], model health [0, 1.0]
Iteration 4610 ended with reward tensor([-0.5000]), enemy health [0.0, 3.0], model health [0, 0]
enemy won!
Iteration 4611 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4612 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [5.0, 9]
Iteration 4613 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [5.0, 8.0]
Iteration 4614 ended with reward tensor([0.4000]), enemy health [0, 9], model health [5.0, 8.0]
Iteration 4615 ended with reward tensor([0]), enemy health [0, 9], model health [5.0, 8.0]
Iteration 4616 ended with reward tensor([0.]), enemy health [0, 9], model health [5.0, 8.0]
Iteration 4617 ended with reward tensor([-0.6000]), enemy health [0, 9.0], model health [5.0, 8.0]
Iteration 4618 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [5.0, 8.0]
Iteration 4619 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [5.0, 8.0]
Iteration 4620 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [4.0, 8.0]
Iteration 4621 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [3.0, 8.0]
Iteration 4622 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [1.0, 8.0]
Iteration 4623 ended with reward tensor([-0.5000]), enemy health [0, 3.0], model health [0.0, 8.0]
Iteration 4624 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 2.0]
Iteration 4625 ended with reward tensor([-0.5000]), enemy health [0, 3.0], model health [0.0, 2.0]
Iteration 4626 ended with reward tensor([-1.]), enemy health [0, 3.0], model health [0.0, 0.0]
enemy won!
Iteration 4627 ended with reward tensor([0]), enemy health [8, 9], model health [7.0, 9]
Iteration 4628 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [7.0, 9]
Iteration 4629 ended with reward tensor([-0.3000]), enemy health [2.0, 9], model health [3.0, 9]
Iteration 4630 ended with reward tensor([0.9000]), enemy health [0, 9], model health [3.0, 8.0]
Iteration 4631 ended with reward tensor([0.]), enemy health [0, 9], model health [3.0, 4.0]
Iteration 4632 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 4.0]
Iteration 4633 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 3.0]
Iteration 4634 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 1.0]
Iteration 4635 ended with reward tensor([-1.]), enemy health [0, 9], model health [0, 0.0]
enemy won!
Iteration 4636 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [7.0, 9]
Iteration 4637 ended with reward tensor([1.]), enemy health [0.0, 9], model health [5.0, 9]
Iteration 4638 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [5.0, 9.0]
Iteration 4639 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [2.0, 9.0]
Iteration 4640 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 4641 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4642 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4643 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4644 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4645 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 5.0]
Iteration 4646 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0, 5.0]
Iteration 4647 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 4648 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 4649 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4650 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 4651 ended with reward tensor([0.9000]), enemy health [4.0, 9.0], model health [5.0, 8.0]
Iteration 4652 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [5.0, 4.0]
Iteration 4653 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [5.0, 4.0]
Iteration 4654 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [5.0, 4.0]
Iteration 4655 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [5.0, 4.0]
Iteration 4656 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [3.0, 4.0]
Iteration 4657 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [2.0, 4.0]
Iteration 4658 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [2.0, 4.0]
Iteration 4659 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [2.0, 3.0]
Iteration 4660 ended with reward tensor([0.9000]), enemy health [1.0, 0], model health [2.0, 3.0]
Iteration 4661 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [2.0, 3.0]
Iteration 4662 ended with reward tensor([2.]), enemy health [0, 0], model health [2.0, 3.0]
model won!
Iteration 4663 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 4664 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [8, 8.0]
Iteration 4665 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [7.0, 8.0]
Iteration 4666 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [4.0, 8.0]
Iteration 4667 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [4.0, 8.0]
Iteration 4668 ended with reward tensor([-0.5000]), enemy health [2.0, 6.0], model health [3.0, 8.0]
Iteration 4669 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 7.0]
Iteration 4670 ended with reward tensor([0.7000]), enemy health [2.0, 4.0], model health [0.0, 7.0]
Iteration 4671 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 4.0]
Iteration 4672 ended with reward tensor([0.7000]), enemy health [1.0, 1.0], model health [0.0, 2.0]
Iteration 4673 ended with reward tensor([-0.5000]), enemy health [1.0, 1.0], model health [0.0, 0.0]
enemy won!
Iteration 4674 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4675 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 9]
Iteration 4676 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [8, 9]
Iteration 4677 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [8, 9]
Iteration 4678 ended with reward tensor([0.9000]), enemy health [0.0, 9], model health [8, 9]
Iteration 4679 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [6.0, 9]
Iteration 4680 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [4.0, 9]
Iteration 4681 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [2.0, 9]
Iteration 4682 ended with reward tensor([1.2000]), enemy health [0.0, 8.0], model health [1.0, 9]
Iteration 4683 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [1.0, 9]
Iteration 4684 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 4685 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 7.0]
Iteration 4686 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 7.0]
Iteration 4687 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 7.0]
Iteration 4688 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 4689 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4690 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4691 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 4692 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9]
Iteration 4693 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9]
Iteration 4694 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 9]
Iteration 4695 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9]
Iteration 4696 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9]
Iteration 4697 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9]
Iteration 4698 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 4699 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9]
Iteration 4700 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 5.0]
Iteration 4701 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 4.0]
Iteration 4702 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 2.0]
Iteration 4703 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 4704 ended with reward tensor([0]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 4705 ended with reward tensor([-0.5000]), enemy health [0.0, 7.0], model health [0, 0]
enemy won!
Iteration 4706 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4707 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4708 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4709 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [4.0, 9]
Iteration 4710 ended with reward tensor([-0.5000]), enemy health [4.0, 9], model health [1.0, 9]
Iteration 4711 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9]
Iteration 4712 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0, 9]
Iteration 4713 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0, 8.0]
Iteration 4714 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 5.0]
Iteration 4715 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 3.0]
Iteration 4716 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 1.0]
Iteration 4717 ended with reward tensor([-0.5000]), enemy health [3.0, 6.0], model health [0, 0.0]
enemy won!
Iteration 4718 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 4719 ended with reward tensor([0]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 4720 ended with reward tensor([0]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 4721 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 4722 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 8.0]
Iteration 4723 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 8.0]
Iteration 4724 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 7.0]
Iteration 4725 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 5.0]
Iteration 4726 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [1.0, 0.0]
Iteration 4727 ended with reward tensor([0.]), enemy health [0.0, 9], model health [1.0, 0.0]
Iteration 4728 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 0.0]
enemy won!
Iteration 4729 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 9.0]
Iteration 4730 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 9.0]
Iteration 4731 ended with reward tensor([0.4000]), enemy health [0, 9], model health [8, 9.0]
Iteration 4732 ended with reward tensor([0]), enemy health [0, 9], model health [8, 9.0]
Iteration 4733 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [8, 9.0]
Iteration 4734 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [7.0, 9.0]
Iteration 4735 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 9.0]
Iteration 4736 ended with reward tensor([-1.]), enemy health [0, 9], model health [4.0, 9.0]
Iteration 4737 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 9.0]
Iteration 4738 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 8.0]
Iteration 4739 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 8.0]
Iteration 4740 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 8.0]
Iteration 4741 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 7.0]
Iteration 4742 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 6.0]
Iteration 4743 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 6.0]
Iteration 4744 ended with reward tensor([2.]), enemy health [0, 0], model health [0.0, 6.0]
model won!
Iteration 4745 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4746 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 4747 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 9]
Iteration 4748 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [2.0, 9]
Iteration 4749 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 9]
Iteration 4750 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 9.0]
Iteration 4751 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 7.0]
Iteration 4752 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 7.0]
Iteration 4753 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 7.0]
Iteration 4754 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 7.0]
Iteration 4755 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 7.0]
Iteration 4756 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 7.0]
Iteration 4757 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 7.0]
model won!
Iteration 4758 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4759 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 6.0]
Iteration 4760 ended with reward tensor([0.9000]), enemy health [0.0, 9], model health [8, 6.0]
Iteration 4761 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [8.0, 6.0]
Iteration 4762 ended with reward tensor([-1.]), enemy health [0.0, 8.0], model health [8.0, 6.0]
Iteration 4763 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 6.0]
Iteration 4764 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 6.0]
Iteration 4765 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 4.0]
Iteration 4766 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 4.0]
Iteration 4767 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 4768 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 1.0]
model won!
Iteration 4769 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4770 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 4771 ended with reward tensor([-0.3000]), enemy health [8, 9], model health [8, 9.0]
Iteration 4772 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9.0]
Iteration 4773 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9.0]
Iteration 4774 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [4.0, 9.0]
Iteration 4775 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [2.0, 9.0]
Iteration 4776 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [2.0, 9.0]
Iteration 4777 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [2.0, 9.0]
Iteration 4778 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [2.0, 9.0]
Iteration 4779 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 9.0]
Iteration 4780 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9.0]
Iteration 4781 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9.0]
Iteration 4782 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 4783 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 5.0]
Iteration 4784 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 5.0]
Iteration 4785 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 5.0]
Iteration 4786 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0, 3.0]
model won!
Iteration 4787 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4788 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 9]
Iteration 4789 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [6.0, 9]
Iteration 4790 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [2.0, 9]
Iteration 4791 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [2.0, 5.0]
Iteration 4792 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [2.0, 3.0]
Iteration 4793 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [2.0, 1.0]
Iteration 4794 ended with reward tensor([0.5000]), enemy health [0.0, 4.0], model health [2.0, 0.0]
Iteration 4795 ended with reward tensor([-1.]), enemy health [0.0, 4.0], model health [2.0, 0.0]
Iteration 4796 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0, 0.0]
enemy won!
Iteration 4797 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4798 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 4799 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 9.0]
Iteration 4800 ended with reward tensor([1.]), enemy health [0.0, 9], model health [6.0, 9.0]
Iteration 4801 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [6.0, 7.0]
Iteration 4802 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [6.0, 7.0]
Iteration 4803 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [6.0, 7.0]
Iteration 4804 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [6.0, 6.0]
Iteration 4805 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [6.0, 2.0]
Iteration 4806 ended with reward tensor([-1.5000]), enemy health [0.0, 1.0], model health [6.0, 2.0]
Iteration 4807 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [6.0, 2.0]
model won!
Iteration 4808 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [3.0, 9]
Iteration 4809 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [3.0, 8.0]
Iteration 4810 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [3.0, 8.0]
Iteration 4811 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 4812 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 4813 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 4814 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 3.0]
Iteration 4815 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 0.0]
enemy won!
Iteration 4816 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4817 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 4818 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 4819 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [5.0, 6.0]
Iteration 4820 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [5.0, 6.0]
Iteration 4821 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [5.0, 4.0]
Iteration 4822 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [5.0, 4.0]
Iteration 4823 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [5.0, 1.0]
Iteration 4824 ended with reward tensor([0]), enemy health [0.0, 2.0], model health [5.0, 0.0]
Iteration 4825 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [5.0, 0.0]
Iteration 4826 ended with reward tensor([-1.]), enemy health [0.0, 2.0], model health [5.0, 0.0]
Iteration 4827 ended with reward tensor([-1.]), enemy health [0.0, 2.0], model health [0.0, 0.0]
enemy won!
Iteration 4828 ended with reward tensor([0.7000]), enemy health [8, 9.0], model health [6.0, 9]
Iteration 4829 ended with reward tensor([-0.5000]), enemy health [8, 9.0], model health [6.0, 9]
Iteration 4830 ended with reward tensor([0.7000]), enemy health [8.0, 9.0], model health [2.0, 9]
Iteration 4831 ended with reward tensor([0.7000]), enemy health [8.0, 9.0], model health [2.0, 9]
Iteration 4832 ended with reward tensor([0.7000]), enemy health [7.0, 9.0], model health [0.0, 9]
Iteration 4833 ended with reward tensor([0.7000]), enemy health [6.0, 9.0], model health [0.0, 9]
Iteration 4834 ended with reward tensor([0.7000]), enemy health [5.0, 9.0], model health [0.0, 9]
Iteration 4835 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 9]
Iteration 4836 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 9]
Iteration 4837 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0.0, 9]
Iteration 4838 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9]
Iteration 4839 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9]
Iteration 4840 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9]
Iteration 4841 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9]
Iteration 4842 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9]
Iteration 4843 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9]
Iteration 4844 ended with reward tensor([0.7000]), enemy health [1.0, 9.0], model health [0.0, 9]
Iteration 4845 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0.0, 9]
Iteration 4846 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 7.0]
Iteration 4847 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 5.0]
Iteration 4848 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 4849 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 2.0]
Iteration 4850 ended with reward tensor([-1.]), enemy health [0.0, 2.0], model health [0.0, 0.0]
enemy won!
Iteration 4851 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [8, 9]
Iteration 4852 ended with reward tensor([0.2000]), enemy health [0, 9], model health [8, 7.0]
Iteration 4853 ended with reward tensor([0]), enemy health [0, 9], model health [8, 7.0]
Iteration 4854 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [6.0, 7.0]
Iteration 4855 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 4856 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 4857 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 7.0]
Iteration 4858 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 5.0]
Iteration 4859 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 4.0]
Iteration 4860 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 3.0]
Iteration 4861 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 2.0]
Iteration 4862 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 2.0]
Iteration 4863 ended with reward tensor([-1.]), enemy health [0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 4864 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [6.0, 9]
Iteration 4865 ended with reward tensor([-0.3000]), enemy health [3.0, 9], model health [6.0, 7.0]
Iteration 4866 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [3.0, 7.0]
Iteration 4867 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [3.0, 7.0]
Iteration 4868 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 4869 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 1.0]
Iteration 4870 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
Iteration 4871 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4872 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 4873 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [5.0, 9.0]
Iteration 4874 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [4.0, 9.0]
Iteration 4875 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [4.0, 9.0]
Iteration 4876 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [1.0, 9.0]
Iteration 4877 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [1.0, 9.0]
Iteration 4878 ended with reward tensor([1.]), enemy health [0, 9], model health [1.0, 9.0]
Iteration 4879 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [1.0, 6.0]
Iteration 4880 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [1.0, 5.0]
Iteration 4881 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [1.0, 5.0]
Iteration 4882 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [1.0, 2.0]
Iteration 4883 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [1.0, 1.0]
Iteration 4884 ended with reward tensor([0]), enemy health [0, 4.0], model health [1.0, 0.0]
Iteration 4885 ended with reward tensor([0.5000]), enemy health [0, 4.0], model health [1.0, 0.0]
Iteration 4886 ended with reward tensor([-1.]), enemy health [0, 4.0], model health [0, 0.0]
enemy won!
Iteration 4887 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4888 ended with reward tensor([0]), enemy health [8, 9], model health [0.0, 9]
Iteration 4889 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0.0, 9.0]
Iteration 4890 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 9.0]
Iteration 4891 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0.0, 9.0]
Iteration 4892 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 9.0]
Iteration 4893 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 9.0]
Iteration 4894 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 9.0]
Iteration 4895 ended with reward tensor([0.7000]), enemy health [4.0, 4.0], model health [0.0, 9.0]
Iteration 4896 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0.0, 9.0]
Iteration 4897 ended with reward tensor([1.]), enemy health [4.0, 0.0], model health [0.0, 9.0]
Iteration 4898 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 9.0]
Iteration 4899 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0.0, 9.0]
Iteration 4900 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 9.0]
Iteration 4901 ended with reward tensor([1.7000]), enemy health [0.0, 0.0], model health [0.0, 9.0]
model won!
Iteration 4902 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [5.0, 9]
Iteration 4903 ended with reward tensor([0.9000]), enemy health [0.0, 9], model health [2.0, 6.0]
Iteration 4904 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 4905 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 4906 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 4.0]
Iteration 4907 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 2.0]
Iteration 4908 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 1.0]
Iteration 4909 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 1.0]
Iteration 4910 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 4911 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4912 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [5.0, 9]
Iteration 4913 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [5.0, 9.0]
Iteration 4914 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [3.0, 9.0]
Iteration 4915 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [3.0, 9.0]
Iteration 4916 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 9.0]
Iteration 4917 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0.0, 8.0]
Iteration 4918 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 8.0]
Iteration 4919 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 6.0]
Iteration 4920 ended with reward tensor([0.7000]), enemy health [2.0, 4.0], model health [0.0, 5.0]
Iteration 4921 ended with reward tensor([0.7000]), enemy health [2.0, 4.0], model health [0.0, 4.0]
Iteration 4922 ended with reward tensor([0.7000]), enemy health [2.0, 4.0], model health [0.0, 1.0]
Iteration 4923 ended with reward tensor([-1.]), enemy health [2.0, 4.0], model health [0.0, 0.0]
enemy won!
Iteration 4924 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4925 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4926 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 4927 ended with reward tensor([0.9000]), enemy health [4.0, 9], model health [3.0, 9]
Iteration 4928 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 8.0]
Iteration 4929 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 7.0]
Iteration 4930 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 7.0]
Iteration 4931 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 7.0]
Iteration 4932 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0.0, 7.0]
Iteration 4933 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 7.0]
Iteration 4934 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 7.0]
Iteration 4935 ended with reward tensor([0.7000]), enemy health [3.0, 4.0], model health [0, 7.0]
Iteration 4936 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 6.0]
Iteration 4937 ended with reward tensor([0.2000]), enemy health [3.0, 2.0], model health [0, 6.0]
Iteration 4938 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0, 2.0]
Iteration 4939 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0, 1.0]
Iteration 4940 ended with reward tensor([-0.5000]), enemy health [3.0, 1.0], model health [0, 0]
enemy won!
Iteration 4941 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4942 ended with reward tensor([0.4000]), enemy health [7.0, 9], model health [8.0, 9]
Iteration 4943 ended with reward tensor([0.4000]), enemy health [6.0, 9], model health [6.0, 9]
Iteration 4944 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [2.0, 6.0]
Iteration 4945 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 6.0]
Iteration 4946 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 6.0]
Iteration 4947 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 6.0]
Iteration 4948 ended with reward tensor([0.7000]), enemy health [5.0, 2.0], model health [0.0, 6.0]
Iteration 4949 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 6.0]
Iteration 4950 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [0.0, 6.0]
Iteration 4951 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0.0, 6.0]
Iteration 4952 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 6.0]
Iteration 4953 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 6.0]
Iteration 4954 ended with reward tensor([1.7000]), enemy health [0, 0.0], model health [0.0, 6.0]
model won!
Iteration 4955 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [8, 9]
Iteration 4956 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 9]
Iteration 4957 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8.0, 9.0]
Iteration 4958 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [8.0, 9.0]
Iteration 4959 ended with reward tensor([1.]), enemy health [0.0, 9], model health [8.0, 9.0]
Iteration 4960 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [8.0, 7.0]
Iteration 4961 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4.0, 7.0]
Iteration 4962 ended with reward tensor([0.]), enemy health [0.0, 9], model health [1.0, 7.0]
Iteration 4963 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 5.0]
Iteration 4964 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 5.0]
Iteration 4965 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 4966 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 4.0]
Iteration 4967 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 2.0]
Iteration 4968 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 1.0]
Iteration 4969 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [0, 0]
enemy won!
Iteration 4970 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4971 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 4972 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [2.0, 9.0]
Iteration 4973 ended with reward tensor([0.7000]), enemy health [0, 9], model health [0, 8.0]
Iteration 4974 ended with reward tensor([0.]), enemy health [0, 9], model health [0, 7.0]
Iteration 4975 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 6.0]
Iteration 4976 ended with reward tensor([-1.]), enemy health [0, 8.0], model health [0, 6.0]
Iteration 4977 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 4.0]
Iteration 4978 ended with reward tensor([0]), enemy health [0, 7.0], model health [0, 2.0]
Iteration 4979 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 1.0]
Iteration 4980 ended with reward tensor([-1.]), enemy health [0, 4.0], model health [0, 1.0]
Iteration 4981 ended with reward tensor([-0.5000]), enemy health [0, 4.0], model health [0, 0]
enemy won!
Iteration 4982 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4983 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9]
Iteration 4984 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 4985 ended with reward tensor([0.7000]), enemy health [8, 8.0], model health [0.0, 8.0]
Iteration 4986 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 6.0]
Iteration 4987 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 5.0]
Iteration 4988 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 4.0]
Iteration 4989 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 1.0]
Iteration 4990 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0.0, 1.0]
Iteration 4991 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 0]
enemy won!
Iteration 4992 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 4993 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 4994 ended with reward tensor([0.4000]), enemy health [3.0, 9], model health [4.0, 9]
Iteration 4995 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 9]
Iteration 4996 ended with reward tensor([0.7000]), enemy health [3.0, 4.0], model health [0.0, 8.0]
Iteration 4997 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0.0, 8.0]
Iteration 4998 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 7.0]
Iteration 4999 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 7.0]
Iteration 5000 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 7.0]
Iteration 5001 ended with reward tensor([1.7000]), enemy health [0, 0.0], model health [0.0, 7.0]
model won!
Iteration 5002 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5003 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 5004 ended with reward tensor([-0.3000]), enemy health [4.0, 9], model health [6.0, 9]
Iteration 5005 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0, 9.0]
Iteration 5006 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 7.0]
Iteration 5007 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0, 7.0]
Iteration 5008 ended with reward tensor([0.7000]), enemy health [2.0, 6.0], model health [0, 6.0]
Iteration 5009 ended with reward tensor([0.7000]), enemy health [1.0, 6.0], model health [0, 6.0]
Iteration 5010 ended with reward tensor([-0.3000]), enemy health [0.0, 6.0], model health [0, 6.0]
Iteration 5011 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 5.0]
Iteration 5012 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0, 3.0]
Iteration 5013 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 2.0]
Iteration 5014 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 2.0]
Iteration 5015 ended with reward tensor([-0.5000]), enemy health [0.0, 1.0], model health [0, 0.0]
enemy won!
Iteration 5016 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 5017 ended with reward tensor([-1.]), enemy health [8, 9], model health [5.0, 9.0]
Iteration 5018 ended with reward tensor([0.9000]), enemy health [5.0, 9], model health [1.0, 9.0]
Iteration 5019 ended with reward tensor([0.7000]), enemy health [5.0, 5.0], model health [0.0, 8.0]
Iteration 5020 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0.0, 8.0]
Iteration 5021 ended with reward tensor([0.7000]), enemy health [5.0, 3.0], model health [0.0, 8.0]
Iteration 5022 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 8.0]
Iteration 5023 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [0, 8.0]
Iteration 5024 ended with reward tensor([1.2000]), enemy health [1.0, 0.0], model health [0, 8.0]
Iteration 5025 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 8.0]
model won!
Iteration 5026 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5027 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5028 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 9.0]
Iteration 5029 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 7.0]
Iteration 5030 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 6.0]
Iteration 5031 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 5.0]
Iteration 5032 ended with reward tensor([0]), enemy health [0.0, 9], model health [6.0, 5.0]
Iteration 5033 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [6.0, 3.0]
Iteration 5034 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [3.0, 3.0]
Iteration 5035 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [1.0, 3.0]
Iteration 5036 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 3.0]
Iteration 5037 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 5038 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 5039 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 5040 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 5041 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 5042 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0]
Iteration 5043 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 5044 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 3.0]
Iteration 5045 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 3.0]
model won!
Iteration 5046 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 5047 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 8.0]
Iteration 5048 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [6.0, 8.0]
Iteration 5049 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 8.0]
Iteration 5050 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 5051 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0.0, 3.0]
Iteration 5052 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 2.0]
Iteration 5053 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 2.0]
Iteration 5054 ended with reward tensor([-1.]), enemy health [3.0, 7.0], model health [0.0, 0]
enemy won!
Iteration 5055 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 5056 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 5057 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 5058 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 5059 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [5.0, 9]
Iteration 5060 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [1.0, 9]
Iteration 5061 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9]
Iteration 5062 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9]
Iteration 5063 ended with reward tensor([1.]), enemy health [0.0, 8.0], model health [0.0, 9]
Iteration 5064 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 5.0]
Iteration 5065 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 3.0]
Iteration 5066 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0]
Iteration 5067 ended with reward tensor([-0.5000]), enemy health [0.0, 8.0], model health [0.0, 0.0]
enemy won!
Iteration 5068 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5069 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5070 ended with reward tensor([0.4000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 5071 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [5.0, 6.0]
Iteration 5072 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 6.0]
Iteration 5073 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 6.0]
Iteration 5074 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 6.0]
Iteration 5075 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 5076 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 3.0]
Iteration 5077 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 3.0]
Iteration 5078 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 1.0]
Iteration 5079 ended with reward tensor([-1.]), enemy health [0.0, 6.0], model health [0.0, 0.0]
enemy won!
Iteration 5080 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 5081 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 5082 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 8.0]
Iteration 5083 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 5084 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [3.0, 8.0]
Iteration 5085 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [2.0, 8.0]
Iteration 5086 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [2.0, 8.0]
Iteration 5087 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 8.0]
model won!
Iteration 5088 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [5.0, 9.0]
Iteration 5089 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0, 9.0]
Iteration 5090 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0, 9.0]
Iteration 5091 ended with reward tensor([0.7000]), enemy health [8, 5.0], model health [0, 8.0]
Iteration 5092 ended with reward tensor([0.7000]), enemy health [8, 4.0], model health [0, 6.0]
Iteration 5093 ended with reward tensor([0.7000]), enemy health [8, 3.0], model health [0, 4.0]
Iteration 5094 ended with reward tensor([0.7000]), enemy health [8, 2.0], model health [0, 3.0]
Iteration 5095 ended with reward tensor([-0.5000]), enemy health [8, 2.0], model health [0, 0.0]
enemy won!
Iteration 5096 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 9]
Iteration 5097 ended with reward tensor([0.4000]), enemy health [2.0, 9], model health [8, 9.0]
Iteration 5098 ended with reward tensor([0.4000]), enemy health [0, 9], model health [3.0, 9.0]
Iteration 5099 ended with reward tensor([0]), enemy health [0, 9], model health [0, 9.0]
Iteration 5100 ended with reward tensor([0.]), enemy health [0, 9], model health [0, 8.0]
Iteration 5101 ended with reward tensor([0.]), enemy health [0, 9], model health [0, 8.0]
Iteration 5102 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0, 6.0]
Iteration 5103 ended with reward tensor([-0.5000]), enemy health [0, 8.0], model health [0, 4.0]
Iteration 5104 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0, 3.0]
Iteration 5105 ended with reward tensor([0.7000]), enemy health [0, 4.0], model health [0, 3.0]
Iteration 5106 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0, 2.0]
Iteration 5107 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 2.0]
Iteration 5108 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 0]
enemy won!
Iteration 5109 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5110 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [8, 9]
Iteration 5111 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 8.0]
Iteration 5112 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 5113 ended with reward tensor([0]), enemy health [0.0, 9], model health [8, 8.0]
Iteration 5114 ended with reward tensor([0.]), enemy health [0.0, 9], model health [2.0, 8.0]
Iteration 5115 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 5116 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 7.0]
Iteration 5117 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0, 5.0]
Iteration 5118 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0, 5.0]
Iteration 5119 ended with reward tensor([-1.]), enemy health [0.0, 9.0], model health [0, 0.0]
enemy won!
Iteration 5120 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5121 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5122 ended with reward tensor([0.4000]), enemy health [4.0, 9], model health [8, 9]
Iteration 5123 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [2.0, 9]
Iteration 5124 ended with reward tensor([0.7000]), enemy health [3.0, 6.0], model health [0.0, 9]
Iteration 5125 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0.0, 9]
Iteration 5126 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0.0, 9]
Iteration 5127 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0.0, 9]
Iteration 5128 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 9]
Iteration 5129 ended with reward tensor([1.]), enemy health [3.0, 0], model health [0.0, 9]
Iteration 5130 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 8.0]
model won!
Iteration 5131 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5132 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5133 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [8, 8.0]
Iteration 5134 ended with reward tensor([0]), enemy health [2.0, 9], model health [8, 6.0]
Iteration 5135 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [8, 6.0]
Iteration 5136 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [2.0, 6.0]
Iteration 5137 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 5138 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 5.0]
Iteration 5139 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 5140 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 4.0]
Iteration 5141 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 3.0]
Iteration 5142 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 3.0]
Iteration 5143 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 2.0]
Iteration 5144 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 2.0]
Iteration 5145 ended with reward tensor([-0.5000]), enemy health [0.0, 2.0], model health [0.0, 0.0]
enemy won!
Iteration 5146 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 5147 ended with reward tensor([0]), enemy health [8, 9], model health [5.0, 9]
Iteration 5148 ended with reward tensor([-1.]), enemy health [8, 9], model health [5.0, 8.0]
Iteration 5149 ended with reward tensor([-0.3000]), enemy health [4.0, 9], model health [2.0, 8.0]
Iteration 5150 ended with reward tensor([-0.3000]), enemy health [0.0, 9], model health [0, 8.0]
Iteration 5151 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 8.0]
Iteration 5152 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 8.0]
Iteration 5153 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0.0, 8.0]
Iteration 5154 ended with reward tensor([2.]), enemy health [0.0, 0], model health [0.0, 8.0]
model won!
Iteration 5155 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 5156 ended with reward tensor([0.2000]), enemy health [3.0, 9], model health [8, 7.0]
Iteration 5157 ended with reward tensor([0.4000]), enemy health [0, 9], model health [4.0, 7.0]
Iteration 5158 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 6.0]
Iteration 5159 ended with reward tensor([0.7000]), enemy health [0, 6.0], model health [0.0, 4.0]
Iteration 5160 ended with reward tensor([-0.5000]), enemy health [0, 6.0], model health [0.0, 4.0]
Iteration 5161 ended with reward tensor([0.7000]), enemy health [0, 5.0], model health [0.0, 4.0]
Iteration 5162 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 4.0]
Iteration 5163 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 4.0]
Iteration 5164 ended with reward tensor([0.7000]), enemy health [0, 3.0], model health [0.0, 4.0]
Iteration 5165 ended with reward tensor([0.7000]), enemy health [0, 2.0], model health [0, 4.0]
Iteration 5166 ended with reward tensor([-0.5000]), enemy health [0, 2.0], model health [0, 4.0]
Iteration 5167 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0, 3.0]
Iteration 5168 ended with reward tensor([2.]), enemy health [0, 0.0], model health [0, 2.0]
model won!
Iteration 5169 ended with reward tensor([0]), enemy health [8, 9], model health [4.0, 9]
Iteration 5170 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4.0, 8.0]
Iteration 5171 ended with reward tensor([0.4000]), enemy health [0.0, 9], model health [4.0, 8.0]
Iteration 5172 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 6.0]
Iteration 5173 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 6.0]
Iteration 5174 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 5.0]
Iteration 5175 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0, 2.0]
Iteration 5176 ended with reward tensor([-0.5000]), enemy health [0.0, 4.0], model health [0, 0.0]
enemy won!
Iteration 5177 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [8, 3.0]
Iteration 5178 ended with reward tensor([0.2000]), enemy health [6.0, 9], model health [8, 1.0]
Iteration 5179 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [6.0, 1.0]
Iteration 5180 ended with reward tensor([0.2000]), enemy health [0, 9], model health [6.0, 1.0]
Iteration 5181 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 1.0]
Iteration 5182 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 0.0]
enemy won!
Iteration 5183 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9.0]
Iteration 5184 ended with reward tensor([-1.]), enemy health [8, 9], model health [8, 9.0]
Iteration 5185 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 9.0]
Iteration 5186 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0, 8.0]
Iteration 5187 ended with reward tensor([0.7000]), enemy health [5.0, 9], model health [0, 5.0]
Iteration 5188 ended with reward tensor([0.7000]), enemy health [5.0, 8.0], model health [0.0, 5.0]
Iteration 5189 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0.0, 4.0]
Iteration 5190 ended with reward tensor([0.7000]), enemy health [5.0, 6.0], model health [0, 4.0]
Iteration 5191 ended with reward tensor([0.7000]), enemy health [5.0, 4.0], model health [0, 4.0]
Iteration 5192 ended with reward tensor([0.7000]), enemy health [5.0, 3.0], model health [0.0, 4.0]
Iteration 5193 ended with reward tensor([0.7000]), enemy health [5.0, 1.0], model health [0.0, 4.0]
Iteration 5194 ended with reward tensor([1.]), enemy health [5.0, 0.0], model health [0.0, 4.0]
Iteration 5195 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 4.0]
Iteration 5196 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 4.0]
Iteration 5197 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0.0, 4.0]
model won!
Iteration 5198 ended with reward tensor([0.2000]), enemy health [7.0, 9], model health [8, 6.0]
Iteration 5199 ended with reward tensor([0.4000]), enemy health [1.0, 9], model health [6.0, 1.0]
Iteration 5200 ended with reward tensor([0.2000]), enemy health [0, 9], model health [1.0, 1.0]
Iteration 5201 ended with reward tensor([0]), enemy health [0, 9], model health [1.0, 0.0]
Iteration 5202 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 0.0]
enemy won!
Iteration 5203 ended with reward tensor([0.5000]), enemy health [8, 9], model health [3.0, 9]
Iteration 5204 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [3.0, 8.0]
Iteration 5205 ended with reward tensor([-0.5000]), enemy health [8, 9], model health [0.0, 8.0]
Iteration 5206 ended with reward tensor([0.]), enemy health [8, 9], model health [0.0, 7.0]
Iteration 5207 ended with reward tensor([0.7000]), enemy health [8, 7.0], model health [0.0, 6.0]
Iteration 5208 ended with reward tensor([0.7000]), enemy health [7.0, 7.0], model health [0.0, 6.0]
Iteration 5209 ended with reward tensor([0.7000]), enemy health [6.0, 7.0], model health [0.0, 5.0]
Iteration 5210 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 5.0]
Iteration 5211 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 3.0]
Iteration 5212 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 3.0]
Iteration 5213 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 2.0]
Iteration 5214 ended with reward tensor([0.7000]), enemy health [5.0, 7.0], model health [0.0, 1.0]
Iteration 5215 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [0.0, 1.0]
Iteration 5216 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 1.0]
Iteration 5217 ended with reward tensor([-1.]), enemy health [3.0, 7.0], model health [0.0, 0.0]
enemy won!
Iteration 5218 ended with reward tensor([0]), enemy health [8, 9], model health [1.0, 9]
Iteration 5219 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [1.0, 9.0]
Iteration 5220 ended with reward tensor([0.2000]), enemy health [1.0, 9], model health [1.0, 8.0]
Iteration 5221 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [1.0, 7.0]
Iteration 5222 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [1.0, 7.0]
Iteration 5223 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0]
Iteration 5224 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 1.0]
Iteration 5225 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0.0, 0.0]
enemy won!
Iteration 5226 ended with reward tensor([0]), enemy health [8, 9], model health [8, 9]
Iteration 5227 ended with reward tensor([0.2000]), enemy health [5.0, 9], model health [5.0, 9]
Iteration 5228 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [1.0, 9]
Iteration 5229 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 6.0]
Iteration 5230 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 6.0]
Iteration 5231 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 6.0]
Iteration 5232 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 6.0]
Iteration 5233 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 6.0]
Iteration 5234 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 5.0]
Iteration 5235 ended with reward tensor([0.7000]), enemy health [3.0, 8.0], model health [0, 5.0]
Iteration 5236 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 4.0]
Iteration 5237 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 4.0]
Iteration 5238 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0, 4.0]
Iteration 5239 ended with reward tensor([0.7000]), enemy health [3.0, 2.0], model health [0, 4.0]
Iteration 5240 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0, 2.0]
Iteration 5241 ended with reward tensor([2.]), enemy health [0.0, 0.0], model health [0, 2.0]
model won!
Iteration 5242 ended with reward tensor([0.7000]), enemy health [6.0, 9], model health [8, 5.0]
Iteration 5243 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [8, 5.0]
Iteration 5244 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [4.0, 5.0]
Iteration 5245 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [1.0, 5.0]
Iteration 5246 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0]
Iteration 5247 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 5.0]
Iteration 5248 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 5.0]
Iteration 5249 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 5.0]
Iteration 5250 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0, 2.0]
Iteration 5251 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0, 0.0]
enemy won!
