Model units:
Name: Canoness, Army Type: Sisters_of_Battle
Name: Dominion Squad, Army Type: Sisters_of_Battle
Enemy units:
Name: Canoness, Army Type: Sisters_of_Battle
Name: Dominion Squad, Army Type: Sisters_of_Battle
Number of Lifetimes ran: 500

Iteration 0 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 3 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 4 ended with reward tensor([0]), enemy health [4, 7.0], model health [2.0, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 5 ended with reward tensor([2]), enemy health [4, 7.0], model health [0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 6 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 9], model VP 1, enemy VP 1, victory condition 1
Iteration 7 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [4, 5.0], model VP 2, enemy VP 2, victory condition 1
Iteration 8 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [4, 5.0], model VP 3, enemy VP 3, victory condition 1
Iteration 9 ended with reward tensor([-1.5000]), enemy health [0.0, 7.0], model health [4, 5.0], model VP 4, enemy VP 4, victory condition 1
Iteration 10 ended with reward tensor([-2]), enemy health [0.0, 7.0], model health [4.0, 1.0], model VP 1, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 11 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4, 7.0], model VP 1, enemy VP 1, victory condition 1
Iteration 12 ended with reward tensor([0.5000]), enemy health [4, 9], model health [2.0, 7.0], model VP 2, enemy VP 3, victory condition 1
Iteration 13 ended with reward tensor([0]), enemy health [4, 9], model health [2.0, 1.0], model VP 3, enemy VP 5, victory condition 1
Iteration 14 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [2.0, 0.0], model VP 4, enemy VP 8, victory condition 1
Iteration 15 ended with reward tensor([-1.5000]), enemy health [4, 3.0], model health [2.0, 0.0], model VP 1, enemy VP 3, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 16 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 1, enemy VP 3, victory condition 2
Iteration 17 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 2, enemy VP 6, victory condition 2
Iteration 18 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [0.0, 9], model VP 3, enemy VP 9, victory condition 2
Iteration 19 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 5.0], model VP 4, enemy VP 12, victory condition 2
Iteration 20 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 5, enemy VP 15, victory condition 2
Major Victory
model won!
Iteration 21 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0, 9], model VP 1, enemy VP 3, victory condition 1
Iteration 22 ended with reward tensor([0.7000]), enemy health [0, 9], model health [0, 9], model VP 2, enemy VP 6, victory condition 1
Iteration 23 ended with reward tensor([0]), enemy health [0, 9], model health [0, 3.0], model VP 3, enemy VP 8, victory condition 1
Iteration 24 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 1.0], model VP 4, enemy VP 10, victory condition 1
Iteration 25 ended with reward tensor([-1.3000]), enemy health [0, 6.0], model health [0, 1.0], model VP 1, enemy VP 2, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 26 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 27 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 2
Iteration 28 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9], model VP 0, enemy VP 6, victory condition 2
Iteration 29 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 8, victory condition 2
Iteration 30 ended with reward tensor([-1.3000]), enemy health [2.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 31 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 32 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 2
Iteration 33 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0], model VP 0, enemy VP 6, victory condition 2
Iteration 34 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 8, victory condition 2
Iteration 35 ended with reward tensor([2]), enemy health [0.0, 8.0], model health [0.0, 0.0], model VP 0, enemy VP 10, victory condition 2
Major Victory
model won!
Iteration 36 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 37 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 7.0], model VP 0, enemy VP 4, victory condition 2
Iteration 38 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 6.0], model VP 0, enemy VP 6, victory condition 2
Iteration 39 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 8, victory condition 2
Major Victory
model won!
Iteration 40 ended with reward tensor([3.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 41 ended with reward tensor([5.2000]), enemy health [0.0, 0], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 42 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [4, 3.0], model VP 0, enemy VP 2, victory condition 2
Iteration 43 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 44 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [4.0, 0], model VP 0, enemy VP 6, victory condition 2
Iteration 45 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0, 0], model VP 0, enemy VP 8, victory condition 2
Major Victory
model won!
Iteration 46 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 47 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [2.0, 9], model VP 0, enemy VP 4, victory condition 2
Iteration 48 ended with reward tensor([4.2000]), enemy health [2.0, 5.0], model health [2.0, 7.0], model VP 0, enemy VP 6, victory condition 2
Iteration 49 ended with reward tensor([0.9000]), enemy health [2.0, 0.0], model health [2.0, 3.0], model VP 0, enemy VP 8, victory condition 2
Iteration 50 ended with reward tensor([-1.3000]), enemy health [1.0, 0.0], model health [2.0, 3.0], model VP 0, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 51 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 2, victory condition 1
Iteration 52 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 6.0], model VP 0, enemy VP 4, victory condition 1
Iteration 53 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 2.0], model VP 0, enemy VP 6, victory condition 1
Iteration 54 ended with reward tensor([2.5000]), enemy health [0.0, 8.0], model health [0.0, 2.0], model VP 0, enemy VP 8, victory condition 1
Iteration 55 ended with reward tensor([2]), enemy health [0.0, 8.0], model health [0.0, 0.0], model VP 0, enemy VP 10, victory condition 1
Major Victory
model won!
Iteration 56 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 57 ended with reward tensor([2.2000]), enemy health [0.0, 3.0], model health [0, 9], model VP 0, enemy VP 4, victory condition 1
Iteration 58 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0, 1.0], model VP 0, enemy VP 6, victory condition 1
Iteration 59 ended with reward tensor([-0.5000]), enemy health [0.0, 2.0], model health [0, 1.0], model VP 0, enemy VP 8, victory condition 1
Iteration 60 ended with reward tensor([2]), enemy health [0.0, 2.0], model health [0, 0.0], model VP 0, enemy VP 10, victory condition 1
Major Victory
model won!
Iteration 61 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [4, 9.0], model VP 0, enemy VP 2, victory condition 2
Iteration 62 ended with reward tensor([4.7000]), enemy health [0, 1.0], model health [4, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 63 ended with reward tensor([2.5000]), enemy health [0, 0.0], model health [4, 3.0], model VP 0, enemy VP 6, victory condition 2
Major Victory
model won!
Iteration 64 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 65 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 2
Iteration 66 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 6, victory condition 2
Iteration 67 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 8, victory condition 2
Major Victory
model won!
Iteration 68 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 69 ended with reward tensor([4.7000]), enemy health [0.0, 1.0], model health [4, 3.0], model VP 0, enemy VP 4, victory condition 1
Iteration 70 ended with reward tensor([-2]), enemy health [0.0, 0], model health [0, 3.0], model VP 0, enemy VP 6, victory condition 1
Major Victory
enemy won!
Iteration 71 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 72 ended with reward tensor([2.5000]), enemy health [0.0, 9], model health [4, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 73 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 6, victory condition 2
Major Victory
model won!
Iteration 74 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 1.0], model VP 0, enemy VP 2, victory condition 1
Iteration 75 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 4, victory condition 1
Iteration 76 ended with reward tensor([2]), enemy health [4.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 6, victory condition 1
Major Victory
model won!
Iteration 77 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 78 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 4.0], model VP 0, enemy VP 4, victory condition 2
Iteration 79 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0.0, 2.0], model VP 0, enemy VP 6, victory condition 2
Iteration 80 ended with reward tensor([0]), enemy health [4, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 8, victory condition 2
Iteration 81 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0.0], model VP 0, enemy VP 10, victory condition 2
Major Victory
model won!
Iteration 82 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 83 ended with reward tensor([0.]), enemy health [0.0, 9], model health [4.0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 84 ended with reward tensor([4.7000]), enemy health [0.0, 1.0], model health [2.0, 5.0], model VP 0, enemy VP 6, victory condition 2
Iteration 85 ended with reward tensor([-2]), enemy health [0.0, 0], model health [2.0, 0], model VP 0, enemy VP 8, victory condition 2
Major Victory
enemy won!
Iteration 86 ended with reward tensor([1.2000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 87 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 88 ended with reward tensor([2]), enemy health [4, 1.0], model health [0, 0], model VP 0, enemy VP 6, victory condition 2
Major Victory
model won!
Iteration 89 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 90 ended with reward tensor([3.2000]), enemy health [4, 1.0], model health [0.0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 91 ended with reward tensor([-1.]), enemy health [0, 0.0], model health [0.0, 4.0], model VP 0, enemy VP 6, victory condition 1
Major Victory
enemy won!
Iteration 92 ended with reward tensor([0]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 93 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4, 9], model VP 0, enemy VP 4, victory condition 2
Iteration 94 ended with reward tensor([-0.6000]), enemy health [3.0, 7.0], model health [4, 7.0], model VP 0, enemy VP 6, victory condition 2
Iteration 95 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [2.0, 7.0], model VP 0, enemy VP 8, victory condition 2
Iteration 96 ended with reward tensor([-2.5000]), enemy health [3.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 10, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 97 ended with reward tensor([0]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 98 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 99 ended with reward tensor([2]), enemy health [4.0, 9], model health [0, 0], model VP 0, enemy VP 6, victory condition 2
Major Victory
model won!
Iteration 100 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 7.0], model VP 0, enemy VP 2, victory condition 2
Iteration 101 ended with reward tensor([4.7000]), enemy health [4, 9.0], model health [4, 1.0], model VP 0, enemy VP 4, victory condition 2
Iteration 102 ended with reward tensor([0]), enemy health [4, 9.0], model health [4, 0], model VP 0, enemy VP 6, victory condition 2
Iteration 103 ended with reward tensor([2]), enemy health [4, 9.0], model health [0.0, 0], model VP 0, enemy VP 8, victory condition 2
Major Victory
model won!
Iteration 104 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 105 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 106 ended with reward tensor([1.2000]), enemy health [0.0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 6, victory condition 1
Iteration 107 ended with reward tensor([2]), enemy health [0.0, 7.0], model health [0.0, 0.0], model VP 0, enemy VP 7, victory condition 1
Major Victory
model won!
Iteration 108 ended with reward tensor([2.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 109 ended with reward tensor([0]), enemy health [4, 7.0], model health [0, 1.0], model VP 0, enemy VP 2, victory condition 1
Iteration 110 ended with reward tensor([2]), enemy health [4, 7.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 111 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 112 ended with reward tensor([4.7000]), enemy health [4, 0], model health [2.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 113 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [2.0, 4.0], model VP 0, enemy VP 3, victory condition 1
Iteration 114 ended with reward tensor([-0.5000]), enemy health [3.0, 0], model health [2.0, 3.0], model VP 0, enemy VP 4, victory condition 1
Iteration 115 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [2.0, 3.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 116 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 117 ended with reward tensor([0.2000]), enemy health [4, 1.0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 118 ended with reward tensor([-0.1000]), enemy health [0, 1.0], model health [4, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 119 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0.0, 3.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 120 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 121 ended with reward tensor([2.5000]), enemy health [4, 9], model health [2.0, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 122 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 123 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 9.0], model VP 0, enemy VP 1, victory condition 1
Iteration 124 ended with reward tensor([0.2000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 2, victory condition 1
Iteration 125 ended with reward tensor([0]), enemy health [4, 0], model health [4, 0.0], model VP 0, enemy VP 3, victory condition 1
Iteration 126 ended with reward tensor([2.5000]), enemy health [4, 0], model health [4, 0.0], model VP 0, enemy VP 4, victory condition 1
Iteration 127 ended with reward tensor([-1.5000]), enemy health [4, 0], model health [4, 0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 128 ended with reward tensor([0]), enemy health [4, 9], model health [4, 0.0], model VP 0, enemy VP 1, victory condition 1
Iteration 129 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0.0], model VP 0, enemy VP 2, victory condition 1
Major Victory
model won!
Iteration 130 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 7.0], model VP 0, enemy VP 1, victory condition 1
Iteration 131 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 132 ended with reward tensor([4.7000]), enemy health [4, 1.0], model health [4, 1.0], model VP 0, enemy VP 3, victory condition 1
Iteration 133 ended with reward tensor([0]), enemy health [4, 1.0], model health [2.0, 1.0], model VP 0, enemy VP 4, victory condition 1
Iteration 134 ended with reward tensor([-1.3000]), enemy health [3.0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 135 ended with reward tensor([3.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 136 ended with reward tensor([0.2000]), enemy health [0, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 2, victory condition 1
Iteration 137 ended with reward tensor([-0.5000]), enemy health [0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 3, victory condition 1
Iteration 138 ended with reward tensor([2]), enemy health [0, 1.0], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 139 ended with reward tensor([1.2000]), enemy health [4.0, 9], model health [4, 1.0], model VP 0, enemy VP 1, victory condition 1
Iteration 140 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 1.0], model VP 0, enemy VP 2, victory condition 1
Iteration 141 ended with reward tensor([0]), enemy health [0.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 3, victory condition 1
Iteration 142 ended with reward tensor([2.5000]), enemy health [0.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 4, victory condition 1
Iteration 143 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 144 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 145 ended with reward tensor([2.2000]), enemy health [2.0, 9], model health [0, 3.0], model VP 0, enemy VP 2, victory condition 1
Iteration 146 ended with reward tensor([2]), enemy health [2.0, 9], model health [0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 147 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 148 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 149 ended with reward tensor([-0.5000]), enemy health [2.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 3, victory condition 1
Iteration 150 ended with reward tensor([1.]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 1
Iteration 151 ended with reward tensor([-1.3000]), enemy health [0.0, 4.0], model health [0.0, 5.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 152 ended with reward tensor([2.5000]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 1, victory condition 2
Iteration 153 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 154 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 1, victory condition 2
Iteration 155 ended with reward tensor([4.7000]), enemy health [4, 0], model health [0.0, 3.0], model VP 0, enemy VP 2, victory condition 2
Iteration 156 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 3.0], model VP 0, enemy VP 3, victory condition 2
Iteration 157 ended with reward tensor([-1.3000]), enemy health [0, 0], model health [0.0, 3.0], model VP 0, enemy VP 4, victory condition 2
Major Victory
enemy won!
Iteration 158 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 159 ended with reward tensor([0.2000]), enemy health [0, 3.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 160 ended with reward tensor([0]), enemy health [0, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 3, victory condition 2
Iteration 161 ended with reward tensor([2.]), enemy health [0, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 4, victory condition 2
Iteration 162 ended with reward tensor([-1.8000]), enemy health [0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 163 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 164 ended with reward tensor([4.7000]), enemy health [0, 7.0], model health [2.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 165 ended with reward tensor([-0.5000]), enemy health [0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 166 ended with reward tensor([2]), enemy health [0, 3.0], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 167 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 168 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 2, victory condition 2
Iteration 169 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 3, victory condition 2
Iteration 170 ended with reward tensor([-0.5000]), enemy health [3.0, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 4, victory condition 2
Iteration 171 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 172 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 173 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 174 ended with reward tensor([-1.8000]), enemy health [0.0, 0], model health [0.0, 7.0], model VP 0, enemy VP 3, victory condition 1
Major Victory
enemy won!
Iteration 175 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 1, victory condition 2
Iteration 176 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 2, victory condition 2
Iteration 177 ended with reward tensor([1.]), enemy health [4, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 3, victory condition 2
Iteration 178 ended with reward tensor([1.5000]), enemy health [4, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 4, victory condition 2
Iteration 179 ended with reward tensor([-2]), enemy health [4, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 180 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 181 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 182 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 183 ended with reward tensor([2.7000]), enemy health [2.0, 0], model health [0.0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 184 ended with reward tensor([-2]), enemy health [0.0, 0], model health [0.0, 5.0], model VP 0, enemy VP 5, victory condition 2
Major Victory
enemy won!
Iteration 185 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 186 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 187 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 188 ended with reward tensor([0.7000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 189 ended with reward tensor([0.]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 2, victory condition 1
Iteration 190 ended with reward tensor([2.2000]), enemy health [0, 9.0], model health [0, 7.0], model VP 0, enemy VP 3, victory condition 1
Iteration 191 ended with reward tensor([2.2000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 4, victory condition 1
Iteration 192 ended with reward tensor([-1.3000]), enemy health [0, 4.0], model health [0, 2.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 193 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 194 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 195 ended with reward tensor([0.7000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 3, victory condition 2
Iteration 196 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 2
Iteration 197 ended with reward tensor([-2]), enemy health [0, 9], model health [0.0, 3.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 198 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 199 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 200 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 9], model VP 0, enemy VP 3, victory condition 1
Iteration 201 ended with reward tensor([-1.3000]), enemy health [0.0, 0], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 1
Major Victory
enemy won!
Iteration 202 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 203 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 204 ended with reward tensor([0]), enemy health [0, 9], model health [0.0, 1.0], model VP 0, enemy VP 3, victory condition 2
Iteration 205 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 206 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 207 ended with reward tensor([2.2000]), enemy health [0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 2, victory condition 2
Iteration 208 ended with reward tensor([2]), enemy health [0, 3.0], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 2
Major Victory
model won!
Iteration 209 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 210 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [2.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 211 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 9.0], model VP 0, enemy VP 3, victory condition 2
Iteration 212 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 8.0], model VP 0, enemy VP 4, victory condition 2
Iteration 213 ended with reward tensor([-2.5000]), enemy health [2.0, 8.0], model health [0, 8.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 214 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 215 ended with reward tensor([2.]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 2, victory condition 1
Iteration 216 ended with reward tensor([0.2000]), enemy health [0, 7.0], model health [0, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 217 ended with reward tensor([-0.5000]), enemy health [0, 7.0], model health [0, 1.0], model VP 0, enemy VP 4, victory condition 1
Iteration 218 ended with reward tensor([2]), enemy health [0, 7.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 219 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 1.0], model VP 0, enemy VP 1, victory condition 1
Iteration 220 ended with reward tensor([0]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 2, victory condition 1
Iteration 221 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 222 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 223 ended with reward tensor([0.7000]), enemy health [4, 4.0], model health [0, 4.0], model VP 0, enemy VP 2, victory condition 1
Iteration 224 ended with reward tensor([0.7000]), enemy health [4, 4.0], model health [0, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 225 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0, 2.0], model VP 0, enemy VP 4, victory condition 1
Iteration 226 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0.0], model VP 0, enemy VP 5, victory condition 1
Major Victory
model won!
Iteration 227 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 228 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 2, victory condition 1
Iteration 229 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 230 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 231 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 232 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [4, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 233 ended with reward tensor([2.5000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 3, victory condition 2
Iteration 234 ended with reward tensor([0]), enemy health [0.0, 5.0], model health [2.0, 0], model VP 0, enemy VP 4, victory condition 2
Iteration 235 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0, 0], model VP 0, enemy VP 5, victory condition 2
Major Victory
model won!
Iteration 236 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 237 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [1.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 238 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 239 ended with reward tensor([2]), enemy health [4, 7.0], model health [0, 0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 240 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 2
Iteration 241 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [2.0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 242 ended with reward tensor([0.2000]), enemy health [0, 3.0], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 243 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 1.0], model VP 0, enemy VP 4, victory condition 2
Major Victory
enemy won!
Iteration 244 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 9.0], model VP 0, enemy VP 1, victory condition 1
Iteration 245 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 246 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 247 ended with reward tensor([2]), enemy health [0, 1.0], model health [0.0, 0.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 248 ended with reward tensor([2.2000]), enemy health [4, 9.0], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 249 ended with reward tensor([1.5000]), enemy health [4, 9.0], model health [0.0, 1.0], model VP 0, enemy VP 2, victory condition 2
Iteration 250 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 3, victory condition 2
Iteration 251 ended with reward tensor([2]), enemy health [4, 1.0], model health [0.0, 0], model VP 0, enemy VP 4, victory condition 2
Major Victory
model won!
Iteration 252 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 253 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 254 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 3, victory condition 1
Iteration 255 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 1
Iteration 256 ended with reward tensor([-1.3000]), enemy health [3.0, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 257 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 258 ended with reward tensor([2.2000]), enemy health [4, 9.0], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 259 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 260 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 4, victory condition 2
Iteration 261 ended with reward tensor([-2.]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 262 ended with reward tensor([1.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 263 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 2, victory condition 1
Iteration 264 ended with reward tensor([2.2000]), enemy health [0.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 3, victory condition 1
Iteration 265 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0.0, 0.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 266 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 267 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 2, victory condition 2
Iteration 268 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 3, victory condition 2
Iteration 269 ended with reward tensor([2.7000]), enemy health [4, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 4, victory condition 2
Iteration 270 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [0.0, 3.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 271 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 272 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 273 ended with reward tensor([0.]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 3, victory condition 1
Iteration 274 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 4, victory condition 1
Iteration 275 ended with reward tensor([-2.5000]), enemy health [0.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 276 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 1.0], model VP 0, enemy VP 1, victory condition 1
Iteration 277 ended with reward tensor([0]), enemy health [4, 7.0], model health [0, 1.0], model VP 0, enemy VP 2, victory condition 1
Iteration 278 ended with reward tensor([2]), enemy health [4, 7.0], model health [0.0, 0.0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 279 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 280 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4.0, 5.0], model VP 0, enemy VP 2, victory condition 1
Iteration 281 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [2.0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 282 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 4.0], model VP 0, enemy VP 4, victory condition 1
Iteration 283 ended with reward tensor([-1.3000]), enemy health [4.0, 9], model health [0, 4.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 284 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 1, victory condition 1
Iteration 285 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 2, victory condition 1
Iteration 286 ended with reward tensor([2]), enemy health [0.0, 7.0], model health [0.0, 0], model VP 0, enemy VP 3, victory condition 1
Major Victory
model won!
Iteration 287 ended with reward tensor([0]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 288 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [2.0, 5.0], model VP 0, enemy VP 2, victory condition 2
Iteration 289 ended with reward tensor([4.7000]), enemy health [4, 0], model health [2.0, 5.0], model VP 0, enemy VP 3, victory condition 2
Iteration 290 ended with reward tensor([3.5000]), enemy health [4, 0], model health [2.0, 5.0], model VP 0, enemy VP 4, victory condition 2
Iteration 291 ended with reward tensor([-1.3000]), enemy health [4.0, 0], model health [2.0, 5.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 292 ended with reward tensor([0]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 293 ended with reward tensor([1.2000]), enemy health [0.0, 9], model health [4.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 294 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [2.0, 9], model VP 0, enemy VP 3, victory condition 1
Iteration 295 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 4, victory condition 1
Iteration 296 ended with reward tensor([-1.3000]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 297 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 298 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 299 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 8.0], model VP 0, enemy VP 3, victory condition 1
Iteration 300 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 8.0], model VP 0, enemy VP 4, victory condition 1
Iteration 301 ended with reward tensor([-2.5000]), enemy health [2.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 302 ended with reward tensor([4.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 303 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 2, victory condition 1
Iteration 304 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9.0], model VP 0, enemy VP 3, victory condition 1
Iteration 305 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9.0], model VP 0, enemy VP 4, victory condition 1
Iteration 306 ended with reward tensor([-1.3000]), enemy health [2.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 1, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 307 ended with reward tensor([0]), enemy health [4, 9], model health [3.0, 0.0], model VP 0, enemy VP 1, victory condition 2
Iteration 308 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0.0], model VP 0, enemy VP 2, victory condition 2
Major Victory
model won!
Iteration 309 ended with reward tensor([0.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 1, victory condition 1
Iteration 310 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 9.0], model VP 0, enemy VP 2, victory condition 1
Iteration 311 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 5.0], model VP 0, enemy VP 3, victory condition 1
Iteration 312 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 4, victory condition 1
Major Victory
model won!
Iteration 313 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 1, victory condition 2
Iteration 314 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 0.0], model VP 0, enemy VP 2, victory condition 2
Iteration 315 ended with reward tensor([0]), enemy health [0.0, 9], model health [4, 0.0], model VP 0, enemy VP 3, victory condition 2
Iteration 316 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 4, victory condition 2
Iteration 317 ended with reward tensor([-1.5000]), enemy health [0.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 5, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 318 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 319 ended with reward tensor([0.]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 320 ended with reward tensor([-1.8000]), enemy health [0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 321 ended with reward tensor([3.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 322 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 323 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 324 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 325 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 326 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 327 ended with reward tensor([0.7000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 328 ended with reward tensor([-2]), enemy health [0, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 329 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 330 ended with reward tensor([4.7000]), enemy health [0, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 331 ended with reward tensor([2.2000]), enemy health [0, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 332 ended with reward tensor([0.2000]), enemy health [0, 1.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 333 ended with reward tensor([2]), enemy health [0, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 334 ended with reward tensor([4.7000]), enemy health [4.0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 335 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 336 ended with reward tensor([2.5000]), enemy health [0.0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 337 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 338 ended with reward tensor([0.2000]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 339 ended with reward tensor([0.]), enemy health [0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 340 ended with reward tensor([0]), enemy health [0, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 341 ended with reward tensor([2]), enemy health [0, 7.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 342 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 343 ended with reward tensor([-0.5000]), enemy health [3.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 344 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 345 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 346 ended with reward tensor([-2.5000]), enemy health [1.0, 9], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 347 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 348 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 349 ended with reward tensor([0.7000]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 350 ended with reward tensor([2.5000]), enemy health [4, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 351 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 352 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 353 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 354 ended with reward tensor([0.7000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 355 ended with reward tensor([0.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 356 ended with reward tensor([-2.]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 357 ended with reward tensor([1.2000]), enemy health [4, 5.0], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 358 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 359 ended with reward tensor([-0.5000]), enemy health [4.0, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 360 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 361 ended with reward tensor([-2.5000]), enemy health [4.0, 5.0], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 362 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 363 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 364 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 365 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 366 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 367 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 368 ended with reward tensor([0.]), enemy health [0.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 369 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 370 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 371 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 372 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 373 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 374 ended with reward tensor([-2.5000]), enemy health [2.0, 9], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 375 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 376 ended with reward tensor([2.5000]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 377 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 378 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 379 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 380 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 381 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 382 ended with reward tensor([-2.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 383 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 384 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 385 ended with reward tensor([0.5000]), enemy health [0.0, 5.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 386 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 387 ended with reward tensor([0]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 388 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 389 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 390 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 391 ended with reward tensor([2]), enemy health [4, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 392 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 393 ended with reward tensor([4.2000]), enemy health [0.0, 5.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 394 ended with reward tensor([2.5000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 395 ended with reward tensor([2.]), enemy health [0.0, 5.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 396 ended with reward tensor([4.]), enemy health [0.0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 397 ended with reward tensor([0.2000]), enemy health [4, 9.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 398 ended with reward tensor([2.5000]), enemy health [4, 9.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 399 ended with reward tensor([2]), enemy health [4, 9.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 400 ended with reward tensor([4.7000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 401 ended with reward tensor([-0.5000]), enemy health [4, 8.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 402 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 403 ended with reward tensor([0]), enemy health [4, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 404 ended with reward tensor([-2]), enemy health [4, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 405 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 406 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 407 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 408 ended with reward tensor([2.2000]), enemy health [0, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 409 ended with reward tensor([-1.8000]), enemy health [0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 410 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 411 ended with reward tensor([0.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 412 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 413 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 414 ended with reward tensor([0.2000]), enemy health [0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 415 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 416 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 417 ended with reward tensor([2.2000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 418 ended with reward tensor([2]), enemy health [0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 419 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 420 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 421 ended with reward tensor([0]), enemy health [4, 3.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 422 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 423 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 424 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 425 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 426 ended with reward tensor([4.7000]), enemy health [4, 9.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 427 ended with reward tensor([2.7000]), enemy health [0, 9.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 428 ended with reward tensor([2]), enemy health [0, 9.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 429 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 430 ended with reward tensor([4.2000]), enemy health [0.0, 3.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 431 ended with reward tensor([-1.8000]), enemy health [0.0, 0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 432 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 433 ended with reward tensor([2.2000]), enemy health [0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 434 ended with reward tensor([2.2000]), enemy health [0, 7.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 435 ended with reward tensor([2]), enemy health [0, 7.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 436 ended with reward tensor([1.2000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 437 ended with reward tensor([-0.8000]), enemy health [0.0, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 438 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 439 ended with reward tensor([4.2000]), enemy health [0.0, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 440 ended with reward tensor([3.5000]), enemy health [0.0, 5.0], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 441 ended with reward tensor([0.2000]), enemy health [0.0, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 442 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 443 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 444 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 445 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 446 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 447 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 448 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 449 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 450 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 451 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 452 ended with reward tensor([0.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 453 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 454 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 455 ended with reward tensor([0.7000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 456 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 457 ended with reward tensor([2.7000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 458 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 459 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 460 ended with reward tensor([-0.5000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 461 ended with reward tensor([-2.5000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 462 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 463 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 464 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 465 ended with reward tensor([2]), enemy health [4, 7.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 466 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 467 ended with reward tensor([0]), enemy health [4, 5.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 468 ended with reward tensor([4.]), enemy health [4, 5.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 469 ended with reward tensor([0.5000]), enemy health [4, 5.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 470 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 471 ended with reward tensor([4.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 472 ended with reward tensor([2.2000]), enemy health [4, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 473 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 474 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 475 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 476 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 477 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 478 ended with reward tensor([-2.5000]), enemy health [4, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 479 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 480 ended with reward tensor([4.2000]), enemy health [2.0, 1.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 481 ended with reward tensor([2.]), enemy health [2.0, 1.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 482 ended with reward tensor([0]), enemy health [2.0, 1.0], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 483 ended with reward tensor([2]), enemy health [2.0, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 484 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 485 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 486 ended with reward tensor([0.2000]), enemy health [0.0, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 487 ended with reward tensor([0.2000]), enemy health [0.0, 0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 488 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 489 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 490 ended with reward tensor([-1.3000]), enemy health [0.0, 0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 491 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 492 ended with reward tensor([0.2000]), enemy health [0.0, 9.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 493 ended with reward tensor([-0.5000]), enemy health [0.0, 9.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 494 ended with reward tensor([2]), enemy health [0.0, 9.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 495 ended with reward tensor([0.2000]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 496 ended with reward tensor([2.]), enemy health [0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 497 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 498 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 499 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 500 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 501 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 502 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 503 ended with reward tensor([0.2000]), enemy health [2.0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 504 ended with reward tensor([2]), enemy health [2.0, 1.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 505 ended with reward tensor([2.5000]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 506 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 507 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 508 ended with reward tensor([-0.5000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 509 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 510 ended with reward tensor([-0.5000]), enemy health [1.0, 9], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 511 ended with reward tensor([-2.5000]), enemy health [1.0, 9], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 512 ended with reward tensor([0.]), enemy health [4, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 513 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 514 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 515 ended with reward tensor([1.]), enemy health [4, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 516 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 517 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 518 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 519 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 520 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 521 ended with reward tensor([4.2000]), enemy health [4, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 522 ended with reward tensor([3.5000]), enemy health [4, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 523 ended with reward tensor([0.2000]), enemy health [2.0, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 524 ended with reward tensor([3.5000]), enemy health [2.0, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 525 ended with reward tensor([1.5000]), enemy health [2.0, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 526 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 527 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 528 ended with reward tensor([0]), enemy health [4.0, 9], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 529 ended with reward tensor([0.7000]), enemy health [4.0, 8.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 530 ended with reward tensor([-2.5000]), enemy health [4.0, 8.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 531 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 532 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 533 ended with reward tensor([0]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 534 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 535 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 536 ended with reward tensor([2.2000]), enemy health [4, 9.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 537 ended with reward tensor([2.2000]), enemy health [2.0, 9.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 538 ended with reward tensor([2]), enemy health [2.0, 9.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 539 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 540 ended with reward tensor([2.]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 541 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 542 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 543 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 544 ended with reward tensor([0]), enemy health [4, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 545 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 546 ended with reward tensor([-1.3000]), enemy health [3.0, 9.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 547 ended with reward tensor([0]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 548 ended with reward tensor([2.5000]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 549 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 550 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 551 ended with reward tensor([2.7000]), enemy health [0.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 552 ended with reward tensor([0.2000]), enemy health [0.0, 0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 553 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 554 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [2.0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 555 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 556 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 557 ended with reward tensor([-2.5000]), enemy health [4, 9], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 558 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 559 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 560 ended with reward tensor([2.2000]), enemy health [4, 0.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 561 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 562 ended with reward tensor([-2.5000]), enemy health [3.0, 0.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 563 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 564 ended with reward tensor([0.5000]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 565 ended with reward tensor([0]), enemy health [4, 3.0], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 566 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 567 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 568 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 569 ended with reward tensor([1.]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 570 ended with reward tensor([0]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 571 ended with reward tensor([0.]), enemy health [4, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 572 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 573 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 574 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 575 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 576 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 577 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 578 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 579 ended with reward tensor([-0.5000]), enemy health [2.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 580 ended with reward tensor([-0.5000]), enemy health [2.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 581 ended with reward tensor([1.2000]), enemy health [2.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 582 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 583 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 584 ended with reward tensor([4.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 585 ended with reward tensor([1.]), enemy health [4, 9], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 586 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 587 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 588 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 589 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 590 ended with reward tensor([4.2000]), enemy health [0.0, 1.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 591 ended with reward tensor([-1.8000]), enemy health [0.0, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 592 ended with reward tensor([0]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 593 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 594 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 595 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 596 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 597 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 598 ended with reward tensor([4.]), enemy health [4, 5.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 599 ended with reward tensor([0]), enemy health [4, 5.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 600 ended with reward tensor([0.2000]), enemy health [4.0, 5.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 601 ended with reward tensor([2]), enemy health [4.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 602 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 603 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 604 ended with reward tensor([2]), enemy health [4, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 605 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 606 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 607 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 608 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 609 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 610 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 611 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 612 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 613 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 614 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 615 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 616 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 617 ended with reward tensor([-1.3000]), enemy health [1.0, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 618 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 619 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [2.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 620 ended with reward tensor([0.7000]), enemy health [4, 0], model health [2.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 621 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [2.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 622 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [2.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 623 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 624 ended with reward tensor([0.5000]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 625 ended with reward tensor([2.]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 626 ended with reward tensor([2.]), enemy health [4, 3.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 627 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 628 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 629 ended with reward tensor([4.2000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 630 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 631 ended with reward tensor([5.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 632 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 633 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 634 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 635 ended with reward tensor([-1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 636 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 637 ended with reward tensor([4.2000]), enemy health [0.0, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 638 ended with reward tensor([2.]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 639 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 640 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 641 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4.0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 642 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 643 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 644 ended with reward tensor([-2.5000]), enemy health [4, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 645 ended with reward tensor([3.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 646 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 647 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 648 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 649 ended with reward tensor([-2.5000]), enemy health [4, 0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 650 ended with reward tensor([0]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 651 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 652 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 653 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 654 ended with reward tensor([-2.5000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 655 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 656 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 657 ended with reward tensor([2.2000]), enemy health [0.0, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 658 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 659 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 660 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 661 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 662 ended with reward tensor([1.]), enemy health [3.0, 0.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 663 ended with reward tensor([-1.3000]), enemy health [2.0, 0.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 664 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 665 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 666 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 667 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 668 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 669 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 670 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 671 ended with reward tensor([-1.3000]), enemy health [1.0, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 672 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 673 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 674 ended with reward tensor([2]), enemy health [4.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 675 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 676 ended with reward tensor([2.]), enemy health [4, 9.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 677 ended with reward tensor([2]), enemy health [4, 9.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 678 ended with reward tensor([0.2000]), enemy health [4, 9.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 679 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 680 ended with reward tensor([0.2000]), enemy health [0.0, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 681 ended with reward tensor([-0.5000]), enemy health [0.0, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 682 ended with reward tensor([-2.5000]), enemy health [0.0, 3.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 683 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 684 ended with reward tensor([4.]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 685 ended with reward tensor([4.2000]), enemy health [4.0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 686 ended with reward tensor([0.7000]), enemy health [4.0, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 687 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 688 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 689 ended with reward tensor([-1.3000]), enemy health [4.0, 3.0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 690 ended with reward tensor([0.2000]), enemy health [4, 9.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 691 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 692 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 693 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 694 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 695 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 696 ended with reward tensor([-0.5000]), enemy health [4, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 697 ended with reward tensor([-1.3000]), enemy health [4.0, 3.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 698 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 699 ended with reward tensor([0.2000]), enemy health [2.0, 3.0], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 700 ended with reward tensor([-0.1000]), enemy health [0.0, 3.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 701 ended with reward tensor([0]), enemy health [0.0, 3.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 702 ended with reward tensor([2]), enemy health [0.0, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 703 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 704 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 705 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 706 ended with reward tensor([2]), enemy health [0.0, 7.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 707 ended with reward tensor([1.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 708 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 709 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 710 ended with reward tensor([2]), enemy health [4.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 711 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 712 ended with reward tensor([2.2000]), enemy health [0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 713 ended with reward tensor([-1.8000]), enemy health [0, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 714 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 715 ended with reward tensor([0.2000]), enemy health [4.0, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 716 ended with reward tensor([2]), enemy health [4.0, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 717 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 718 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 719 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [3.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 720 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 721 ended with reward tensor([0.7000]), enemy health [4, 2.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 722 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 723 ended with reward tensor([-1.]), enemy health [4, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 724 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 725 ended with reward tensor([0]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 726 ended with reward tensor([0]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 727 ended with reward tensor([0]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 728 ended with reward tensor([-2]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 729 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 730 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 731 ended with reward tensor([2]), enemy health [4, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 732 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 733 ended with reward tensor([0]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 734 ended with reward tensor([2.]), enemy health [4, 3.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 735 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 736 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 737 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 738 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 739 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 740 ended with reward tensor([2.]), enemy health [2.0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 741 ended with reward tensor([2]), enemy health [2.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 742 ended with reward tensor([0]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 743 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 744 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 745 ended with reward tensor([0]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 746 ended with reward tensor([-1.8000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 747 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 748 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 749 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 750 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 751 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 752 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 753 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 754 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 755 ended with reward tensor([0.2000]), enemy health [4.0, 0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 756 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 757 ended with reward tensor([4.2000]), enemy health [4, 0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 758 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 759 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 760 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 761 ended with reward tensor([0.2000]), enemy health [0.0, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 762 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 763 ended with reward tensor([0.2000]), enemy health [0, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 764 ended with reward tensor([2]), enemy health [0, 7.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 765 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 766 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 767 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 768 ended with reward tensor([2.7000]), enemy health [0.0, 5.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 769 ended with reward tensor([0.]), enemy health [0.0, 0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 770 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 771 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [4.0, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 772 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 773 ended with reward tensor([0.7000]), enemy health [1.0, 7.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 774 ended with reward tensor([-1.]), enemy health [0.0, 7.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 775 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 776 ended with reward tensor([0]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 777 ended with reward tensor([2]), enemy health [4, 7.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 778 ended with reward tensor([0.7000]), enemy health [0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 779 ended with reward tensor([1.5000]), enemy health [0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 780 ended with reward tensor([2]), enemy health [0, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 781 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 782 ended with reward tensor([4.2000]), enemy health [4, 0.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 783 ended with reward tensor([3.5000]), enemy health [4, 0.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 784 ended with reward tensor([-0.5000]), enemy health [4, 0.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 785 ended with reward tensor([-1.3000]), enemy health [3.0, 0.0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 786 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 787 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 788 ended with reward tensor([4.2000]), enemy health [2.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 789 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 790 ended with reward tensor([2.7000]), enemy health [0.0, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 791 ended with reward tensor([0.]), enemy health [0.0, 3.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 792 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 793 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 794 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 795 ended with reward tensor([0.7000]), enemy health [4, 9.0], model health [3.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 796 ended with reward tensor([0]), enemy health [4, 9.0], model health [3.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 797 ended with reward tensor([-2.5000]), enemy health [4, 9.0], model health [3.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 798 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 799 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 800 ended with reward tensor([2.2000]), enemy health [4, 0.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 801 ended with reward tensor([1.5000]), enemy health [4, 0.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 802 ended with reward tensor([-1.3000]), enemy health [1.0, 0.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 803 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 804 ended with reward tensor([4.2000]), enemy health [0, 5.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 805 ended with reward tensor([2.2000]), enemy health [0, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 806 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 807 ended with reward tensor([2.]), enemy health [4.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 808 ended with reward tensor([2]), enemy health [4.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 809 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 810 ended with reward tensor([2.5000]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 811 ended with reward tensor([0]), enemy health [4, 7.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 812 ended with reward tensor([2.]), enemy health [4, 7.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 813 ended with reward tensor([0.]), enemy health [4, 7.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 814 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 815 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 816 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 817 ended with reward tensor([2.7000]), enemy health [3.0, 2.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 818 ended with reward tensor([-1.]), enemy health [3.0, 0.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 819 ended with reward tensor([4.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 820 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 821 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 822 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 823 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 824 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 825 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 826 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 827 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 828 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 829 ended with reward tensor([0.5000]), enemy health [4, 3.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 830 ended with reward tensor([4.]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 831 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 832 ended with reward tensor([0.2000]), enemy health [4, 1.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 833 ended with reward tensor([-0.5000]), enemy health [4, 1.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 834 ended with reward tensor([-0.5000]), enemy health [4, 1.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 835 ended with reward tensor([-2.5000]), enemy health [4, 1.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 836 ended with reward tensor([4.7000]), enemy health [4, 1.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 837 ended with reward tensor([5.2000]), enemy health [0.0, 1.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 838 ended with reward tensor([2.5000]), enemy health [0.0, 1.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 839 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 840 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 841 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 842 ended with reward tensor([1.5000]), enemy health [0.0, 6.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 843 ended with reward tensor([2]), enemy health [0.0, 6.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 844 ended with reward tensor([2.7000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 845 ended with reward tensor([0.2000]), enemy health [0.0, 0.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 846 ended with reward tensor([0]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 847 ended with reward tensor([0.]), enemy health [4, 9], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 848 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 849 ended with reward tensor([2]), enemy health [4, 7.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 850 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 851 ended with reward tensor([0.]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 852 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 853 ended with reward tensor([2]), enemy health [4, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 854 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 855 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 856 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 857 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 858 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 859 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 860 ended with reward tensor([4.2000]), enemy health [0.0, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 861 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 862 ended with reward tensor([0.5000]), enemy health [0.0, 6.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 863 ended with reward tensor([-0.5000]), enemy health [0.0, 6.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 864 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 865 ended with reward tensor([4.9000]), enemy health [4, 2.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 866 ended with reward tensor([1.]), enemy health [4, 0.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 867 ended with reward tensor([2.7000]), enemy health [3.0, 0.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 868 ended with reward tensor([-1.3000]), enemy health [3.0, 0.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 869 ended with reward tensor([4.2000]), enemy health [4.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 870 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 871 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 872 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 873 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 874 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 875 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 876 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 877 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 878 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 879 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 880 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 881 ended with reward tensor([0]), enemy health [4, 7.0], model health [4, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 882 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 883 ended with reward tensor([0]), enemy health [4, 6.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 884 ended with reward tensor([-2.5000]), enemy health [4, 6.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 885 ended with reward tensor([4.7000]), enemy health [4, 9.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 886 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 887 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 888 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 889 ended with reward tensor([-1.3000]), enemy health [0, 6.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 890 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 891 ended with reward tensor([2.7000]), enemy health [0.0, 5.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 892 ended with reward tensor([4.2000]), enemy health [0.0, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 893 ended with reward tensor([0.2000]), enemy health [4, 9.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 894 ended with reward tensor([4.7000]), enemy health [4, 1.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 895 ended with reward tensor([4.2000]), enemy health [4, 0.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 896 ended with reward tensor([0.7000]), enemy health [2.0, 0.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 897 ended with reward tensor([0.]), enemy health [0.0, 0.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 898 ended with reward tensor([5.2000]), enemy health [4, 7.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 899 ended with reward tensor([5.2000]), enemy health [4, 3.0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 900 ended with reward tensor([5.2000]), enemy health [4, 0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 901 ended with reward tensor([4.5000]), enemy health [4, 0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 902 ended with reward tensor([-1.3000]), enemy health [4, 0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 903 ended with reward tensor([1.2000]), enemy health [4, 3.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 904 ended with reward tensor([0.7000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 905 ended with reward tensor([3.5000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 906 ended with reward tensor([3.5000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 907 ended with reward tensor([-1.3000]), enemy health [4.0, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 908 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 909 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 910 ended with reward tensor([4.2000]), enemy health [4, 0.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 911 ended with reward tensor([3.5000]), enemy health [4, 0.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 912 ended with reward tensor([-1.3000]), enemy health [0.0, 0.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 913 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 914 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 915 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 916 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 917 ended with reward tensor([4.2000]), enemy health [4.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 918 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 919 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 920 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 921 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 922 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 923 ended with reward tensor([2.7000]), enemy health [0.0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 924 ended with reward tensor([-1.3000]), enemy health [0.0, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 925 ended with reward tensor([0.7000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 926 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 927 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 928 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 929 ended with reward tensor([4.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 930 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 931 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 932 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 933 ended with reward tensor([0.5000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 934 ended with reward tensor([1.5000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 935 ended with reward tensor([0.2000]), enemy health [2.0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 936 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 937 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 938 ended with reward tensor([3.5000]), enemy health [0.0, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 939 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 940 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 941 ended with reward tensor([-2.5000]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 942 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 943 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 944 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 945 ended with reward tensor([2.7000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 946 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 947 ended with reward tensor([4.]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 948 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 949 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 950 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 951 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 952 ended with reward tensor([-1.3000]), enemy health [0.0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 953 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 954 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 955 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 956 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 957 ended with reward tensor([-1.3000]), enemy health [0.0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 958 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 959 ended with reward tensor([4.]), enemy health [4, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 960 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 961 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 962 ended with reward tensor([-1.8000]), enemy health [0.0, 9], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 963 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 964 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 965 ended with reward tensor([0]), enemy health [0.0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 966 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 967 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 968 ended with reward tensor([0]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 969 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 970 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 971 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 972 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 973 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 974 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 975 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 976 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 977 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 978 ended with reward tensor([1.5000]), enemy health [0.0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 979 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 980 ended with reward tensor([-1.3000]), enemy health [0.0, 3.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 981 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 982 ended with reward tensor([2.]), enemy health [4, 7.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 983 ended with reward tensor([2]), enemy health [4, 7.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 984 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 985 ended with reward tensor([0.2000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 986 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 987 ended with reward tensor([4.2000]), enemy health [2.0, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 988 ended with reward tensor([1.5000]), enemy health [2.0, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 989 ended with reward tensor([0]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 990 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 991 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 992 ended with reward tensor([1.]), enemy health [0.0, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 993 ended with reward tensor([-1.3000]), enemy health [0.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 994 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 995 ended with reward tensor([2.]), enemy health [0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 996 ended with reward tensor([2.]), enemy health [0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 997 ended with reward tensor([4.]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 998 ended with reward tensor([1.2000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 999 ended with reward tensor([4.7000]), enemy health [0.0, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1000 ended with reward tensor([2.]), enemy health [0.0, 7.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1001 ended with reward tensor([2.]), enemy health [0.0, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1002 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1003 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1004 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1005 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1006 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1007 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1008 ended with reward tensor([0]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1009 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1010 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1011 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1012 ended with reward tensor([0.9000]), enemy health [0.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1013 ended with reward tensor([2.7000]), enemy health [0.0, 9.0], model health [1.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1014 ended with reward tensor([0]), enemy health [0.0, 9.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1015 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1016 ended with reward tensor([-1.3000]), enemy health [0.0, 7.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1017 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1018 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1019 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1020 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1021 ended with reward tensor([-1.3000]), enemy health [2.0, 3.0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1022 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1023 ended with reward tensor([4.2000]), enemy health [0, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1024 ended with reward tensor([0.2000]), enemy health [0, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1025 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1026 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1027 ended with reward tensor([0.2000]), enemy health [2.0, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1028 ended with reward tensor([2.]), enemy health [2.0, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1029 ended with reward tensor([2]), enemy health [2.0, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1030 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1031 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1032 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1033 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1034 ended with reward tensor([-2.5000]), enemy health [2.0, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1035 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1036 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1037 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1038 ended with reward tensor([-0.5000]), enemy health [2.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1039 ended with reward tensor([-2.5000]), enemy health [2.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1040 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1041 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1042 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1043 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1044 ended with reward tensor([-1.3000]), enemy health [3.0, 4.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1045 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1046 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1047 ended with reward tensor([2.2000]), enemy health [4.0, 1.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1048 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1049 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [3.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1050 ended with reward tensor([0]), enemy health [4, 5.0], model health [3.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1051 ended with reward tensor([2.]), enemy health [4, 5.0], model health [3.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1052 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1053 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1054 ended with reward tensor([2.2000]), enemy health [0.0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1055 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1056 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1057 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1058 ended with reward tensor([2.]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1059 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1060 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1061 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1062 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1063 ended with reward tensor([1.]), enemy health [2.0, 0.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1064 ended with reward tensor([-1.8000]), enemy health [0.0, 0.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1065 ended with reward tensor([0]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1066 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1067 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1068 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1069 ended with reward tensor([-1.3000]), enemy health [0.0, 9.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1070 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1071 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1072 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1073 ended with reward tensor([0]), enemy health [4.0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1074 ended with reward tensor([2]), enemy health [4.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1075 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1076 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1077 ended with reward tensor([0.7000]), enemy health [3.0, 7.0], model health [4.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1078 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [2.0, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1079 ended with reward tensor([-1.3000]), enemy health [2.0, 6.0], model health [1.0, 6.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1080 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1081 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1082 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1083 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1084 ended with reward tensor([-1.]), enemy health [0.0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1085 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1086 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1087 ended with reward tensor([4.7000]), enemy health [0.0, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1088 ended with reward tensor([2.2000]), enemy health [0.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1089 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1090 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1091 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1092 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1093 ended with reward tensor([0]), enemy health [4, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1094 ended with reward tensor([-1.3000]), enemy health [4.0, 7.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1095 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1096 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1097 ended with reward tensor([2]), enemy health [0.0, 9.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1098 ended with reward tensor([2.7000]), enemy health [4, 7.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1099 ended with reward tensor([2.7000]), enemy health [4, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1100 ended with reward tensor([0.2000]), enemy health [4, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1101 ended with reward tensor([0.7000]), enemy health [4, 0.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1102 ended with reward tensor([0.]), enemy health [4, 0.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1103 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1104 ended with reward tensor([0.2000]), enemy health [4, 0.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1105 ended with reward tensor([-1.8000]), enemy health [0.0, 0.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1106 ended with reward tensor([5.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1107 ended with reward tensor([4.7000]), enemy health [4, 1.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1108 ended with reward tensor([4.7000]), enemy health [4, 0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1109 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1110 ended with reward tensor([-1.]), enemy health [0.0, 0], model health [1.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1111 ended with reward tensor([2.5000]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1112 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1113 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1114 ended with reward tensor([0.7000]), enemy health [4.0, 1.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1115 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1116 ended with reward tensor([-0.5000]), enemy health [2.0, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1117 ended with reward tensor([-1.3000]), enemy health [1.0, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1118 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1119 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1120 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1121 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1122 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1123 ended with reward tensor([4.7000]), enemy health [4, 9.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1124 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1125 ended with reward tensor([2.5000]), enemy health [2.0, 9.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1126 ended with reward tensor([2]), enemy health [2.0, 9.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1127 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1128 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1129 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1130 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1131 ended with reward tensor([2.7000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1132 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1133 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1134 ended with reward tensor([-1.]), enemy health [2.0, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1135 ended with reward tensor([0.2000]), enemy health [0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1136 ended with reward tensor([4.2000]), enemy health [0, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1137 ended with reward tensor([-1.3000]), enemy health [0, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1138 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1139 ended with reward tensor([0.5000]), enemy health [0.0, 7.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1140 ended with reward tensor([2]), enemy health [0.0, 7.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1141 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1142 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1143 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1144 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1145 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1146 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1147 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1148 ended with reward tensor([0.]), enemy health [0.0, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1149 ended with reward tensor([2.7000]), enemy health [0.0, 0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1150 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1151 ended with reward tensor([-1.8000]), enemy health [0.0, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1152 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1153 ended with reward tensor([4.7000]), enemy health [4, 1.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1154 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1155 ended with reward tensor([4.7000]), enemy health [3.0, 0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1156 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1157 ended with reward tensor([4.7000]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1158 ended with reward tensor([4.]), enemy health [4, 0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1159 ended with reward tensor([2.]), enemy health [4, 0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1160 ended with reward tensor([0.]), enemy health [4, 0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1161 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1162 ended with reward tensor([4.7000]), enemy health [0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1163 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1164 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1165 ended with reward tensor([4.7000]), enemy health [4, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1166 ended with reward tensor([4.]), enemy health [4, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1167 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1168 ended with reward tensor([-2.5000]), enemy health [3.0, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1169 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1170 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1171 ended with reward tensor([0.]), enemy health [4, 9], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1172 ended with reward tensor([-0.3000]), enemy health [4, 5.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1173 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1174 ended with reward tensor([3.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1175 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1176 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1177 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1178 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1179 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1180 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1181 ended with reward tensor([-1.3000]), enemy health [4, 7.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1182 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1183 ended with reward tensor([1.]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1184 ended with reward tensor([2.2000]), enemy health [0, 3.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1185 ended with reward tensor([2.2000]), enemy health [0, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1186 ended with reward tensor([2]), enemy health [0, 1.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1187 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1188 ended with reward tensor([0.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1189 ended with reward tensor([0.2000]), enemy health [0.0, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1190 ended with reward tensor([1.5000]), enemy health [0.0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1191 ended with reward tensor([2]), enemy health [0.0, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1192 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1193 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1194 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1195 ended with reward tensor([0.]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1196 ended with reward tensor([-2.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1197 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1198 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1199 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1200 ended with reward tensor([3.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1201 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1202 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1203 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1204 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1205 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1206 ended with reward tensor([-1.3000]), enemy health [0.0, 4.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1207 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1208 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1209 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1210 ended with reward tensor([0]), enemy health [4, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1211 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1212 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1213 ended with reward tensor([0.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1214 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1215 ended with reward tensor([4.2000]), enemy health [4, 0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1216 ended with reward tensor([-2.5000]), enemy health [4, 0], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1217 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1218 ended with reward tensor([2.]), enemy health [0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1219 ended with reward tensor([2.]), enemy health [0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1220 ended with reward tensor([0]), enemy health [0, 9], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1221 ended with reward tensor([-2]), enemy health [0, 9], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1222 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1223 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1224 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1225 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1226 ended with reward tensor([-2]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1227 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1228 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1229 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1230 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1231 ended with reward tensor([-1.3000]), enemy health [0.0, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1232 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1233 ended with reward tensor([0.5000]), enemy health [4, 1.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1234 ended with reward tensor([2.]), enemy health [4, 1.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1235 ended with reward tensor([2]), enemy health [4, 1.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1236 ended with reward tensor([0.2000]), enemy health [4, 1.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1237 ended with reward tensor([0.2000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1238 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1239 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1240 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1241 ended with reward tensor([4.5000]), enemy health [4, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1242 ended with reward tensor([4.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1243 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1244 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1245 ended with reward tensor([-1.3000]), enemy health [4.0, 9.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1246 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1247 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1248 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1249 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1250 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1251 ended with reward tensor([2.7000]), enemy health [2.0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1252 ended with reward tensor([0.2000]), enemy health [0.0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1253 ended with reward tensor([2]), enemy health [0.0, 3.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1254 ended with reward tensor([0.2000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1255 ended with reward tensor([0.2000]), enemy health [0, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1256 ended with reward tensor([4.]), enemy health [0, 3.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1257 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1258 ended with reward tensor([2.]), enemy health [2.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1259 ended with reward tensor([2.]), enemy health [2.0, 5.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1260 ended with reward tensor([2]), enemy health [2.0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1261 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1262 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1263 ended with reward tensor([1.]), enemy health [4, 5.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1264 ended with reward tensor([2]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1265 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1266 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1267 ended with reward tensor([-1.]), enemy health [0.0, 0.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1268 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1269 ended with reward tensor([4.7000]), enemy health [0.0, 1.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1270 ended with reward tensor([0.7000]), enemy health [0.0, 1.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1271 ended with reward tensor([-1.]), enemy health [0.0, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1272 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1273 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1274 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1275 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1276 ended with reward tensor([4.7000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1277 ended with reward tensor([2.7000]), enemy health [0.0, 1.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1278 ended with reward tensor([0.]), enemy health [0.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1279 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1280 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1281 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1282 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1283 ended with reward tensor([-2.5000]), enemy health [1.0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1284 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1285 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1286 ended with reward tensor([3.5000]), enemy health [0.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1287 ended with reward tensor([1.5000]), enemy health [0.0, 5.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1288 ended with reward tensor([3.5000]), enemy health [0.0, 5.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1289 ended with reward tensor([0.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1290 ended with reward tensor([2.7000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1291 ended with reward tensor([0.7000]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1292 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1293 ended with reward tensor([-1.3000]), enemy health [0, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1294 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1295 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1296 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1297 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1298 ended with reward tensor([-1.3000]), enemy health [2.0, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1299 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1300 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1301 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1302 ended with reward tensor([2.]), enemy health [4, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1303 ended with reward tensor([0.]), enemy health [4, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1304 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1305 ended with reward tensor([2.2000]), enemy health [4, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1306 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1307 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1308 ended with reward tensor([0.2000]), enemy health [0, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1309 ended with reward tensor([3.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1310 ended with reward tensor([4.7000]), enemy health [0, 9], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1311 ended with reward tensor([0]), enemy health [0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1312 ended with reward tensor([2.]), enemy health [0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1313 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1314 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1315 ended with reward tensor([4.2000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1316 ended with reward tensor([3.5000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1317 ended with reward tensor([3.5000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1318 ended with reward tensor([1.5000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1319 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1320 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1321 ended with reward tensor([0.7000]), enemy health [1.0, 8.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1322 ended with reward tensor([0.7000]), enemy health [1.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1323 ended with reward tensor([-1.3000]), enemy health [1.0, 4.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1324 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1325 ended with reward tensor([-0.5000]), enemy health [4, 1.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1326 ended with reward tensor([1.]), enemy health [4, 0.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1327 ended with reward tensor([0.2000]), enemy health [0, 0.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1328 ended with reward tensor([4.2000]), enemy health [0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1329 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1330 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1331 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1332 ended with reward tensor([2]), enemy health [0, 8.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1333 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1334 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1335 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1336 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1337 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1338 ended with reward tensor([0]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1339 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1340 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1341 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1342 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1343 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1344 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1345 ended with reward tensor([-1.3000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1346 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1347 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1348 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1349 ended with reward tensor([0]), enemy health [0, 8.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1350 ended with reward tensor([2]), enemy health [0, 8.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1351 ended with reward tensor([0.7000]), enemy health [4, 9.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1352 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1353 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1354 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1355 ended with reward tensor([-1.3000]), enemy health [0.0, 5.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1356 ended with reward tensor([0.7000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1357 ended with reward tensor([4.2000]), enemy health [0, 1.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1358 ended with reward tensor([-1.8000]), enemy health [0, 0.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1359 ended with reward tensor([2.7000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1360 ended with reward tensor([3.5000]), enemy health [0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1361 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1362 ended with reward tensor([2.7000]), enemy health [4, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1363 ended with reward tensor([2.]), enemy health [4, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1364 ended with reward tensor([0.7000]), enemy health [3.0, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1365 ended with reward tensor([-1.3000]), enemy health [1.0, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1366 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1367 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1368 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1369 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1370 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1371 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1372 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1373 ended with reward tensor([4.2000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1374 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1375 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1376 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1377 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1378 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1379 ended with reward tensor([2]), enemy health [4, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1380 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1381 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1382 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1383 ended with reward tensor([4.7000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1384 ended with reward tensor([-1.]), enemy health [0.0, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1385 ended with reward tensor([0.2000]), enemy health [2.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1386 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1387 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1388 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1389 ended with reward tensor([-1.3000]), enemy health [0.0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1390 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1391 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1392 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1393 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1394 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1395 ended with reward tensor([2.]), enemy health [2.0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1396 ended with reward tensor([2.]), enemy health [2.0, 9], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1397 ended with reward tensor([2]), enemy health [2.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1398 ended with reward tensor([4.7000]), enemy health [2.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1399 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1400 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1401 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1402 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1403 ended with reward tensor([2.2000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1404 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1405 ended with reward tensor([2.2000]), enemy health [0.0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1406 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1407 ended with reward tensor([-1.3000]), enemy health [0.0, 5.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1408 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1409 ended with reward tensor([2.7000]), enemy health [4, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1410 ended with reward tensor([0.7000]), enemy health [1.0, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1411 ended with reward tensor([-1.]), enemy health [0.0, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1412 ended with reward tensor([2.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1413 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1414 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1415 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1416 ended with reward tensor([-1.3000]), enemy health [4.0, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1417 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1418 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1419 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1420 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1421 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1422 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1423 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1424 ended with reward tensor([-0.5000]), enemy health [0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1425 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1426 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1427 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1428 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1429 ended with reward tensor([-2]), enemy health [0.0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1430 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1431 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1432 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1433 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1434 ended with reward tensor([-1.3000]), enemy health [0.0, 6.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1435 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1436 ended with reward tensor([0.7000]), enemy health [1.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1437 ended with reward tensor([1.]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1438 ended with reward tensor([4.7000]), enemy health [0.0, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1439 ended with reward tensor([0.]), enemy health [0.0, 0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1440 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1441 ended with reward tensor([0.7000]), enemy health [4, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1442 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1443 ended with reward tensor([0.7000]), enemy health [3.0, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1444 ended with reward tensor([-1.3000]), enemy health [3.0, 1.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1445 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1446 ended with reward tensor([0]), enemy health [4, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1447 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1448 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1449 ended with reward tensor([0.7000]), enemy health [4.0, 3.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1450 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1451 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1452 ended with reward tensor([-1.3000]), enemy health [2.0, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1453 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1454 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1455 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1456 ended with reward tensor([2]), enemy health [4, 7.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1457 ended with reward tensor([4.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1458 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1459 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1460 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1461 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1462 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1463 ended with reward tensor([-0.5000]), enemy health [4, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1464 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1465 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1466 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1467 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1468 ended with reward tensor([-1.3000]), enemy health [0.0, 2.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1469 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1470 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1471 ended with reward tensor([0]), enemy health [2.0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1472 ended with reward tensor([2]), enemy health [2.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1473 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1474 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1475 ended with reward tensor([2]), enemy health [0.0, 7.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1476 ended with reward tensor([4.2000]), enemy health [4, 0.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1477 ended with reward tensor([0.]), enemy health [4, 0.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1478 ended with reward tensor([4.]), enemy health [4, 0.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1479 ended with reward tensor([0.7000]), enemy health [4.0, 0.0], model health [4.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1480 ended with reward tensor([-1.3000]), enemy health [2.0, 0.0], model health [4.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1481 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1482 ended with reward tensor([3.5000]), enemy health [0.0, 5.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1483 ended with reward tensor([0.5000]), enemy health [0.0, 5.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1484 ended with reward tensor([2.]), enemy health [0.0, 5.0], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1485 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1486 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1487 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1488 ended with reward tensor([4.2000]), enemy health [2.0, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1489 ended with reward tensor([2.2000]), enemy health [0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1490 ended with reward tensor([-1.3000]), enemy health [0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1491 ended with reward tensor([0.]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1492 ended with reward tensor([4.]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1493 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1494 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1495 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1496 ended with reward tensor([0.2000]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1497 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1498 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1499 ended with reward tensor([0.7000]), enemy health [0, 9.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1500 ended with reward tensor([2]), enemy health [0, 9.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1501 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [1.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1502 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1503 ended with reward tensor([0.7000]), enemy health [3.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1504 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1505 ended with reward tensor([-1.3000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1506 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1507 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1508 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1509 ended with reward tensor([1.7000]), enemy health [0.0, 7.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1510 ended with reward tensor([-1.3000]), enemy health [0.0, 7.0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1511 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1512 ended with reward tensor([4.2000]), enemy health [2.0, 3.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1513 ended with reward tensor([0.7000]), enemy health [2.0, 2.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1514 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1515 ended with reward tensor([-1.]), enemy health [2.0, 0.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1516 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1517 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1518 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1519 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1520 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1521 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1522 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1523 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1524 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1525 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1526 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1527 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1528 ended with reward tensor([4.2000]), enemy health [2.0, 5.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1529 ended with reward tensor([0.7000]), enemy health [2.0, 3.0], model health [1.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1530 ended with reward tensor([0.7000]), enemy health [2.0, 1.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1531 ended with reward tensor([-1.]), enemy health [2.0, 0.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1532 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1533 ended with reward tensor([2.]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1534 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1535 ended with reward tensor([1.2000]), enemy health [4.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1536 ended with reward tensor([2.5000]), enemy health [4.0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1537 ended with reward tensor([2]), enemy health [4.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1538 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1539 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1540 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1541 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1542 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1543 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1544 ended with reward tensor([4.]), enemy health [2.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1545 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1546 ended with reward tensor([4.]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1547 ended with reward tensor([2.]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1548 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1549 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1550 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1551 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1552 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1553 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1554 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1555 ended with reward tensor([-0.5000]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1556 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1557 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1558 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1559 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1560 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1561 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1562 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1563 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1564 ended with reward tensor([0.7000]), enemy health [2.0, 8.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1565 ended with reward tensor([-1.3000]), enemy health [2.0, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1566 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1567 ended with reward tensor([2.2000]), enemy health [2.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1568 ended with reward tensor([1.]), enemy health [0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1569 ended with reward tensor([2]), enemy health [0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1570 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1571 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1572 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1573 ended with reward tensor([0.2000]), enemy health [0.0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1574 ended with reward tensor([1.5000]), enemy health [0.0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1575 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1576 ended with reward tensor([2]), enemy health [0.0, 5.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1577 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1578 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1579 ended with reward tensor([0.7000]), enemy health [0.0, 9.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1580 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1581 ended with reward tensor([2]), enemy health [0.0, 8.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1582 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1583 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1584 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1585 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1586 ended with reward tensor([-1.3000]), enemy health [4, 8.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1587 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1588 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1589 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1590 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1591 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1592 ended with reward tensor([4.2000]), enemy health [4, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1593 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1594 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [1.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1595 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1596 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1597 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1598 ended with reward tensor([2]), enemy health [0.0, 3.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1599 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1600 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1601 ended with reward tensor([2]), enemy health [4, 7.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1602 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1603 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1604 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1605 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1606 ended with reward tensor([-0.5000]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1607 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1608 ended with reward tensor([2.2000]), enemy health [2.0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1609 ended with reward tensor([2.2000]), enemy health [0.0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1610 ended with reward tensor([2]), enemy health [0.0, 3.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1611 ended with reward tensor([2.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1612 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1613 ended with reward tensor([0.2000]), enemy health [2.0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1614 ended with reward tensor([2.2000]), enemy health [0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1615 ended with reward tensor([2]), enemy health [0, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1616 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1617 ended with reward tensor([0]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1618 ended with reward tensor([2.]), enemy health [4, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1619 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1620 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1621 ended with reward tensor([2.2000]), enemy health [0.0, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1622 ended with reward tensor([2.7000]), enemy health [0.0, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1623 ended with reward tensor([2]), enemy health [0.0, 1.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1624 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1625 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1626 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1627 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1628 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1629 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1630 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1631 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1632 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1633 ended with reward tensor([2.]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1634 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1635 ended with reward tensor([0.2000]), enemy health [4, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1636 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1637 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1638 ended with reward tensor([2.]), enemy health [0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1639 ended with reward tensor([2.]), enemy health [0, 9], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1640 ended with reward tensor([2.]), enemy health [0, 9], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1641 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1642 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1643 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1644 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1645 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1646 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1647 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [3.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1648 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [3.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1649 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [3.0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1650 ended with reward tensor([0.7000]), enemy health [4, 8.0], model health [3.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1651 ended with reward tensor([-1.3000]), enemy health [4, 8.0], model health [3.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1652 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1653 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1654 ended with reward tensor([0.2000]), enemy health [0, 0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1655 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1656 ended with reward tensor([4.2000]), enemy health [4, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1657 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1658 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1659 ended with reward tensor([-1.]), enemy health [0.0, 0.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1660 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1661 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1662 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1663 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1664 ended with reward tensor([-1.3000]), enemy health [1.0, 0], model health [0, 4.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1665 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1666 ended with reward tensor([3.]), enemy health [0, 9], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1667 ended with reward tensor([0.7000]), enemy health [0, 9], model health [4.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1668 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [4.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1669 ended with reward tensor([-1.3000]), enemy health [0, 6.0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1670 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1671 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1672 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1673 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1674 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1675 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1676 ended with reward tensor([2.2000]), enemy health [2.0, 9.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1677 ended with reward tensor([0.7000]), enemy health [2.0, 9.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1678 ended with reward tensor([1.]), enemy health [0.0, 9.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1679 ended with reward tensor([2]), enemy health [0.0, 9.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1680 ended with reward tensor([1.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1681 ended with reward tensor([5.2000]), enemy health [0.0, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1682 ended with reward tensor([2.5000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1683 ended with reward tensor([2.5000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1684 ended with reward tensor([0.5000]), enemy health [0.0, 5.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1685 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1686 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1687 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1688 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1689 ended with reward tensor([0.2000]), enemy health [4.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1690 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1691 ended with reward tensor([0]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1692 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
model won!
Iteration 1693 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1694 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1695 ended with reward tensor([2.]), enemy health [2.0, 0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1696 ended with reward tensor([1.]), enemy health [2.0, 0.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1697 ended with reward tensor([-1.]), enemy health [0.0, 0.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
enemy won!
Iteration 1698 ended with reward tensor([0.2000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1699 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1700 ended with reward tensor([4.2000]), enemy health [4, 0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1701 ended with reward tensor([4.]), enemy health [2.0, 0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1702 ended with reward tensor([-1.]), enemy health [2.0, 0.0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1703 ended with reward tensor([4.2000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1704 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1705 ended with reward tensor([0]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1706 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1707 ended with reward tensor([1.2000]), enemy health [4, 7.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1708 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1709 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1710 ended with reward tensor([0.7000]), enemy health [4.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1711 ended with reward tensor([-1.3000]), enemy health [2.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1712 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1713 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1714 ended with reward tensor([2.]), enemy health [4, 5.0], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1715 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1716 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1717 ended with reward tensor([2.7000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1718 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1719 ended with reward tensor([2.2000]), enemy health [0.0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1720 ended with reward tensor([0.2000]), enemy health [0.0, 0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1721 ended with reward tensor([5.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1722 ended with reward tensor([3.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1723 ended with reward tensor([2.]), enemy health [0.0, 9], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1724 ended with reward tensor([0.]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1725 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1726 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1727 ended with reward tensor([0.7000]), enemy health [4, 9.0], model health [0.0, 6.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1728 ended with reward tensor([0.7000]), enemy health [4, 6.0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1729 ended with reward tensor([0.7000]), enemy health [4.0, 6.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1730 ended with reward tensor([2]), enemy health [4.0, 6.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1731 ended with reward tensor([0.2000]), enemy health [4, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1732 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1733 ended with reward tensor([1.5000]), enemy health [4, 1.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1734 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1735 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1736 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1737 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1738 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1739 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1740 ended with reward tensor([0.7000]), enemy health [4.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1741 ended with reward tensor([-1.3000]), enemy health [2.0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1742 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1743 ended with reward tensor([-0.8000]), enemy health [4, 3.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1744 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1745 ended with reward tensor([-0.5000]), enemy health [3.0, 3.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1746 ended with reward tensor([-1.3000]), enemy health [3.0, 2.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1747 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1748 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1749 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1750 ended with reward tensor([0.7000]), enemy health [2.0, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1751 ended with reward tensor([-1.3000]), enemy health [1.0, 0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1752 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1753 ended with reward tensor([2.2000]), enemy health [4, 9.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1754 ended with reward tensor([0.7000]), enemy health [4.0, 9.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1755 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 6.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1756 ended with reward tensor([0.7000]), enemy health [2.0, 5.0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1757 ended with reward tensor([2.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1758 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1759 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1760 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1761 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1762 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1763 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1764 ended with reward tensor([0.2000]), enemy health [4, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1765 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1766 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1767 ended with reward tensor([4.2000]), enemy health [4, 0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1768 ended with reward tensor([1.5000]), enemy health [4, 0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1769 ended with reward tensor([-0.5000]), enemy health [4, 0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1770 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1771 ended with reward tensor([4.2000]), enemy health [4, 5.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1772 ended with reward tensor([2.2000]), enemy health [4, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1773 ended with reward tensor([0.7000]), enemy health [3.0, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1774 ended with reward tensor([-1.3000]), enemy health [3.0, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1775 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1776 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1777 ended with reward tensor([3.7000]), enemy health [0, 7.0], model health [2.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1778 ended with reward tensor([2.]), enemy health [0, 7.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1779 ended with reward tensor([0.]), enemy health [0, 7.0], model health [1.0, 0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1780 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1781 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1782 ended with reward tensor([2.2000]), enemy health [4, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1783 ended with reward tensor([1.5000]), enemy health [4, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1784 ended with reward tensor([-0.5000]), enemy health [4, 0.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1785 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1786 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1787 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1788 ended with reward tensor([1.]), enemy health [0.0, 3.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1789 ended with reward tensor([2]), enemy health [0.0, 3.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1790 ended with reward tensor([2.7000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1791 ended with reward tensor([2.7000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1792 ended with reward tensor([2.]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1793 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1794 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1795 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1796 ended with reward tensor([2.]), enemy health [0.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1797 ended with reward tensor([1.]), enemy health [0.0, 9], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1798 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1799 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1800 ended with reward tensor([2.7000]), enemy health [0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1801 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1802 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1803 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1804 ended with reward tensor([4.7000]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1805 ended with reward tensor([0.7000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1806 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1807 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1808 ended with reward tensor([5.7000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1809 ended with reward tensor([0.5000]), enemy health [0.0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1810 ended with reward tensor([2.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1811 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1812 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1813 ended with reward tensor([3.9000]), enemy health [0.0, 5.0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1814 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1815 ended with reward tensor([0.7000]), enemy health [0.0, 4.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1816 ended with reward tensor([-1.3000]), enemy health [0.0, 4.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1817 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1818 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1819 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1820 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1821 ended with reward tensor([2]), enemy health [0.0, 6.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1822 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1823 ended with reward tensor([2.2000]), enemy health [4, 9.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1824 ended with reward tensor([0.7000]), enemy health [4, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1825 ended with reward tensor([0.7000]), enemy health [3.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1826 ended with reward tensor([-1.3000]), enemy health [2.0, 5.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1827 ended with reward tensor([4.7000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1828 ended with reward tensor([4.]), enemy health [0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1829 ended with reward tensor([3.5000]), enemy health [0, 9], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1830 ended with reward tensor([2.]), enemy health [0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1831 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1832 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1833 ended with reward tensor([4.2000]), enemy health [4, 9.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1834 ended with reward tensor([2.]), enemy health [4, 9.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1835 ended with reward tensor([2]), enemy health [4, 9.0], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1836 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1837 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1838 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [4.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1839 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [4.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1840 ended with reward tensor([0.]), enemy health [0.0, 7.0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1841 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1842 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1843 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1844 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1845 ended with reward tensor([4.2000]), enemy health [4, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1846 ended with reward tensor([2.]), enemy health [4, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1847 ended with reward tensor([4.]), enemy health [4, 3.0], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1848 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1849 ended with reward tensor([2.]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1850 ended with reward tensor([2.]), enemy health [4, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1851 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1852 ended with reward tensor([2.7000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1853 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1854 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1855 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1856 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1857 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1858 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1859 ended with reward tensor([4.2000]), enemy health [4, 1.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1860 ended with reward tensor([4.2000]), enemy health [2.0, 1.0], model health [4.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1861 ended with reward tensor([0]), enemy health [2.0, 1.0], model health [4.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1862 ended with reward tensor([2.]), enemy health [2.0, 1.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1863 ended with reward tensor([-2]), enemy health [2.0, 1.0], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1864 ended with reward tensor([3.2000]), enemy health [0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1865 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1866 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1867 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1868 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1869 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1870 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1871 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1872 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1873 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1874 ended with reward tensor([2.2000]), enemy health [4, 1.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1875 ended with reward tensor([2.2000]), enemy health [4, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1876 ended with reward tensor([-0.5000]), enemy health [4, 0.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1877 ended with reward tensor([4.2000]), enemy health [0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1878 ended with reward tensor([0]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1879 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1880 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1881 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1882 ended with reward tensor([0.2000]), enemy health [0.0, 4.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1883 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1884 ended with reward tensor([-1.3000]), enemy health [0.0, 2.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1885 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1886 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1887 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1888 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1889 ended with reward tensor([5.2000]), enemy health [4, 7.0], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1890 ended with reward tensor([2.7000]), enemy health [4, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1891 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1892 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1893 ended with reward tensor([-2]), enemy health [3.0, 3.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1894 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1895 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1896 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1897 ended with reward tensor([0.7000]), enemy health [4, 7.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1898 ended with reward tensor([0.7000]), enemy health [1.0, 0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 1899 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1900 ended with reward tensor([3.5000]), enemy health [4, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1901 ended with reward tensor([4.7000]), enemy health [0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1902 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1903 ended with reward tensor([0.2000]), enemy health [0, 1.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1904 ended with reward tensor([-1.]), enemy health [0, 0], model health [0, 2.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1905 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1906 ended with reward tensor([2.]), enemy health [0.0, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 1
Iteration 1907 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1908 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1909 ended with reward tensor([3.]), enemy health [0.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1910 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1911 ended with reward tensor([-0.5000]), enemy health [0.0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1912 ended with reward tensor([-1.3000]), enemy health [0.0, 5.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1913 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1914 ended with reward tensor([0.5000]), enemy health [2.0, 9], model health [2.0, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1915 ended with reward tensor([2]), enemy health [2.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1916 ended with reward tensor([0.7000]), enemy health [4, 3.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1917 ended with reward tensor([3.5000]), enemy health [0.0, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1918 ended with reward tensor([3.5000]), enemy health [0.0, 3.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1919 ended with reward tensor([2.]), enemy health [0.0, 3.0], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1920 ended with reward tensor([0.]), enemy health [0.0, 3.0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1921 ended with reward tensor([3.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1922 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1923 ended with reward tensor([2.2000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1924 ended with reward tensor([0.7000]), enemy health [3.0, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1925 ended with reward tensor([-1.3000]), enemy health [1.0, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1926 ended with reward tensor([0.]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1927 ended with reward tensor([2.]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1928 ended with reward tensor([2.]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1929 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1930 ended with reward tensor([0.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1931 ended with reward tensor([4.7000]), enemy health [2.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1932 ended with reward tensor([4.7000]), enemy health [0, 9], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1933 ended with reward tensor([2.]), enemy health [0, 9], model health [4, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1934 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1935 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1936 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1937 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0.0, 2.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1938 ended with reward tensor([2]), enemy health [0.0, 6.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1939 ended with reward tensor([0.7000]), enemy health [4.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1940 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1941 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1942 ended with reward tensor([4.2000]), enemy health [4, 7.0], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1943 ended with reward tensor([4.2000]), enemy health [0, 7.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1944 ended with reward tensor([0.2000]), enemy health [0, 0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1945 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1946 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1947 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1948 ended with reward tensor([2.2000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1949 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1950 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1951 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1952 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1953 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1954 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1955 ended with reward tensor([2.]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1956 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1957 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1958 ended with reward tensor([0.7000]), enemy health [2.0, 7.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1959 ended with reward tensor([-2.5000]), enemy health [2.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1960 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1961 ended with reward tensor([2.2000]), enemy health [2.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1962 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1963 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1964 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1965 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1966 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1967 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1968 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1969 ended with reward tensor([3.5000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1970 ended with reward tensor([0.2000]), enemy health [0.0, 7.0], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1971 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1972 ended with reward tensor([-1.3000]), enemy health [0.0, 4.0], model health [0, 1.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 1973 ended with reward tensor([2.2000]), enemy health [4, 7.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1974 ended with reward tensor([2.2000]), enemy health [4, 5.0], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1975 ended with reward tensor([2]), enemy health [4, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1976 ended with reward tensor([0.5000]), enemy health [4, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1977 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1978 ended with reward tensor([2]), enemy health [0, 5.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1979 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1980 ended with reward tensor([0.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1981 ended with reward tensor([0.7000]), enemy health [4, 9.0], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1982 ended with reward tensor([0.7000]), enemy health [3.0, 9.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1983 ended with reward tensor([-2.5000]), enemy health [3.0, 9.0], model health [0, 8.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 1984 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1985 ended with reward tensor([0.2000]), enemy health [4, 5.0], model health [0, 9.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1986 ended with reward tensor([0.2000]), enemy health [0, 5.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1987 ended with reward tensor([0.7000]), enemy health [0, 1.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1988 ended with reward tensor([-1.]), enemy health [0, 0.0], model health [0.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 1989 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 1990 ended with reward tensor([0.2000]), enemy health [4, 3.0], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1991 ended with reward tensor([2.2000]), enemy health [4.0, 3.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1992 ended with reward tensor([2]), enemy health [4.0, 3.0], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1993 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 1994 ended with reward tensor([2.2000]), enemy health [0, 9], model health [0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 1995 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 1996 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 1997 ended with reward tensor([2.5000]), enemy health [4, 9], model health [4, 0], model VP 0, enemy VP 0, victory condition 2
Iteration 1998 ended with reward tensor([2]), enemy health [4, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 1999 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 2000 ended with reward tensor([2.7000]), enemy health [2.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2001 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2002 ended with reward tensor([0.7000]), enemy health [2.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2003 ended with reward tensor([-1.3000]), enemy health [2.0, 6.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 2004 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2005 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2006 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 2007 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2008 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2009 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 2010 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2011 ended with reward tensor([1.5000]), enemy health [0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2012 ended with reward tensor([2]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 2013 ended with reward tensor([0.2000]), enemy health [0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2014 ended with reward tensor([3.5000]), enemy health [0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2015 ended with reward tensor([4.7000]), enemy health [0, 5.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2016 ended with reward tensor([2.]), enemy health [0, 5.0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2017 ended with reward tensor([-1.3000]), enemy health [0, 4.0], model health [4.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 2018 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2019 ended with reward tensor([2.2000]), enemy health [2.0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2020 ended with reward tensor([2.2000]), enemy health [0.0, 9], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2021 ended with reward tensor([2]), enemy health [0.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 2022 ended with reward tensor([0.2000]), enemy health [4, 0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2023 ended with reward tensor([2.2000]), enemy health [0.0, 0], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 2024 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2025 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2026 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2027 ended with reward tensor([2.]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2028 ended with reward tensor([-2.5000]), enemy health [0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 2029 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2030 ended with reward tensor([4.2000]), enemy health [0.0, 7.0], model health [4, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2031 ended with reward tensor([4.2000]), enemy health [0.0, 7.0], model health [2.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2032 ended with reward tensor([0.7000]), enemy health [0.0, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2033 ended with reward tensor([-1.3000]), enemy health [0.0, 5.0], model health [0.0, 9.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 2034 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2035 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2036 ended with reward tensor([1.]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2037 ended with reward tensor([2]), enemy health [0.0, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 2038 ended with reward tensor([4.7000]), enemy health [4, 5.0], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2039 ended with reward tensor([1.]), enemy health [0.0, 5.0], model health [0.0, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2040 ended with reward tensor([0.7000]), enemy health [0.0, 3.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2041 ended with reward tensor([0.7000]), enemy health [0.0, 2.0], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2042 ended with reward tensor([-1.]), enemy health [0.0, 0], model health [0.0, 4.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
enemy won!
Iteration 2043 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 2044 ended with reward tensor([3.7000]), enemy health [0.0, 9], model health [2.0, 7.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2045 ended with reward tensor([0.7000]), enemy health [0.0, 8.0], model health [2.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2046 ended with reward tensor([0.7000]), enemy health [0.0, 6.0], model health [2.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2047 ended with reward tensor([-1.3000]), enemy health [0.0, 4.0], model health [2.0, 2.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
enemy won!
Iteration 2048 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2049 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2050 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2051 ended with reward tensor([2.2000]), enemy health [2.0, 9], model health [0.0, 5.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2052 ended with reward tensor([-1.]), enemy health [0.0, 9], model health [0, 5.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 2053 ended with reward tensor([4.]), enemy health [4, 9], model health [4, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 2054 ended with reward tensor([3.5000]), enemy health [4, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2055 ended with reward tensor([4.2000]), enemy health [2.0, 9], model health [4.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2056 ended with reward tensor([4.2000]), enemy health [0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 2057 ended with reward tensor([4.5000]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 2058 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [2.0, 5.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2059 ended with reward tensor([-0.5000]), enemy health [4, 5.0], model health [1.0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2060 ended with reward tensor([2.5000]), enemy health [4, 5.0], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2061 ended with reward tensor([0.5000]), enemy health [4, 5.0], model health [1.0, 0.0], model VP 0, enemy VP 0, victory condition 1
Slay and Secure Victory Condition
model won!
Iteration 2062 ended with reward tensor([2.2000]), enemy health [2.0, 9], model health [0.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2063 ended with reward tensor([2]), enemy health [2.0, 9], model health [0.0, 0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 2064 ended with reward tensor([4.]), enemy health [4, 9], model health [2.0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2065 ended with reward tensor([2.2000]), enemy health [4.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2066 ended with reward tensor([0.2000]), enemy health [0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2067 ended with reward tensor([2]), enemy health [0, 9], model health [0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
Iteration 2068 ended with reward tensor([4.2000]), enemy health [0.0, 9], model health [4, 7.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2069 ended with reward tensor([0.7000]), enemy health [0.0, 7.0], model health [4, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2070 ended with reward tensor([3.5000]), enemy health [0.0, 5.0], model health [4.0, 1.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2071 ended with reward tensor([2.]), enemy health [0.0, 5.0], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2072 ended with reward tensor([0.]), enemy health [0.0, 5.0], model health [2.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 2073 ended with reward tensor([2.]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2074 ended with reward tensor([-0.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2075 ended with reward tensor([0.2000]), enemy health [0.0, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 2
Iteration 2076 ended with reward tensor([1.5000]), enemy health [0.0, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2077 ended with reward tensor([-1.3000]), enemy health [0.0, 8.0], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 2
Ancient Relic Victory Condition
enemy won!
Iteration 2078 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 9], model VP 0, enemy VP 0, victory condition 1
Iteration 2079 ended with reward tensor([1.5000]), enemy health [4, 9], model health [0, 3.0], model VP 0, enemy VP 0, victory condition 1
Iteration 2080 ended with reward tensor([2]), enemy health [4, 9], model health [0, 0], model VP 0, enemy VP 0, victory condition 1
Major Victory
model won!
Iteration 2081 ended with reward tensor([4.2000]), enemy health [0, 9], model health [4, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2082 ended with reward tensor([0.7000]), enemy health [0, 8.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2083 ended with reward tensor([0.7000]), enemy health [0, 7.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2084 ended with reward tensor([1.]), enemy health [0, 7.0], model health [0.0, 3.0], model VP 0, enemy VP 0, victory condition 2
Iteration 2085 ended with reward tensor([2]), enemy health [0, 7.0], model health [0.0, 0.0], model VP 0, enemy VP 0, victory condition 2
Major Victory
model won!
